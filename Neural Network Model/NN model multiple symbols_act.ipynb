{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl (1.4MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-19.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: pyyaml in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/4a/5c86ed8b245aa48f9f819b13a0a9039e9126ba19fdd0c7e0b8026c12315a/tensorflow-1.14.0-cp36-cp36m-win_amd64.whl (68.3MB)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/59/ec6c6075dd628f2efd33dbe11b259e63e1de7cbc26e45b38de767df528d4/protobuf-3.8.0-cp36-cp36m-win_amd64.whl (1.1MB)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.0.8)\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/ed/e036d31a9b2c750f270cbb1cfc1c0f94ac78ae504eea7eec3267be4e294a/numpy-1.16.4-cp36-cp36m-win_amd64.whl (11.9MB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/6a/e83233ed636bdf8668f0e79897fd70bce04869482dd88f3cfc4c42404fb2/grpcio-1.21.1-cp36-cp36m-win_amd64.whl (1.6MB)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.1)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Building wheels for collected packages: gast, absl-py, termcolor, wrapt\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\ee\\98\\38\\46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\d7\\de\\2e\\efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "Successfully built gast absl-py termcolor wrapt\n",
      "Installing collected packages: gast, protobuf, numpy, absl-py, grpcio, markdown, tensorboard, astor, google-pasta, termcolor, wrapt, tensorflow-estimator, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.21.1 markdown-3.1.1 numpy-1.16.4 protobuf-3.8.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.11.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "!pip install --user keras\n",
    "!pip install --user tensorflow\n",
    "!pip install --user -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CPU only\n",
    "# Only Macbook needs to run this cell\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and do data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>exdate</th>\n",
       "      <th>maturity</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>underlying_price</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>cp_flag_C</th>\n",
       "      <th>cp_flag_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.181376</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.450289</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.676564</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.369425</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.888123</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date      exdate  maturity  strike_price  best_offer  \\\n",
       "0    AXP  2013-01-02  2013-01-04         2          60.0        0.03   \n",
       "1    AXP  2013-01-02  2013-01-04         2          62.5        0.05   \n",
       "2    AXP  2013-01-02  2013-01-04         2          65.0        0.05   \n",
       "3    AXP  2013-01-02  2013-01-04         2          67.5        0.50   \n",
       "4    AXP  2013-01-02  2013-01-04         2          70.0        0.01   \n",
       "\n",
       "   impl_volatility  underlying_price  interest_rate  cp_flag_C  cp_flag_P  \n",
       "0         0.181376             58.75         0.0008          1          0  \n",
       "1         0.450289             58.75         0.0008          1          0  \n",
       "2         0.676564             58.75         0.0008          1          0  \n",
       "3         1.369425             58.75         0.0008          1          0  \n",
       "4         0.888123             58.75         0.0008          1          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Options.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['interest_rate'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['best_offer'].values\n",
    "X = df[['maturity', 'strike_price', 'impl_volatility', 'underlying_price', 'cp_flag_C', 'cp_flag_P', 'interest_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to build a regression neural network model\n",
    "sc= preprocessing.MinMaxScaler()\n",
    "X= sc.fit_transform(X)\n",
    "y= y.reshape(-1,1)\n",
    "y=sc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1559488, 7)\n",
      "(1559488, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train, XX_validation, yy_train, yy_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0626 10:27:01.360829  7592 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0626 10:27:01.372834  7592 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0626 10:27:01.375843  7592 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Built Keras sequential model with 3 hidden layer, and after the first hidden layer.\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable early stopping based on the loss of validation data\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is a simple regression problem, we should custom metrics function\n",
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1))\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0626 10:27:25.071674  7592 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use mean_squared_error to compile regression model loss\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0626 10:27:45.490572  7592 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0626 10:27:45.587808  7592 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1247590 samples, validate on 311898 samples\n",
      "Epoch 1/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 1.8663e-04 - rmse: 0.0048 - r_square: 0.9826 - val_loss: 2.5641e-05 - val_rmse: 0.0039 - val_r_square: 0.9975\n",
      "Epoch 2/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 1.5015e-05 - rmse: 0.0027 - r_square: 0.9985 - val_loss: 1.8775e-05 - val_rmse: 0.0032 - val_r_square: 0.9981-05 - rmse: 0.0029 - r_square: 0.9 - ETA: 2s - los\n",
      "Epoch 3/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 1.1449e-05 - rmse: 0.0023 - r_square: 0.9989 - val_loss: 1.3845e-05 - val_rmse: 0.0026 - val_r_square: 0.9986\n",
      "Epoch 4/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 9.6179e-06 - rmse: 0.0020 - r_square: 0.9990 - val_loss: 1.0802e-05 - val_rmse: 0.0023 - val_r_square: 0.9989\n",
      "Epoch 5/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 8.4139e-06 - rmse: 0.0019 - r_square: 0.9992 - val_loss: 7.7196e-06 - val_rmse: 0.0017 - val_r_square: 0.9992\n",
      "Epoch 6/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.5241e-06 - rmse: 0.0017 - r_square: 0.9993 - val_loss: 6.1171e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 7/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.2026e-06 - rmse: 0.0017 - r_square: 0.9993 - val_loss: 6.9285e-06 - val_rmse: 0.0015 - val_r_square: 0.9993\n",
      "Epoch 8/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.6754e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 8.3874e-06 - val_rmse: 0.0017 - val_r_square: 0.9992\n",
      "Epoch 9/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.3809e-06 - rmse: 0.0016 - r_square: 0.9994 - val_loss: 7.7228e-06 - val_rmse: 0.0019 - val_r_square: 0.9992\n",
      "Epoch 10/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 6.2055e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 5.6974e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 11/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 5.8821e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 6.0533e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 12/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 5.7498e-06 - rmse: 0.0014 - r_square: 0.9994 - val_loss: 5.2104e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 13/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 5.6930e-06 - rmse: 0.0014 - r_square: 0.9994 - val_loss: 5.3698e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 14/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 5.5703e-06 - rmse: 0.0014 - r_square: 0.9994 - val_loss: 5.0140e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 15/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 5.4921e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 4.7261e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 16/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 5.4289e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 8.8901e-06 - val_rmse: 0.0018 - val_r_square: 0.9991\n",
      "Epoch 17/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 5.3035e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 5.9197e-06 - val_rmse: 0.0016 - val_r_square: 0.9994\n",
      "Epoch 18/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 5.2348e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 5.6095e-06 - val_rmse: 0.0014 - val_r_square: 0.9994\n",
      "Epoch 19/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 5.1929e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 6.2168e-06 - val_rmse: 0.0017 - val_r_square: 0.9994\n",
      "Epoch 20/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 5.1594e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.3513e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 21/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 5.0468e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.5676e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 22/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 5.0686e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.1609e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 23/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.9644e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.5256e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 24/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.8962e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.2317e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 25/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.9251e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.8822e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 26/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.9117e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 3.9784e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 27/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.7627e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 8.9340e-06 - val_rmse: 0.0018 - val_r_square: 0.9991\n",
      "Epoch 28/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.8219e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 1.0509e-05 - val_rmse: 0.0021 - val_r_square: 0.9990loss: 4.8367e-06 - rmse: 0.0013 - r_square: 0.9\n",
      "Epoch 29/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.7917e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.1763e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 30/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.7322e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.3818e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 31/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.6526e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.5874e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 32/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.6613e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.7182e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 33/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.6366e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.0582e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 34/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.6806e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 3.8611e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 35/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.5742e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.1426e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 36/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.5934e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.6770e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 37/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.5370e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.9178e-06 - val_rmse: 0.0013 - val_r_square: 0.99951s - loss: 4.5104e\n",
      "Epoch 38/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.5295e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.4220e-06 - val_rmse: 0.0015 - val_r_square: 0.9995\n",
      "Epoch 39/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.5173e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.3113e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 40/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.4663e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0143e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 41/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.5174e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.2839e-06 - val_rmse: 0.0011 - val_r_square: 0.9996: 4.5278e-06 - rmse: 0.0012 - r_square: 0.99\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.4791e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.9500e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 43/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.4562e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.2288e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 44/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.4330e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9929e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 45/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.4634e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7729e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 46/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.4173e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1949e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 47/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.4392e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.2142e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 48/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.3511e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.8987e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 49/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.3710e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9454e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 50/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.3417e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0834e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 51/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.3501e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.9475e-06 - val_rmse: 0.0013 - val_r_square: 0.9994\n",
      "Epoch 52/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.3370e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.7486e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 53/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.3117e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.6480e-06 - val_rmse: 0.0014 - val_r_square: 0.9994\n",
      "Epoch 54/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.3180e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.6208e-06 - val_rmse: 0.0013 - val_r_square: 0.9994012\n",
      "Epoch 55/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.2785e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1685e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 56/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.3324e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.7479e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 57/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.2415e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.8314e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 58/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.2908e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0093e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 59/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.2097e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0865e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 60/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.2723e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8434e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 61/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.2286e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7040e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 62/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.2585e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.6774e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 63/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.1880e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.4951e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 64/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.2086e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 8.0799e-06 - val_rmse: 0.0018 - val_r_square: 0.9992\n",
      "Epoch 65/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.1951e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7309e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 66/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.2185e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9358e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 67/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.1852e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0416e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 68/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.1284e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.6593e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 69/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.1663e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3364e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 70/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.1440e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3097e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 71/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.1405e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.6416e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 72/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.1867e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1382e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 73/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.1013e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3265e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 74/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.1430e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.6388e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 75/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.1008e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.8393e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 76/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.1512e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.4554e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 77/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.1144e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9491e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 78/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.0970e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.4977e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 79/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.1311e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9592e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 80/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.1065e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.4944e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 81/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0862e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.7055e-06 - val_rmse: 0.0014 - val_r_square: 0.9994\n",
      "Epoch 82/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0524e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0878e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 83/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.1075e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.6097e-06 - val_rmse: 0.0013 - val_r_square: 0.9994\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.0730e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7543e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 85/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0370e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.6504e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 86/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0797e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9833e-06 - val_rmse: 0.0011 - val_r_square: 0.9996- loss: 4.1181e-06 - rms\n",
      "Epoch 87/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0605e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.1393e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 88/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0334e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0693e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 89/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0295e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6462e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 90/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.0617e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.2555e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 91/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.0394e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4456e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 92/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.0071e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6857e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 93/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0347e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6655e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 94/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.0270e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 6.0969e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 95/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0077e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8212e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 96/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 4.0262e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0596e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 97/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.0015e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 7.5498e-06 - val_rmse: 0.0018 - val_r_square: 0.9993\n",
      "Epoch 98/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 4.0060e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.6582e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 99/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.9924e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.5194e-06 - val_rmse: 0.0011 - val_r_square: 0.9997\n",
      "Epoch 100/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.9745e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.0637e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 101/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9690e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8135e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 102/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9726e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.6413e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 103/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 4.0152e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7398e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 104/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.9653e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0258e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 105/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.9961e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4866e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 106/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.9612e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4891e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 107/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.9703e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9820e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 108/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.9724e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7248e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 109/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.9462e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2720e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 110/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.9824e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.6444e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 111/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.9394e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.5975e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 112/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9224e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.6112e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 113/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9446e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7401e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 114/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9247e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0691e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 115/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9193e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4643e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 116/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.9145e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2975e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 117/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.9158e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4969e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 118/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.9386e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4552e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 119/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.9264e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9568e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 120/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8611e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.3811e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 121/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.9298e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.5897e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 122/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8849e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8016e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 123/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9314e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9625e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 124/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9130e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.3528e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 125/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9370e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6210e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8856e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9747e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 127/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.9134e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9225e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 128/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8912e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4395e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 129/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8931e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.3683e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 130/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8820e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7186e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 131/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8729e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6603e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 132/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8761e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6597e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 133/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8968e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2446e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 134/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8459e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4938e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 135/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8939e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.5057e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 136/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8770e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8715e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 137/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8733e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0539e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 138/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8582e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4997e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 139/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8824e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.1905e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 140/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8754e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.0609e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 141/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8552e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0757e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 142/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8630e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0265e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 143/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8221e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6992e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 144/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8512e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4157e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 145/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8580e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9059e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 146/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8347e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 6.0471e-06 - val_rmse: 0.0016 - val_r_square: 0.9994\n",
      "Epoch 147/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8348e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4758e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 148/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8408e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2111e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 149/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8508e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7485e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 150/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8408e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7131e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 151/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8298e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8761e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 152/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8641e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6393e-06 - val_rmse: 0.0011 - val_r_square: 0.9996724e-06 - rmse: 0 - ETA: 1s - loss: 3.8722e-06 - rmse: 0.001\n",
      "Epoch 153/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8118e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.3277e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 154/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8465e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7461e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 155/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8397e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7289e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 156/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7990e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.4081e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 157/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8185e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.1662e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 158/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.8593e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.7269e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 159/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7857e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.5768e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 160/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8069e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.3721e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 161/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8148e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6052e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 162/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8189e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0539e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 163/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8124e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7017e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 164/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7903e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7276e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 165/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8092e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6158e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 166/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7744e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7858e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7792e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.6112e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 168/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.8071e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4909e-06 - val_rmse: 0.0011 - val_r_square: 0.9997\n",
      "Epoch 169/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7965e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6263e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 170/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7770e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4897e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 171/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7920e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4116e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 172/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7925e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9423e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 173/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7739e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4740e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 174/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7782e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0782e-06 - val_rmse: 0.0012 - val_r_square: 0.9996ss: 3.8008e-\n",
      "Epoch 175/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.8199e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4755e-06 - val_rmse: 9.9425e-04 - val_r_square: 0.9997\n",
      "Epoch 176/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7590e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.5635e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 177/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7819e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.5665e-06 - val_rmse: 0.0010 - val_r_square: 0.99960.0011 - r_squa\n",
      "Epoch 178/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7874e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.5968e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 179/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7910e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0234e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 180/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7653e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.4778e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 181/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7687e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6481e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 182/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7669e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.5285e-06 - val_rmse: 0.0011 - val_r_square: 0.9997\n",
      "Epoch 183/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7647e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8790e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 184/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7591e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6656e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 185/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7628e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.1560e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 186/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7319e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0971e-06 - val_rmse: 0.0011 - val_r_square: 0.9996e-06 - rmse: 0.0011 - r_s\n",
      "Epoch 187/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7494e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.2748e-06 - val_rmse: 9.8470e-04 - val_r_square: 0.9997\n",
      "Epoch 188/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7798e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2310e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 189/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7529e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.2968e-06 - val_rmse: 9.9972e-04 - val_r_square: 0.9997\n",
      "Epoch 190/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7284e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2769e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 191/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7520e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7510e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 192/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7326e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8281e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 193/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7451e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.6765e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 194/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7381e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.3779e-06 - val_rmse: 0.0010 - val_r_square: 0.9997\n",
      "Epoch 195/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7511e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2966e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 196/200\n",
      "1247590/1247590 [==============================] - 6s 4us/step - loss: 3.7330e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.3377e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 197/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7533e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9973e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 198/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 3.7459e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4493e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 199/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7434e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.1355e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 200/200\n",
      "1247590/1247590 [==============================] - 5s 4us/step - loss: 3.7399e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6459e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "result = model.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation)\n",
    "                   #callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.9088315e-02]\n",
      " [6.5235101e-02]\n",
      " [1.1087340e+00]\n",
      " [1.6013426e+00]\n",
      " [9.0264447e-02]\n",
      " [1.2800211e+01]\n",
      " [2.9944185e+01]\n",
      " [8.8438711e+00]\n",
      " [9.3262167e+00]\n",
      " [5.0455082e+01]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "pre_act = sc.inverse_transform(predictions)\n",
    "print(pre_act[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_act = sc.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.000e-02],\n",
       "       [1.200e-01],\n",
       "       [1.120e+00],\n",
       "       [1.500e+00],\n",
       "       [4.000e-02],\n",
       "       [1.255e+01],\n",
       "       [3.055e+01],\n",
       "       [8.300e+00],\n",
       "       [9.400e+00],\n",
       "       [5.065e+01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_act[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curves including R^2 and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for rmse\n",
    "plt.plot(result.history['rmse'])\n",
    "plt.plot(result.history['val_rmse'])\n",
    "plt.title('rmse')\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for R^2\n",
    "plt.plot(result.history['r_square'])\n",
    "plt.plot(result.history['val_r_square'])\n",
    "plt.title('model R^2')\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.146496\n",
      "Mean squared error (MSE):       0.070069\n",
      "Root mean squared error (RMSE): 0.264706\n",
      "R square (R^2):                 0.999659\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm, math\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1247590 samples, validate on 311898 samples\n",
      "Epoch 1/200\n",
      "1247590/1247590 [==============================] - 7s 6us/step - loss: 3.3774e-04 - rmse: 0.0087 - r_square: 0.9678 - val_loss: 1.9030e-04 - val_rmse: 0.0080 - val_r_square: 0.9817\n",
      "Epoch 2/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 2.8983e-05 - rmse: 0.0034 - r_square: 0.9972 - val_loss: 2.0098e-04 - val_rmse: 0.0073 - val_r_square: 0.9808\n",
      "Epoch 3/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.9616e-05 - rmse: 0.0028 - r_square: 0.9981 - val_loss: 1.6104e-04 - val_rmse: 0.0064 - val_r_square: 0.9848\n",
      "Epoch 4/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.5838e-05 - rmse: 0.0025 - r_square: 0.9984 - val_loss: 1.9723e-04 - val_rmse: 0.0070 - val_r_square: 0.9813\n",
      "Epoch 5/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.4334e-05 - rmse: 0.0024 - r_square: 0.9986 - val_loss: 2.1143e-04 - val_rmse: 0.0074 - val_r_square: 0.9799\n",
      "Epoch 6/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 1.2581e-05 - rmse: 0.0022 - r_square: 0.9988 - val_loss: 1.7074e-04 - val_rmse: 0.0065 - val_r_square: 0.9838\n",
      "Epoch 7/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.1711e-05 - rmse: 0.0021 - r_square: 0.9988 - val_loss: 1.5654e-04 - val_rmse: 0.0062 - val_r_square: 0.9852\n",
      "Epoch 8/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 1.1021e-05 - rmse: 0.0020 - r_square: 0.9989 - val_loss: 2.0073e-04 - val_rmse: 0.0069 - val_r_square: 0.9810\n",
      "Epoch 9/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 1.0352e-05 - rmse: 0.0020 - r_square: 0.9990 - val_loss: 1.8845e-04 - val_rmse: 0.0069 - val_r_square: 0.9822\n",
      "Epoch 10/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 1.0163e-05 - rmse: 0.0020 - r_square: 0.9990 - val_loss: 1.7797e-04 - val_rmse: 0.0067 - val_r_square: 0.9832\n",
      "Epoch 11/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 9.6053e-06 - rmse: 0.0019 - r_square: 0.9991 - val_loss: 1.4070e-04 - val_rmse: 0.0061 - val_r_square: 0.9867\n",
      "Epoch 12/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 9.2869e-06 - rmse: 0.0019 - r_square: 0.9991 - val_loss: 1.7414e-04 - val_rmse: 0.0064 - val_r_square: 0.9835\n",
      "Epoch 13/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 9.1781e-06 - rmse: 0.0018 - r_square: 0.9991 - val_loss: 1.5675e-04 - val_rmse: 0.0062 - val_r_square: 0.9852\n",
      "Epoch 14/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 8.6455e-06 - rmse: 0.0018 - r_square: 0.9991 - val_loss: 1.6337e-04 - val_rmse: 0.0061 - val_r_square: 0.9846\n",
      "Epoch 15/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 8.7918e-06 - rmse: 0.0018 - r_square: 0.9991 - val_loss: 1.4326e-04 - val_rmse: 0.0060 - val_r_square: 0.9865\n",
      "Epoch 16/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 8.4921e-06 - rmse: 0.0018 - r_square: 0.9992 - val_loss: 1.5930e-04 - val_rmse: 0.0062 - val_r_square: 0.9850\n",
      "Epoch 17/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 8.4360e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.7247e-04 - val_rmse: 0.0064 - val_r_square: 0.9837\n",
      "Epoch 18/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 8.1167e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.9433e-04 - val_rmse: 0.0070 - val_r_square: 0.9816\n",
      "Epoch 19/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 8.1356e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.8598e-04 - val_rmse: 0.0067 - val_r_square: 0.9824\n",
      "Epoch 20/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.9210e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.6662e-04 - val_rmse: 0.0062 - val_r_square: 0.9842\n",
      "Epoch 21/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.8683e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.6720e-04 - val_rmse: 0.0065 - val_r_square: 0.9842\n",
      "Epoch 22/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.7369e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.8145e-04 - val_rmse: 0.0069 - val_r_square: 0.9828\n",
      "Epoch 23/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 7.7764e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.7896e-04 - val_rmse: 0.0066 - val_r_square: 0.9831\n",
      "Epoch 24/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.6063e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.3959e-04 - val_rmse: 0.0060 - val_r_square: 0.9869\n",
      "Epoch 25/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.5048e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.4223e-04 - val_rmse: 0.0058 - val_r_square: 0.9866\n",
      "Epoch 26/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 7.4427e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.6926e-04 - val_rmse: 0.0063 - val_r_square: 0.9840\n",
      "Epoch 27/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.4344e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.5528e-04 - val_rmse: 0.0063 - val_r_square: 0.9853\n",
      "Epoch 28/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.2424e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.3464e-04 - val_rmse: 0.0058 - val_r_square: 0.9873\n",
      "Epoch 29/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 7.2916e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.7294e-04 - val_rmse: 0.0065 - val_r_square: 0.9837\n",
      "Epoch 30/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 7.1020e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.5631e-04 - val_rmse: 0.0060 - val_r_square: 0.9853\n",
      "Epoch 31/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 7.0372e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.6080e-04 - val_rmse: 0.0061 - val_r_square: 0.9848\n",
      "Epoch 32/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.2510e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.7614e-04 - val_rmse: 0.0064 - val_r_square: 0.9833\n",
      "Epoch 33/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.9845e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.5340e-04 - val_rmse: 0.0064 - val_r_square: 0.9855\n",
      "Epoch 34/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.9131e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.3482e-04 - val_rmse: 0.0057 - val_r_square: 0.9873\n",
      "Epoch 35/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 7.0099e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.6285e-04 - val_rmse: 0.0062 - val_r_square: 0.9846\n",
      "Epoch 36/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.7764e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.5705e-04 - val_rmse: 0.0060 - val_r_square: 0.9852\n",
      "Epoch 37/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.8963e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.5956e-04 - val_rmse: 0.0063 - val_r_square: 0.9849\n",
      "Epoch 38/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.7525e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.4589e-04 - val_rmse: 0.0059 - val_r_square: 0.9863\n",
      "Epoch 39/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.7083e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.6118e-04 - val_rmse: 0.0062 - val_r_square: 0.9848\n",
      "Epoch 40/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.8272e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.5974e-04 - val_rmse: 0.0061 - val_r_square: 0.9849\n",
      "Epoch 41/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.6935e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.5126e-04 - val_rmse: 0.0059 - val_r_square: 0.9857\n",
      "Epoch 42/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.7362e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.5979e-04 - val_rmse: 0.0061 - val_r_square: 0.9849\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.5722e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.8226e-04 - val_rmse: 0.0067 - val_r_square: 0.9828\n",
      "Epoch 44/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.6883e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.4781e-04 - val_rmse: 0.0059 - val_r_square: 0.9861\n",
      "Epoch 45/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.4507e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4628e-04 - val_rmse: 0.0061 - val_r_square: 0.9862\n",
      "Epoch 46/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.5123e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.6996e-04 - val_rmse: 0.0064 - val_r_square: 0.9840\n",
      "Epoch 47/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 6.5133e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4737e-04 - val_rmse: 0.0059 - val_r_square: 0.9861\n",
      "Epoch 48/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.4952e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4743e-04 - val_rmse: 0.0061 - val_r_square: 0.9861\n",
      "Epoch 49/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.5695e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.6315e-04 - val_rmse: 0.0064 - val_r_square: 0.9846\n",
      "Epoch 50/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.4460e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5398e-04 - val_rmse: 0.0061 - val_r_square: 0.9855\n",
      "Epoch 51/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.3766e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4976e-04 - val_rmse: 0.0060 - val_r_square: 0.9859\n",
      "Epoch 52/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.4120e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5793e-04 - val_rmse: 0.0062 - val_r_square: 0.9851\n",
      "Epoch 53/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 6.3619e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5089e-04 - val_rmse: 0.0063 - val_r_square: 0.9858\n",
      "Epoch 00053: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model2.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result2 = model2.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14105938]\n",
      " [ 0.45383525]\n",
      " [ 1.4506612 ]\n",
      " [ 2.0541828 ]\n",
      " [ 0.4501266 ]\n",
      " [11.754693  ]\n",
      " [27.416527  ]\n",
      " [ 7.7179933 ]\n",
      " [ 9.548293  ]\n",
      " [42.440228  ]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.869359\n",
      "Mean squared error (MSE):       2.887372\n",
      "Root mean squared error (RMSE): 1.699227\n",
      "R square (R^2):                 0.985961\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model2.predict(X_test)\n",
    "pre_act2 = sc.inverse_transform(predictions2)\n",
    "print(pre_act2[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act2))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act2))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act2)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try batch normalization technique to regularize neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1247590 samples, validate on 311898 samples\n",
      "Epoch 1/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 2.6774e-04 - rmse: 0.0099 - r_square: 0.9738 - val_loss: 4.1092e-05 - val_rmse: 0.0047 - val_r_square: 0.9960\n",
      "Epoch 2/200\n",
      "1247590/1247590 [==============================] - 7s 5us/step - loss: 1.6580e-04 - rmse: 0.0073 - r_square: 0.9839 - val_loss: 6.4023e-05 - val_rmse: 0.0046 - val_r_square: 0.9937\n",
      "Epoch 3/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.6055e-04 - rmse: 0.0069 - r_square: 0.9845 - val_loss: 9.2657e-05 - val_rmse: 0.0066 - val_r_square: 0.9910\n",
      "Epoch 4/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.5294e-04 - rmse: 0.0067 - r_square: 0.9852 - val_loss: 3.4704e-05 - val_rmse: 0.0039 - val_r_square: 0.9966\n",
      "Epoch 5/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.4963e-04 - rmse: 0.0066 - r_square: 0.9855 - val_loss: 2.4409e-05 - val_rmse: 0.0031 - val_r_square: 0.9976\n",
      "Epoch 6/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.4666e-04 - rmse: 0.0065 - r_square: 0.9859 - val_loss: 2.5529e-05 - val_rmse: 0.0034 - val_r_square: 0.9975\n",
      "Epoch 7/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.4527e-04 - rmse: 0.0065 - r_square: 0.9859 - val_loss: 1.7337e-05 - val_rmse: 0.0025 - val_r_square: 0.9983\n",
      "Epoch 8/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.4109e-04 - rmse: 0.0064 - r_square: 0.9863 - val_loss: 4.5351e-05 - val_rmse: 0.0044 - val_r_square: 0.9956\n",
      "Epoch 9/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.4038e-04 - rmse: 0.0063 - r_square: 0.9864 - val_loss: 1.8763e-05 - val_rmse: 0.0027 - val_r_square: 0.9982\n",
      "Epoch 10/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.4299e-04 - rmse: 0.0064 - r_square: 0.9861 - val_loss: 3.2859e-05 - val_rmse: 0.0037 - val_r_square: 0.9968\n",
      "Epoch 11/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.4048e-04 - rmse: 0.0063 - r_square: 0.9863 - val_loss: 2.2711e-05 - val_rmse: 0.0028 - val_r_square: 0.9978\n",
      "Epoch 12/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3878e-04 - rmse: 0.0063 - r_square: 0.9865 - val_loss: 4.9823e-05 - val_rmse: 0.0042 - val_r_square: 0.9951\n",
      "Epoch 13/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3997e-04 - rmse: 0.0063 - r_square: 0.9865 - val_loss: 2.2871e-05 - val_rmse: 0.0031 - val_r_square: 0.9978\n",
      "Epoch 14/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3890e-04 - rmse: 0.0063 - r_square: 0.9866 - val_loss: 2.8437e-05 - val_rmse: 0.0031 - val_r_square: 0.9972\n",
      "Epoch 15/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3886e-04 - rmse: 0.0063 - r_square: 0.9866 - val_loss: 4.6313e-05 - val_rmse: 0.0037 - val_r_square: 0.9955\n",
      "Epoch 16/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3810e-04 - rmse: 0.0063 - r_square: 0.9866 - val_loss: 3.4796e-05 - val_rmse: 0.0039 - val_r_square: 0.9966\n",
      "Epoch 17/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3675e-04 - rmse: 0.0063 - r_square: 0.9867 - val_loss: 3.2676e-05 - val_rmse: 0.0033 - val_r_square: 0.9968\n",
      "Epoch 18/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3519e-04 - rmse: 0.0062 - r_square: 0.9869 - val_loss: 2.9780e-05 - val_rmse: 0.0034 - val_r_square: 0.9971\n",
      "Epoch 19/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3764e-04 - rmse: 0.0063 - r_square: 0.9867 - val_loss: 2.0826e-05 - val_rmse: 0.0031 - val_r_square: 0.9979\n",
      "Epoch 20/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3642e-04 - rmse: 0.0062 - r_square: 0.9868 - val_loss: 2.5982e-05 - val_rmse: 0.0032 - val_r_square: 0.9975\n",
      "Epoch 21/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3337e-04 - rmse: 0.0062 - r_square: 0.9871 - val_loss: 1.7012e-05 - val_rmse: 0.0024 - val_r_square: 0.9983\n",
      "Epoch 22/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3323e-04 - rmse: 0.0062 - r_square: 0.9871 - val_loss: 2.0682e-05 - val_rmse: 0.0027 - val_r_square: 0.9980\n",
      "Epoch 23/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3118e-04 - rmse: 0.0061 - r_square: 0.9873 - val_loss: 6.5358e-05 - val_rmse: 0.0050 - val_r_square: 0.9937\n",
      "Epoch 24/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3081e-04 - rmse: 0.0062 - r_square: 0.9874 - val_loss: 1.6162e-05 - val_rmse: 0.0025 - val_r_square: 0.9984\n",
      "Epoch 25/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3787e-04 - rmse: 0.0062 - r_square: 0.9867 - val_loss: 2.1108e-05 - val_rmse: 0.0030 - val_r_square: 0.9979\n",
      "Epoch 26/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3559e-04 - rmse: 0.0062 - r_square: 0.9869 - val_loss: 2.0384e-05 - val_rmse: 0.0026 - val_r_square: 0.9980\n",
      "Epoch 27/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3700e-04 - rmse: 0.0062 - r_square: 0.9868 - val_loss: 4.9509e-05 - val_rmse: 0.0036 - val_r_square: 0.9952\n",
      "Epoch 28/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3322e-04 - rmse: 0.0062 - r_square: 0.9871 - val_loss: 3.2363e-05 - val_rmse: 0.0041 - val_r_square: 0.9968\n",
      "Epoch 29/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3616e-04 - rmse: 0.0062 - r_square: 0.9868 - val_loss: 2.0056e-05 - val_rmse: 0.0026 - val_r_square: 0.9980\n",
      "Epoch 30/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3418e-04 - rmse: 0.0062 - r_square: 0.9870 - val_loss: 2.2568e-05 - val_rmse: 0.0028 - val_r_square: 0.9978\n",
      "Epoch 31/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3481e-04 - rmse: 0.0062 - r_square: 0.9869 - val_loss: 3.8189e-05 - val_rmse: 0.0042 - val_r_square: 0.9962 - rmse: 0.0062 - r_square\n",
      "Epoch 32/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3763e-04 - rmse: 0.0063 - r_square: 0.9866 - val_loss: 4.9051e-05 - val_rmse: 0.0045 - val_r_square: 0.9952\n",
      "Epoch 33/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3255e-04 - rmse: 0.0062 - r_square: 0.9871 - val_loss: 2.9888e-05 - val_rmse: 0.0038 - val_r_square: 0.9971\n",
      "Epoch 34/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3392e-04 - rmse: 0.0062 - r_square: 0.9870 - val_loss: 1.8004e-05 - val_rmse: 0.0023 - val_r_square: 0.9982\n",
      "Epoch 35/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3508e-04 - rmse: 0.0062 - r_square: 0.9869 - val_loss: 1.8456e-05 - val_rmse: 0.0029 - val_r_square: 0.9982\n",
      "Epoch 36/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3269e-04 - rmse: 0.0062 - r_square: 0.9872 - val_loss: 1.8740e-05 - val_rmse: 0.0030 - val_r_square: 0.9982\n",
      "Epoch 37/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3235e-04 - rmse: 0.0061 - r_square: 0.9872 - val_loss: 2.3295e-05 - val_rmse: 0.0036 - val_r_square: 0.9977\n",
      "Epoch 38/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3252e-04 - rmse: 0.0061 - r_square: 0.9871 - val_loss: 2.4852e-05 - val_rmse: 0.0029 - val_r_square: 0.99760.0062 - r_square - ETA: 2s - loss: 1.3425\n",
      "Epoch 39/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3056e-04 - rmse: 0.0061 - r_square: 0.9874 - val_loss: 1.8560e-05 - val_rmse: 0.0025 - val_r_square: 0.9982\n",
      "Epoch 40/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3194e-04 - rmse: 0.0062 - r_square: 0.9872 - val_loss: 2.6519e-05 - val_rmse: 0.0028 - val_r_square: 0.9974\n",
      "Epoch 41/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3513e-04 - rmse: 0.0062 - r_square: 0.9870 - val_loss: 4.3368e-05 - val_rmse: 0.0040 - val_r_square: 0.9958\n",
      "Epoch 42/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3178e-04 - rmse: 0.0061 - r_square: 0.9872 - val_loss: 3.0070e-05 - val_rmse: 0.0034 - val_r_square: 0.9971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3702e-04 - rmse: 0.0062 - r_square: 0.9868 - val_loss: 2.2971e-05 - val_rmse: 0.0028 - val_r_square: 0.9978\n",
      "Epoch 44/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3207e-04 - rmse: 0.0061 - r_square: 0.9871 - val_loss: 2.2472e-05 - val_rmse: 0.0029 - val_r_square: 0.9978\n",
      "Epoch 45/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3419e-04 - rmse: 0.0062 - r_square: 0.9869 - val_loss: 5.2184e-05 - val_rmse: 0.0043 - val_r_square: 0.9949\n",
      "Epoch 46/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3525e-04 - rmse: 0.0062 - r_square: 0.9869 - val_loss: 5.2180e-05 - val_rmse: 0.0047 - val_r_square: 0.9949\n",
      "Epoch 47/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3321e-04 - rmse: 0.0061 - r_square: 0.9872 - val_loss: 1.8973e-05 - val_rmse: 0.0025 - val_r_square: 0.9982\n",
      "Epoch 48/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3168e-04 - rmse: 0.0061 - r_square: 0.9872 - val_loss: 2.7491e-05 - val_rmse: 0.0035 - val_r_square: 0.9973\n",
      "Epoch 49/200\n",
      "1247590/1247590 [==============================] - 6s 5us/step - loss: 1.3369e-04 - rmse: 0.0061 - r_square: 0.9869 - val_loss: 1.8239e-05 - val_rmse: 0.0025 - val_r_square: 0.9982\n",
      "Epoch 00049: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model3 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model3.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result3 = model3.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.3860190e-02]\n",
      " [ 2.1948852e-02]\n",
      " [ 1.5370960e+00]\n",
      " [ 1.3288963e+00]\n",
      " [ 7.9244830e-02]\n",
      " [ 1.2244590e+01]\n",
      " [ 2.9527538e+01]\n",
      " [ 8.7078705e+00]\n",
      " [ 9.0483189e+00]\n",
      " [ 4.7312302e+01]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.340313\n",
      "Mean squared error (MSE):       0.346584\n",
      "Root mean squared error (RMSE): 0.588714\n",
      "R square (R^2):                 0.998315\n"
     ]
    }
   ],
   "source": [
    "predictions3 = model3.predict(X_test)\n",
    "pre_act3 = sc.inverse_transform(predictions3)\n",
    "print(pre_act3[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act3))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act3))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act3)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference: \n",
    "&emsp;&emsp;What does 'Accuracy' mean in Regression? https://github.com/keras-team/keras/issues/7947 <br>\n",
    "&emsp;&emsp;https://keras.io/metrics/<br>\n",
    "&emsp;&emsp;Scale, Standardize, or Normalize with Scikit-Learn https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02 <br>\n",
    "&emsp;&emsp;The Day my Computer Won the Nobel Prize (Neural Network Option Pricing)  https://medium.com/datadriveninvestor/the-day-my-computer-won-the-nobel-prize-neural-network-option-pricing-d29b4379f1d2 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
