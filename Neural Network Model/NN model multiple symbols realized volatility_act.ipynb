{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl (1.4MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-19.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: pyyaml in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.11.0)\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/4a/5c86ed8b245aa48f9f819b13a0a9039e9126ba19fdd0c7e0b8026c12315a/tensorflow-1.14.0-cp36-cp36m-win_amd64.whl (68.3MB)\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/ed/e036d31a9b2c750f270cbb1cfc1c0f94ac78ae504eea7eec3267be4e294a/numpy-1.16.4-cp36-cp36m-win_amd64.whl (11.9MB)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.1)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/59/ec6c6075dd628f2efd33dbe11b259e63e1de7cbc26e45b38de767df528d4/protobuf-3.8.0-cp36-cp36m-win_amd64.whl (1.1MB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/93/297ff3656f1073fba84e2f9633ad3b27a007eb59ad22099ac30142f80365/grpcio-1.22.0-cp36-cp36m-win_amd64.whl (1.6MB)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.0.8)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.0)\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Requirement already satisfied: setuptools in c:\\program files\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Building wheels for collected packages: gast, absl-py, termcolor, wrapt\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\ee\\98\\38\\46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\d7\\de\\2e\\efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "Successfully built gast absl-py termcolor wrapt\n",
      "Installing collected packages: numpy, google-pasta, gast, absl-py, tensorflow-estimator, protobuf, grpcio, markdown, tensorboard, astor, termcolor, wrapt, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.22.0 markdown-3.1.1 numpy-1.16.4 protobuf-3.8.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.11.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "!pip install --user keras\n",
    "!pip install --user tensorflow\n",
    "!pip install --user -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CPU only\n",
    "# Only Macbook needs to run this cell\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and do data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>exdate</th>\n",
       "      <th>maturity</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>volatility</th>\n",
       "      <th>underlying_price</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>cp_flag_C</th>\n",
       "      <th>cp_flag_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.170513</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.170513</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.170513</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.170513</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.170513</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date      exdate  maturity  strike_price  best_offer  \\\n",
       "0    AXP  2013-01-02  2013-01-04         2          40.0        20.4   \n",
       "1    AXP  2013-01-02  2013-01-04         2          44.0        15.4   \n",
       "2    AXP  2013-01-02  2013-01-04         2          45.0        14.4   \n",
       "3    AXP  2013-01-02  2013-01-04         2          46.0        13.4   \n",
       "4    AXP  2013-01-02  2013-01-04         2          47.0        12.4   \n",
       "\n",
       "   volatility  underlying_price  interest_rate  cp_flag_C  cp_flag_P  \n",
       "0    0.170513             58.75         0.0008          1          0  \n",
       "1    0.170513             58.75         0.0008          1          0  \n",
       "2    0.170513             58.75         0.0008          1          0  \n",
       "3    0.170513             58.75         0.0008          1          0  \n",
       "4    0.170513             58.75         0.0008          1          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Options_R.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['volatility'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['best_offer'].values\n",
    "X = df[['maturity', 'strike_price', 'underlying_price', 'volatility', 'cp_flag_C', 'cp_flag_P', 'interest_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to build a regression neural network model\n",
    "sc= preprocessing.MinMaxScaler()\n",
    "X= sc.fit_transform(X)\n",
    "y= y.reshape(-1,1)\n",
    "y=sc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1079819, 7)\n",
      "(1079819, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train, XX_validation, yy_train, yy_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 20:54:55.305389  8584 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0703 20:54:55.320410  8584 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0703 20:54:55.325403  8584 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Built Keras sequential model with 3 hidden layer, and after the first hidden layer.\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable early stopping based on the loss of validation data\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is a simple regression problem, we should custom metrics function\n",
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1))\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 20:55:01.351735  8584 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use mean_squared_error to compile regression model loss\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 20:55:04.486424  8584 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0703 20:55:04.570343  8584 deprecation_wrapper.py:119] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 863855 samples, validate on 215964 samples\n",
      "Epoch 1/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.6444e-04 - rmse: 0.0056 - r_square: 0.9876 - val_loss: 2.5155e-05 - val_rmse: 0.0038 - val_r_square: 0.9981\n",
      "Epoch 2/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 2.3841e-05 - rmse: 0.0035 - r_square: 0.9982 - val_loss: 1.5990e-05 - val_rmse: 0.0029 - val_r_square: 0.9988\n",
      "Epoch 3/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 2.0503e-05 - rmse: 0.0032 - r_square: 0.9984 - val_loss: 1.7168e-05 - val_rmse: 0.0029 - val_r_square: 0.9987\n",
      "Epoch 4/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.8513e-05 - rmse: 0.0030 - r_square: 0.9986 - val_loss: 1.4049e-05 - val_rmse: 0.0024 - val_r_square: 0.9989\n",
      "Epoch 5/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.7200e-05 - rmse: 0.0029 - r_square: 0.9987 - val_loss: 1.4151e-05 - val_rmse: 0.0024 - val_r_square: 0.9989\n",
      "Epoch 6/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.6344e-05 - rmse: 0.0028 - r_square: 0.9987 - val_loss: 1.3761e-05 - val_rmse: 0.0024 - val_r_square: 0.9990\n",
      "Epoch 7/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.5712e-05 - rmse: 0.0027 - r_square: 0.9988 - val_loss: 1.4882e-05 - val_rmse: 0.0024 - val_r_square: 0.9989\n",
      "Epoch 8/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.5049e-05 - rmse: 0.0026 - r_square: 0.9988 - val_loss: 1.2666e-05 - val_rmse: 0.0023 - val_r_square: 0.9990\n",
      "Epoch 9/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.4494e-05 - rmse: 0.0025 - r_square: 0.9989 - val_loss: 1.2870e-05 - val_rmse: 0.0023 - val_r_square: 0.9990\n",
      "Epoch 10/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.4219e-05 - rmse: 0.0025 - r_square: 0.9989 - val_loss: 1.2180e-05 - val_rmse: 0.0023 - val_r_square: 0.9991\n",
      "Epoch 11/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.3820e-05 - rmse: 0.0025 - r_square: 0.9989 - val_loss: 1.6146e-05 - val_rmse: 0.0025 - val_r_square: 0.9988\n",
      "Epoch 12/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.3735e-05 - rmse: 0.0025 - r_square: 0.9989 - val_loss: 1.2520e-05 - val_rmse: 0.0024 - val_r_square: 0.9991\n",
      "Epoch 13/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.3347e-05 - rmse: 0.0024 - r_square: 0.9990 - val_loss: 1.4263e-05 - val_rmse: 0.0024 - val_r_square: 0.9989\n",
      "Epoch 14/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.3206e-05 - rmse: 0.0024 - r_square: 0.9990 - val_loss: 1.3708e-05 - val_rmse: 0.0025 - val_r_square: 0.9990\n",
      "Epoch 15/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.3076e-05 - rmse: 0.0024 - r_square: 0.9990 - val_loss: 1.5115e-05 - val_rmse: 0.0026 - val_r_square: 0.9989\n",
      "Epoch 16/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.2916e-05 - rmse: 0.0024 - r_square: 0.9990 - val_loss: 1.1198e-05 - val_rmse: 0.0022 - val_r_square: 0.9991\n",
      "Epoch 17/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.2574e-05 - rmse: 0.0023 - r_square: 0.9990 - val_loss: 1.2710e-05 - val_rmse: 0.0022 - val_r_square: 0.9990\n",
      "Epoch 18/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.2432e-05 - rmse: 0.0023 - r_square: 0.9990 - val_loss: 1.5356e-05 - val_rmse: 0.0027 - val_r_square: 0.9988\n",
      "Epoch 19/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.2300e-05 - rmse: 0.0023 - r_square: 0.9991 - val_loss: 1.2254e-05 - val_rmse: 0.0022 - val_r_square: 0.9991\n",
      "Epoch 20/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.2323e-05 - rmse: 0.0023 - r_square: 0.9991 - val_loss: 1.1652e-05 - val_rmse: 0.0024 - val_r_square: 0.9991\n",
      "Epoch 21/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.2222e-05 - rmse: 0.0023 - r_square: 0.9991 - val_loss: 1.3179e-05 - val_rmse: 0.0024 - val_r_square: 0.9990\n",
      "Epoch 22/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.2035e-05 - rmse: 0.0023 - r_square: 0.9991 - val_loss: 1.0410e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 23/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1758e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.0959e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 24/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1817e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.1746e-05 - val_rmse: 0.0023 - val_r_square: 0.9991\n",
      "Epoch 25/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1724e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.3227e-05 - val_rmse: 0.0023 - val_r_square: 0.9990\n",
      "Epoch 26/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1682e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.1905e-05 - val_rmse: 0.0022 - val_r_square: 0.9991\n",
      "Epoch 27/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1519e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.8624e-05 - val_rmse: 0.0028 - val_r_square: 0.9986\n",
      "Epoch 28/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1505e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.1197e-05 - val_rmse: 0.0022 - val_r_square: 0.9992\n",
      "Epoch 29/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1372e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.4258e-05 - val_rmse: 0.0024 - val_r_square: 0.9989\n",
      "Epoch 30/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1355e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.1083e-05 - val_rmse: 0.0023 - val_r_square: 0.9992\n",
      "Epoch 31/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1260e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.2037e-05 - val_rmse: 0.0024 - val_r_square: 0.9991\n",
      "Epoch 32/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1337e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.0015e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 33/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1103e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.8856e-05 - val_rmse: 0.0032 - val_r_square: 0.9986\n",
      "Epoch 34/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1142e-05 - rmse: 0.0022 - r_square: 0.9991 - val_loss: 1.1537e-05 - val_rmse: 0.0022 - val_r_square: 0.9991\n",
      "Epoch 35/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.1028e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0711e-05 - val_rmse: 0.0022 - val_r_square: 0.9992\n",
      "Epoch 36/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0995e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0505e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 37/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0945e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.1273e-05 - val_rmse: 0.0023 - val_r_square: 0.9991\n",
      "Epoch 38/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0981e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0112e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 39/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0912e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0047e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 40/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0906e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.4360e-05 - val_rmse: 0.0024 - val_r_square: 0.9989\n",
      "Epoch 41/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0741e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0087e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 42/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0767e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0712e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0667e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0648e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 44/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0667e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 9.6013e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 45/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0657e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0146e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 46/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0537e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.2308e-05 - val_rmse: 0.0024 - val_r_square: 0.9991\n",
      "Epoch 47/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0641e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0303e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 48/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0626e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0526e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 49/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0447e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.1329e-05 - val_rmse: 0.0021 - val_r_square: 0.9991\n",
      "Epoch 50/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0487e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.4915e-05 - val_rmse: 0.0025 - val_r_square: 0.9989\n",
      "Epoch 51/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0458e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 9.7343e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 52/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0414e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.1646e-05 - val_rmse: 0.0021 - val_r_square: 0.9991\n",
      "Epoch 53/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0422e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0365e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 54/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0387e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.1165e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 55/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0382e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0598e-05 - val_rmse: 0.0022 - val_r_square: 0.9992\n",
      "Epoch 56/200\n",
      "863855/863855 [==============================] - 4s 4us/step - loss: 1.0321e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.1048e-05 - val_rmse: 0.0022 - val_r_square: 0.9992\n",
      "Epoch 57/200\n",
      "863855/863855 [==============================] - 4s 4us/step - loss: 1.0235e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.0284e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 58/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0210e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 9.9363e-06 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 59/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0205e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 9.8956e-06 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 60/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0274e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 9.5413e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 61/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0154e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.2657e-05 - val_rmse: 0.0024 - val_r_square: 0.9990\n",
      "Epoch 62/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0222e-05 - rmse: 0.0021 - r_square: 0.9992 - val_loss: 1.4049e-05 - val_rmse: 0.0025 - val_r_square: 0.9989\n",
      "Epoch 63/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0093e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.8334e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 64/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0096e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.6331e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 65/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0087e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.7054e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 66/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.0158e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.8724e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 67/200\n",
      "863855/863855 [==============================] - 6s 7us/step - loss: 1.0072e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.2385e-05 - val_rmse: 0.0023 - val_r_square: 0.9991\n",
      "Epoch 68/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.0140e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.0220e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 69/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 9.9810e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.1893e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 70/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.0057e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.2052e-05 - val_rmse: 0.0024 - val_r_square: 0.9991\n",
      "Epoch 71/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.0054e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.0922e-05 - val_rmse: 0.0022 - val_r_square: 0.9992\n",
      "Epoch 72/200\n",
      "863855/863855 [==============================] - 7s 8us/step - loss: 1.0007e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.2385e-05 - val_rmse: 0.0023 - val_r_square: 0.9991\n",
      "Epoch 73/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0012e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.0138e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 74/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0014e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.2356e-05 - val_rmse: 0.0023 - val_r_square: 0.9991\n",
      "Epoch 75/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.8619e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.3992e-05 - val_rmse: 0.0024 - val_r_square: 0.9989\n",
      "Epoch 76/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 1.0017e-05 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.6099e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 77/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.9320e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.0756e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 78/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.8974e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 1.0381e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 79/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.8881e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.2161e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 80/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.8292e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.4782e-06 - val_rmse: 0.0021 - val_r_square: 0.9993\n",
      "Epoch 81/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.8148e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 8.8052e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 82/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.8431e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.6315e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 83/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.7850e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.0320e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 84/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.7915e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.7049e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 85/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.8223e-06 - rmse: 0.0020 - r_square: 0.9992 - val_loss: 9.3630e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.7631e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 8.6737e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 87/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.7618e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.2664e-05 - val_rmse: 0.0023 - val_r_square: 0.9990\n",
      "Epoch 88/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6812e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.6972e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 89/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.7085e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.1482e-05 - val_rmse: 0.0022 - val_r_square: 0.9991\n",
      "Epoch 90/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.7494e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.1944e-05 - val_rmse: 0.0022 - val_r_square: 0.9991\n",
      "Epoch 91/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6857e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.1364e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 92/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.7081e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.0146e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 93/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6228e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.1527e-05 - val_rmse: 0.0021 - val_r_square: 0.9991\n",
      "Epoch 94/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6617e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.0737e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 95/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6761e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.1511e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 96/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6160e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.7091e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 97/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6152e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.0440e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 98/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6295e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.0871e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 99/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.5740e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.2632e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 100/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.5889e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.1401e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 101/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6169e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.0349e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 102/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6007e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.0403e-05 - val_rmse: 0.0021 - val_r_square: 0.9992\n",
      "Epoch 103/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.6078e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.0813e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 104/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.5934e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.1858e-05 - val_rmse: 0.0023 - val_r_square: 0.9991\n",
      "Epoch 105/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.4735e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.1164e-05 - val_rmse: 0.0023 - val_r_square: 0.9992\n",
      "Epoch 106/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.5840e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.5046e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 107/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.5809e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.0181e-05 - val_rmse: 0.0020 - val_r_square: 0.9992\n",
      "Epoch 108/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.5311e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.2941e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 109/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.4755e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 8.7424e-06 - val_rmse: 0.0019 - val_r_square: 0.9993\n",
      "Epoch 110/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 9.4891e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 1.0876e-05 - val_rmse: 0.0023 - val_r_square: 0.9992\n",
      "Epoch 111/200\n",
      "863855/863855 [==============================] - 4s 5us/step - loss: 9.4876e-06 - rmse: 0.0020 - r_square: 0.9993 - val_loss: 9.7643e-06 - val_rmse: 0.0020 - val_r_square: 0.9993\n",
      "Epoch 00111: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "result = model.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9878725e-01]\n",
      " [8.0572510e+00]\n",
      " [4.3696209e+01]\n",
      " [1.3325646e+01]\n",
      " [1.5871577e+00]\n",
      " [9.5909962e-04]\n",
      " [5.8215833e+00]\n",
      " [4.6672096e+00]\n",
      " [9.6788549e+00]\n",
      " [1.8222956e+01]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "pre_act = sc.inverse_transform(predictions)\n",
    "print(pre_act[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_act = sc.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.400e-01],\n",
       "       [7.600e+00],\n",
       "       [4.435e+01],\n",
       "       [1.425e+01],\n",
       "       [1.760e+00],\n",
       "       [3.000e-02],\n",
       "       [5.500e+00],\n",
       "       [4.500e+00],\n",
       "       [9.350e+00],\n",
       "       [1.795e+01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_act[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curves including R^2 and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for rmse\n",
    "plt.plot(result.history['rmse'])\n",
    "plt.plot(result.history['val_rmse'])\n",
    "plt.title('rmse')\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for R^2\n",
    "plt.plot(result.history['r_square'])\n",
    "plt.plot(result.history['val_r_square'])\n",
    "plt.title('model R^2')\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.277239\n",
      "Mean squared error (MSE):       0.187401\n",
      "Root mean squared error (RMSE): 0.432898\n",
      "R square (R^2):                 0.999290\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm, math\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 21:07:57.700560  8584 deprecation.py:506] From C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 863855 samples, validate on 215964 samples\n",
      "Epoch 1/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 6.3613e-04 - rmse: 0.0129 - r_square: 0.9520 - val_loss: 1.5197e-04 - val_rmse: 0.0080 - val_r_square: 0.9887\n",
      "Epoch 2/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 5.7282e-05 - rmse: 0.0049 - r_square: 0.9957 - val_loss: 1.9159e-04 - val_rmse: 0.0076 - val_r_square: 0.9859\n",
      "Epoch 3/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 3.1524e-05 - rmse: 0.0037 - r_square: 0.9976 - val_loss: 2.2923e-04 - val_rmse: 0.0086 - val_r_square: 0.9831\n",
      "Epoch 4/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.6084e-05 - rmse: 0.0034 - r_square: 0.9980 - val_loss: 1.9561e-04 - val_rmse: 0.0080 - val_r_square: 0.9856\n",
      "Epoch 5/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.3394e-05 - rmse: 0.0032 - r_square: 0.9982 - val_loss: 2.4516e-04 - val_rmse: 0.0088 - val_r_square: 0.9819\n",
      "Epoch 6/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.1403e-05 - rmse: 0.0030 - r_square: 0.9984 - val_loss: 2.8163e-04 - val_rmse: 0.0094 - val_r_square: 0.9792\n",
      "Epoch 7/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0166e-05 - rmse: 0.0029 - r_square: 0.9985 - val_loss: 2.3112e-04 - val_rmse: 0.0086 - val_r_square: 0.9830\n",
      "Epoch 8/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9425e-05 - rmse: 0.0029 - r_square: 0.9985 - val_loss: 1.9782e-04 - val_rmse: 0.0076 - val_r_square: 0.9855\n",
      "Epoch 9/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8781e-05 - rmse: 0.0028 - r_square: 0.9986 - val_loss: 1.8724e-04 - val_rmse: 0.0073 - val_r_square: 0.9862\n",
      "Epoch 10/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8352e-05 - rmse: 0.0028 - r_square: 0.9986 - val_loss: 2.5841e-04 - val_rmse: 0.0093 - val_r_square: 0.9809\n",
      "Epoch 11/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8006e-05 - rmse: 0.0028 - r_square: 0.9986 - val_loss: 1.9958e-04 - val_rmse: 0.0079 - val_r_square: 0.9853\n",
      "Epoch 12/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.7701e-05 - rmse: 0.0027 - r_square: 0.9986 - val_loss: 1.9256e-04 - val_rmse: 0.0076 - val_r_square: 0.9858\n",
      "Epoch 13/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.7270e-05 - rmse: 0.0027 - r_square: 0.9987 - val_loss: 1.8807e-04 - val_rmse: 0.0074 - val_r_square: 0.9862\n",
      "Epoch 14/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.6973e-05 - rmse: 0.0027 - r_square: 0.9987 - val_loss: 1.9714e-04 - val_rmse: 0.0078 - val_r_square: 0.9855\n",
      "Epoch 15/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.6724e-05 - rmse: 0.0026 - r_square: 0.9987 - val_loss: 2.4670e-04 - val_rmse: 0.0086 - val_r_square: 0.9818\n",
      "Epoch 16/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.6782e-05 - rmse: 0.0026 - r_square: 0.9987 - val_loss: 2.2376e-04 - val_rmse: 0.0084 - val_r_square: 0.9835\n",
      "Epoch 17/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.6320e-05 - rmse: 0.0026 - r_square: 0.9988 - val_loss: 2.6165e-04 - val_rmse: 0.0090 - val_r_square: 0.9807\n",
      "Epoch 18/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.6407e-05 - rmse: 0.0026 - r_square: 0.9987 - val_loss: 2.2808e-04 - val_rmse: 0.0084 - val_r_square: 0.9832\n",
      "Epoch 19/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.6174e-05 - rmse: 0.0026 - r_square: 0.9988 - val_loss: 2.5256e-04 - val_rmse: 0.0088 - val_r_square: 0.9814\n",
      "Epoch 20/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.5996e-05 - rmse: 0.0026 - r_square: 0.9988 - val_loss: 2.1630e-04 - val_rmse: 0.0080 - val_r_square: 0.9841\n",
      "Epoch 21/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.5719e-05 - rmse: 0.0025 - r_square: 0.9988 - val_loss: 2.2170e-04 - val_rmse: 0.0081 - val_r_square: 0.9837\n",
      "Epoch 22/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.5625e-05 - rmse: 0.0025 - r_square: 0.9988 - val_loss: 2.6953e-04 - val_rmse: 0.0093 - val_r_square: 0.9801\n",
      "Epoch 23/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.5425e-05 - rmse: 0.0025 - r_square: 0.9988 - val_loss: 2.3360e-04 - val_rmse: 0.0084 - val_r_square: 0.9828\n",
      "Epoch 24/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.5395e-05 - rmse: 0.0025 - r_square: 0.9988 - val_loss: 2.6819e-04 - val_rmse: 0.0092 - val_r_square: 0.9802\n",
      "Epoch 25/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.5278e-05 - rmse: 0.0025 - r_square: 0.9988 - val_loss: 2.2599e-04 - val_rmse: 0.0082 - val_r_square: 0.9834\n",
      "Epoch 26/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.5076e-05 - rmse: 0.0025 - r_square: 0.9988 - val_loss: 1.9811e-04 - val_rmse: 0.0077 - val_r_square: 0.9854\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model2.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result2 = model2.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.84491634]\n",
      " [ 6.4803762 ]\n",
      " [40.58042   ]\n",
      " [11.621701  ]\n",
      " [ 1.5075382 ]\n",
      " [ 0.09726154]\n",
      " [ 5.584685  ]\n",
      " [ 4.2508855 ]\n",
      " [ 8.1683655 ]\n",
      " [16.12794   ]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      1.070542\n",
      "Mean squared error (MSE):       3.806763\n",
      "Root mean squared error (RMSE): 1.951093\n",
      "R square (R^2):                 0.985587\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model2.predict(X_test)\n",
    "pre_act2 = sc.inverse_transform(predictions2)\n",
    "print(pre_act2[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act2))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act2))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act2)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try batch normalization technique to regularize neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 863855 samples, validate on 215964 samples\n",
      "Epoch 1/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 4.4561e-04 - rmse: 0.0133 - r_square: 0.9662 - val_loss: 6.8910e-05 - val_rmse: 0.0056 - val_r_square: 0.9948\n",
      "Epoch 2/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.5730e-04 - rmse: 0.0097 - r_square: 0.9807 - val_loss: 6.6448e-05 - val_rmse: 0.0060 - val_r_square: 0.9950\n",
      "Epoch 3/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.1984e-04 - rmse: 0.0089 - r_square: 0.9834 - val_loss: 4.8273e-05 - val_rmse: 0.0051 - val_r_square: 0.9963\n",
      "Epoch 4/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.2071e-04 - rmse: 0.0087 - r_square: 0.9834 - val_loss: 4.2584e-05 - val_rmse: 0.0050 - val_r_square: 0.9968\n",
      "Epoch 5/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.1969e-04 - rmse: 0.0086 - r_square: 0.9835 - val_loss: 3.7960e-05 - val_rmse: 0.0043 - val_r_square: 0.9971\n",
      "Epoch 6/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0971e-04 - rmse: 0.0084 - r_square: 0.9842 - val_loss: 1.8454e-04 - val_rmse: 0.0093 - val_r_square: 0.9861\n",
      "Epoch 7/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0521e-04 - rmse: 0.0082 - r_square: 0.9846 - val_loss: 7.5393e-05 - val_rmse: 0.0051 - val_r_square: 0.9943\n",
      "Epoch 8/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0671e-04 - rmse: 0.0083 - r_square: 0.9843 - val_loss: 4.5815e-05 - val_rmse: 0.0051 - val_r_square: 0.9965\n",
      "Epoch 9/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0749e-04 - rmse: 0.0083 - r_square: 0.9843 - val_loss: 6.9451e-05 - val_rmse: 0.0049 - val_r_square: 0.9948\n",
      "Epoch 10/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0217e-04 - rmse: 0.0082 - r_square: 0.9848 - val_loss: 2.7471e-05 - val_rmse: 0.0035 - val_r_square: 0.9979\n",
      "Epoch 11/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0455e-04 - rmse: 0.0082 - r_square: 0.9846 - val_loss: 4.3886e-05 - val_rmse: 0.0054 - val_r_square: 0.9967\n",
      "Epoch 12/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0260e-04 - rmse: 0.0081 - r_square: 0.9849 - val_loss: 2.1481e-05 - val_rmse: 0.0031 - val_r_square: 0.9984\n",
      "Epoch 13/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 2.0126e-04 - rmse: 0.0081 - r_square: 0.9849 - val_loss: 3.7204e-05 - val_rmse: 0.0040 - val_r_square: 0.9972\n",
      "Epoch 14/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9591e-04 - rmse: 0.0079 - r_square: 0.9853 - val_loss: 3.3154e-05 - val_rmse: 0.0034 - val_r_square: 0.9975\n",
      "Epoch 15/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9856e-04 - rmse: 0.0080 - r_square: 0.9850 - val_loss: 2.0320e-05 - val_rmse: 0.0029 - val_r_square: 0.9985\n",
      "Epoch 16/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9888e-04 - rmse: 0.0080 - r_square: 0.9850 - val_loss: 3.1302e-05 - val_rmse: 0.0037 - val_r_square: 0.9976\n",
      "Epoch 17/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9725e-04 - rmse: 0.0080 - r_square: 0.9850 - val_loss: 2.6874e-05 - val_rmse: 0.0034 - val_r_square: 0.9980\n",
      "Epoch 18/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9909e-04 - rmse: 0.0080 - r_square: 0.9849 - val_loss: 3.1332e-05 - val_rmse: 0.0036 - val_r_square: 0.9976\n",
      "Epoch 19/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9397e-04 - rmse: 0.0079 - r_square: 0.9853 - val_loss: 1.9572e-05 - val_rmse: 0.0028 - val_r_square: 0.9985\n",
      "Epoch 20/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9505e-04 - rmse: 0.0079 - r_square: 0.9853 - val_loss: 3.4428e-05 - val_rmse: 0.0040 - val_r_square: 0.9974\n",
      "Epoch 21/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9462e-04 - rmse: 0.0079 - r_square: 0.9852 - val_loss: 5.6501e-05 - val_rmse: 0.0044 - val_r_square: 0.9958\n",
      "Epoch 22/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9627e-04 - rmse: 0.0079 - r_square: 0.9852 - val_loss: 4.2460e-05 - val_rmse: 0.0039 - val_r_square: 0.9968\n",
      "Epoch 23/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9621e-04 - rmse: 0.0080 - r_square: 0.9853 - val_loss: 3.5968e-05 - val_rmse: 0.0036 - val_r_square: 0.9973\n",
      "Epoch 24/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9705e-04 - rmse: 0.0079 - r_square: 0.9851 - val_loss: 6.7737e-05 - val_rmse: 0.0049 - val_r_square: 0.9950\n",
      "Epoch 25/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9636e-04 - rmse: 0.0079 - r_square: 0.9852 - val_loss: 2.1183e-05 - val_rmse: 0.0029 - val_r_square: 0.9984\n",
      "Epoch 26/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9437e-04 - rmse: 0.0079 - r_square: 0.9854 - val_loss: 4.6397e-05 - val_rmse: 0.0040 - val_r_square: 0.9965\n",
      "Epoch 27/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9825e-04 - rmse: 0.0080 - r_square: 0.9850 - val_loss: 3.1214e-05 - val_rmse: 0.0036 - val_r_square: 0.9976\n",
      "Epoch 28/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9340e-04 - rmse: 0.0079 - r_square: 0.9854 - val_loss: 4.3302e-05 - val_rmse: 0.0041 - val_r_square: 0.9967\n",
      "Epoch 29/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9698e-04 - rmse: 0.0079 - r_square: 0.9852 - val_loss: 2.5976e-05 - val_rmse: 0.0033 - val_r_square: 0.9981\n",
      "Epoch 30/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9460e-04 - rmse: 0.0079 - r_square: 0.9853 - val_loss: 3.2012e-05 - val_rmse: 0.0034 - val_r_square: 0.9976\n",
      "Epoch 31/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9085e-04 - rmse: 0.0078 - r_square: 0.9856 - val_loss: 3.4487e-05 - val_rmse: 0.0038 - val_r_square: 0.9974\n",
      "Epoch 32/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9747e-04 - rmse: 0.0079 - r_square: 0.9850 - val_loss: 1.8645e-05 - val_rmse: 0.0026 - val_r_square: 0.9986\n",
      "Epoch 33/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9459e-04 - rmse: 0.0079 - r_square: 0.9852 - val_loss: 3.1361e-05 - val_rmse: 0.0033 - val_r_square: 0.9976\n",
      "Epoch 34/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8977e-04 - rmse: 0.0078 - r_square: 0.9856 - val_loss: 3.0168e-05 - val_rmse: 0.0032 - val_r_square: 0.9977\n",
      "Epoch 35/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9448e-04 - rmse: 0.0079 - r_square: 0.9853 - val_loss: 3.4254e-05 - val_rmse: 0.0036 - val_r_square: 0.9974\n",
      "Epoch 36/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8863e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 2.7704e-05 - val_rmse: 0.0033 - val_r_square: 0.9979\n",
      "Epoch 37/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9352e-04 - rmse: 0.0079 - r_square: 0.9854 - val_loss: 2.1914e-05 - val_rmse: 0.0030 - val_r_square: 0.9984\n",
      "Epoch 38/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8816e-04 - rmse: 0.0078 - r_square: 0.9859 - val_loss: 2.2590e-05 - val_rmse: 0.0032 - val_r_square: 0.9983\n",
      "Epoch 39/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9582e-04 - rmse: 0.0079 - r_square: 0.9853 - val_loss: 7.1115e-05 - val_rmse: 0.0060 - val_r_square: 0.9947\n",
      "Epoch 40/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9339e-04 - rmse: 0.0079 - r_square: 0.9853 - val_loss: 9.4138e-05 - val_rmse: 0.0056 - val_r_square: 0.9929\n",
      "Epoch 41/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9138e-04 - rmse: 0.0078 - r_square: 0.9856 - val_loss: 2.0794e-05 - val_rmse: 0.0029 - val_r_square: 0.9984\n",
      "Epoch 42/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9124e-04 - rmse: 0.0078 - r_square: 0.9856 - val_loss: 2.3702e-05 - val_rmse: 0.0032 - val_r_square: 0.9982\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8851e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 7.0527e-05 - val_rmse: 0.0047 - val_r_square: 0.9947\n",
      "Epoch 44/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8842e-04 - rmse: 0.0078 - r_square: 0.9857 - val_loss: 1.8592e-05 - val_rmse: 0.0026 - val_r_square: 0.9986\n",
      "Epoch 45/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8761e-04 - rmse: 0.0077 - r_square: 0.9859 - val_loss: 5.1962e-05 - val_rmse: 0.0041 - val_r_square: 0.9961\n",
      "Epoch 46/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8646e-04 - rmse: 0.0077 - r_square: 0.9859 - val_loss: 1.9350e-05 - val_rmse: 0.0031 - val_r_square: 0.9985\n",
      "Epoch 47/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8911e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 3.2271e-05 - val_rmse: 0.0041 - val_r_square: 0.9976\n",
      "Epoch 48/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9125e-04 - rmse: 0.0078 - r_square: 0.9855 - val_loss: 3.0817e-05 - val_rmse: 0.0035 - val_r_square: 0.9977\n",
      "Epoch 49/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8431e-04 - rmse: 0.0077 - r_square: 0.9861 - val_loss: 3.9181e-05 - val_rmse: 0.0041 - val_r_square: 0.9971\n",
      "Epoch 50/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8976e-04 - rmse: 0.0078 - r_square: 0.9856 - val_loss: 4.8774e-05 - val_rmse: 0.0046 - val_r_square: 0.9963\n",
      "Epoch 51/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8948e-04 - rmse: 0.0078 - r_square: 0.9857 - val_loss: 2.4951e-05 - val_rmse: 0.0030 - val_r_square: 0.9981\n",
      "Epoch 52/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8913e-04 - rmse: 0.0078 - r_square: 0.9857 - val_loss: 3.0990e-05 - val_rmse: 0.0035 - val_r_square: 0.9977\n",
      "Epoch 53/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9275e-04 - rmse: 0.0078 - r_square: 0.9854 - val_loss: 2.8508e-05 - val_rmse: 0.0037 - val_r_square: 0.9979\n",
      "Epoch 54/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8426e-04 - rmse: 0.0077 - r_square: 0.9861 - val_loss: 3.8003e-05 - val_rmse: 0.0037 - val_r_square: 0.9972\n",
      "Epoch 55/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8781e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 2.2996e-05 - val_rmse: 0.0030 - val_r_square: 0.9983\n",
      "Epoch 56/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8434e-04 - rmse: 0.0076 - r_square: 0.9861 - val_loss: 2.5619e-05 - val_rmse: 0.0033 - val_r_square: 0.9981\n",
      "Epoch 57/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8506e-04 - rmse: 0.0077 - r_square: 0.9860 - val_loss: 2.6286e-05 - val_rmse: 0.0036 - val_r_square: 0.9980\n",
      "Epoch 58/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8856e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 3.3006e-05 - val_rmse: 0.0033 - val_r_square: 0.9975\n",
      "Epoch 59/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8358e-04 - rmse: 0.0077 - r_square: 0.9862 - val_loss: 1.9604e-05 - val_rmse: 0.0030 - val_r_square: 0.9985\n",
      "Epoch 60/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8890e-04 - rmse: 0.0078 - r_square: 0.9857 - val_loss: 3.1224e-05 - val_rmse: 0.0036 - val_r_square: 0.9977\n",
      "Epoch 61/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8894e-04 - rmse: 0.0077 - r_square: 0.9856 - val_loss: 3.3742e-05 - val_rmse: 0.0043 - val_r_square: 0.9974\n",
      "Epoch 62/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8754e-04 - rmse: 0.0077 - r_square: 0.9859 - val_loss: 5.3480e-05 - val_rmse: 0.0041 - val_r_square: 0.9960\n",
      "Epoch 63/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8960e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 4.1701e-05 - val_rmse: 0.0038 - val_r_square: 0.9969\n",
      "Epoch 64/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8232e-04 - rmse: 0.0077 - r_square: 0.9862 - val_loss: 3.1274e-05 - val_rmse: 0.0031 - val_r_square: 0.9977\n",
      "Epoch 65/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9382e-04 - rmse: 0.0079 - r_square: 0.9853 - val_loss: 3.1836e-05 - val_rmse: 0.0036 - val_r_square: 0.9976\n",
      "Epoch 66/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.9120e-04 - rmse: 0.0078 - r_square: 0.9855 - val_loss: 6.1351e-05 - val_rmse: 0.0048 - val_r_square: 0.9954\n",
      "Epoch 67/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9382e-04 - rmse: 0.0078 - r_square: 0.9854 - val_loss: 3.9196e-05 - val_rmse: 0.0041 - val_r_square: 0.9971\n",
      "Epoch 68/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8487e-04 - rmse: 0.0076 - r_square: 0.9860 - val_loss: 3.6411e-05 - val_rmse: 0.0034 - val_r_square: 0.9973\n",
      "Epoch 69/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9067e-04 - rmse: 0.0078 - r_square: 0.9856 - val_loss: 1.8191e-05 - val_rmse: 0.0028 - val_r_square: 0.9986\n",
      "Epoch 70/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8404e-04 - rmse: 0.0077 - r_square: 0.9861 - val_loss: 3.3740e-05 - val_rmse: 0.0035 - val_r_square: 0.9975\n",
      "Epoch 71/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8879e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 2.2600e-05 - val_rmse: 0.0031 - val_r_square: 0.9983\n",
      "Epoch 72/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8323e-04 - rmse: 0.0077 - r_square: 0.9861 - val_loss: 3.1616e-05 - val_rmse: 0.0036 - val_r_square: 0.9976\n",
      "Epoch 73/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9176e-04 - rmse: 0.0078 - r_square: 0.9855 - val_loss: 4.0754e-05 - val_rmse: 0.0049 - val_r_square: 0.9969\n",
      "Epoch 74/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8515e-04 - rmse: 0.0077 - r_square: 0.9860 - val_loss: 3.0962e-05 - val_rmse: 0.0038 - val_r_square: 0.9977\n",
      "Epoch 75/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8201e-04 - rmse: 0.0076 - r_square: 0.9863 - val_loss: 2.7600e-05 - val_rmse: 0.0037 - val_r_square: 0.9979\n",
      "Epoch 76/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8704e-04 - rmse: 0.0077 - r_square: 0.9859 - val_loss: 3.3294e-05 - val_rmse: 0.0040 - val_r_square: 0.9975\n",
      "Epoch 77/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8440e-04 - rmse: 0.0077 - r_square: 0.9860 - val_loss: 2.0265e-05 - val_rmse: 0.0030 - val_r_square: 0.9985\n",
      "Epoch 78/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.7748e-04 - rmse: 0.0075 - r_square: 0.9866 - val_loss: 2.4257e-05 - val_rmse: 0.0032 - val_r_square: 0.9982\n",
      "Epoch 79/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8813e-04 - rmse: 0.0077 - r_square: 0.9859 - val_loss: 3.3966e-05 - val_rmse: 0.0036 - val_r_square: 0.9974\n",
      "Epoch 80/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8860e-04 - rmse: 0.0077 - r_square: 0.9858 - val_loss: 2.5048e-05 - val_rmse: 0.0034 - val_r_square: 0.9981\n",
      "Epoch 81/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8748e-04 - rmse: 0.0077 - r_square: 0.9859 - val_loss: 2.7191e-05 - val_rmse: 0.0031 - val_r_square: 0.9980\n",
      "Epoch 82/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.9037e-04 - rmse: 0.0078 - r_square: 0.9856 - val_loss: 2.6724e-05 - val_rmse: 0.0033 - val_r_square: 0.9980\n",
      "Epoch 83/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8443e-04 - rmse: 0.0077 - r_square: 0.9861 - val_loss: 3.9185e-05 - val_rmse: 0.0041 - val_r_square: 0.9971\n",
      "Epoch 84/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8746e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 2.3225e-05 - val_rmse: 0.0031 - val_r_square: 0.9983\n",
      "Epoch 85/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8480e-04 - rmse: 0.0077 - r_square: 0.9862 - val_loss: 2.0660e-05 - val_rmse: 0.0028 - val_r_square: 0.9985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8529e-04 - rmse: 0.0077 - r_square: 0.9861 - val_loss: 3.0196e-05 - val_rmse: 0.0040 - val_r_square: 0.9977\n",
      "Epoch 87/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8795e-04 - rmse: 0.0078 - r_square: 0.9858 - val_loss: 3.5633e-05 - val_rmse: 0.0038 - val_r_square: 0.9973\n",
      "Epoch 88/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8740e-04 - rmse: 0.0077 - r_square: 0.9859 - val_loss: 3.3265e-05 - val_rmse: 0.0033 - val_r_square: 0.9975\n",
      "Epoch 89/200\n",
      "863855/863855 [==============================] - 5s 6us/step - loss: 1.8283e-04 - rmse: 0.0077 - r_square: 0.9861 - val_loss: 4.9943e-05 - val_rmse: 0.0038 - val_r_square: 0.9963\n",
      "Epoch 90/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8504e-04 - rmse: 0.0077 - r_square: 0.9861 - val_loss: 2.7448e-05 - val_rmse: 0.0033 - val_r_square: 0.9979\n",
      "Epoch 91/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8487e-04 - rmse: 0.0077 - r_square: 0.9862 - val_loss: 2.8454e-05 - val_rmse: 0.0032 - val_r_square: 0.9979\n",
      "Epoch 92/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8667e-04 - rmse: 0.0077 - r_square: 0.9860 - val_loss: 2.2501e-05 - val_rmse: 0.0034 - val_r_square: 0.9983\n",
      "Epoch 93/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8302e-04 - rmse: 0.0077 - r_square: 0.9862 - val_loss: 4.3118e-05 - val_rmse: 0.0040 - val_r_square: 0.9968\n",
      "Epoch 94/200\n",
      "863855/863855 [==============================] - 5s 5us/step - loss: 1.8556e-04 - rmse: 0.0077 - r_square: 0.9860 - val_loss: 3.4910e-05 - val_rmse: 0.0034 - val_r_square: 0.9974\n",
      "Epoch 00094: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model3 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model3.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result3 = model3.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.6824301e-01]\n",
      " [ 7.1230826e+00]\n",
      " [ 4.2358734e+01]\n",
      " [ 1.2410133e+01]\n",
      " [ 1.6438693e+00]\n",
      " [-2.8274857e-02]\n",
      " [ 5.0302896e+00]\n",
      " [ 3.9520421e+00]\n",
      " [ 8.2271948e+00]\n",
      " [ 1.7088663e+01]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.470328\n",
      "Mean squared error (MSE):       0.670427\n",
      "Root mean squared error (RMSE): 0.818796\n",
      "R square (R^2):                 0.997462\n"
     ]
    }
   ],
   "source": [
    "predictions3 = model3.predict(X_test)\n",
    "pre_act3 = sc.inverse_transform(predictions3)\n",
    "print(pre_act3[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act3))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act3))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act3)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference: \n",
    "&emsp;&emsp;What does 'Accuracy' mean in Regression? https://github.com/keras-team/keras/issues/7947 <br>\n",
    "&emsp;&emsp;https://keras.io/metrics/<br>\n",
    "&emsp;&emsp;Scale, Standardize, or Normalize with Scikit-Learn https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02 <br>\n",
    "&emsp;&emsp;The Day my Computer Won the Nobel Prize (Neural Network Option Pricing)  https://medium.com/datadriveninvestor/the-day-my-computer-won-the-nobel-prize-neural-network-option-pricing-d29b4379f1d2 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
