{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl (1.4MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-19.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.11.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/4a/5c86ed8b245aa48f9f819b13a0a9039e9126ba19fdd0c7e0b8026c12315a/tensorflow-1.14.0-cp36-cp36m-win_amd64.whl (68.3MB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.1)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/ed/e036d31a9b2c750f270cbb1cfc1c0f94ac78ae504eea7eec3267be4e294a/numpy-1.16.4-cp36-cp36m-win_amd64.whl (11.9MB)\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.0.8)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/74/44ec96740ed10ae6d0508efc083c6b7e605c509bc32136e9aea840d09daf/protobuf-3.9.0-cp36-cp36m-win_amd64.whl (1.1MB)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/93/297ff3656f1073fba84e2f9633ad3b27a007eb59ad22099ac30142f80365/grpcio-1.22.0-cp36-cp36m-win_amd64.whl (1.6MB)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Building wheels for collected packages: wrapt, absl-py, termcolor, gast\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\d7\\de\\2e\\efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\ee\\98\\38\\46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built wrapt absl-py termcolor gast\n",
      "Installing collected packages: tensorflow-estimator, google-pasta, numpy, wrapt, absl-py, protobuf, astor, termcolor, markdown, grpcio, tensorboard, gast, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.22.0 markdown-3.1.1 numpy-1.16.4 protobuf-3.9.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.11.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "!pip install --user keras\n",
    "!pip install --user tensorflow\n",
    "!pip install --user -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CPU only\n",
    "# Only Macbook needs to run this cell\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and do data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>exdate</th>\n",
       "      <th>maturity</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>realized_vol</th>\n",
       "      <th>underlying_price</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>cp_flag_C</th>\n",
       "      <th>cp_flag_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.346417</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>58.61</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>3</td>\n",
       "      <td>57.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.234645</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>58.61</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.229130</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>58.61</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>3</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.413285</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>58.61</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.608310</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>58.61</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date      exdate  maturity  strike_price  best_offer  \\\n",
       "0    AXP  2012-09-04  2012-09-07         3          55.0        3.65   \n",
       "1    AXP  2012-09-04  2012-09-07         3          57.5        1.25   \n",
       "2    AXP  2012-09-04  2012-09-07         3          60.0        0.09   \n",
       "3    AXP  2012-09-04  2012-09-07         3          62.5        0.08   \n",
       "4    AXP  2012-09-04  2012-09-07         3          65.0        0.08   \n",
       "\n",
       "   impl_volatility  realized_vol  underlying_price  interest_rate  cp_flag_C  \\\n",
       "0         0.346417      0.169029             58.61          0.001          1   \n",
       "1         0.234645      0.169029             58.61          0.001          1   \n",
       "2         0.229130      0.169029             58.61          0.001          1   \n",
       "3         0.413285      0.169029             58.61          0.001          1   \n",
       "4         0.608310      0.169029             58.61          0.001          1   \n",
       "\n",
       "   cp_flag_P  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Options_R_new.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the option data has less than 7 days to maturity.\n",
    "df = df[df.maturity > 6]\n",
    "\n",
    "# Remove the option data with deep in-the-money and deep out-of-money\n",
    "def moneyness(S,X):\n",
    "    return S/X\n",
    "df['moneyness'] = df.apply(lambda row: moneyness(row['underlying_price'], row['strike_price']), axis = 1)\n",
    "df = df[df.moneyness >= 0.7]\n",
    "df = df[df.moneyness <= 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['interest_rate'].notnull()]\n",
    "y = df['best_offer'].values\n",
    "X = df[['maturity', 'strike_price', 'impl_volatility', 'underlying_price', 'cp_flag_C', 'cp_flag_P', 'interest_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to build a regression neural network model\n",
    "X = preprocessing.normalize(X)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1138934, 7)\n",
      "(1138934, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train, XX_validation, yy_train, yy_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built Keras sequential model with 3 hidden layer, and after the first hidden layer.\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable early stopping based on the loss of validation data\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is a simple regression problem, we should custom metrics function\n",
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1))\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean_squared_error to compile regression model loss\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 911147 samples, validate on 227787 samples\n",
      "Epoch 1/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 40.2112 - rmse: 3.5875 - r_square: 0.5739 - val_loss: 6.7470 - val_rmse: 1.5053 - val_r_square: 0.9275\n",
      "Epoch 2/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 4.3188 - rmse: 1.1751 - r_square: 0.9534 - val_loss: 2.4260 - val_rmse: 0.9224 - val_r_square: 0.9739\n",
      "Epoch 3/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.0073 - rmse: 0.8025 - r_square: 0.9782 - val_loss: 1.2903 - val_rmse: 0.6522 - val_r_square: 0.9861\n",
      "Epoch 4/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 1.2870 - rmse: 0.6475 - r_square: 0.9861 - val_loss: 2.3249 - val_rmse: 0.9078 - val_r_square: 0.9750\n",
      "Epoch 5/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 1.0497 - rmse: 0.5807 - r_square: 0.9887 - val_loss: 0.7164 - val_rmse: 0.5116 - val_r_square: 0.9923\n",
      "Epoch 6/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.9564 - rmse: 0.5461 - r_square: 0.9896 - val_loss: 1.7321 - val_rmse: 0.6844 - val_r_square: 0.9817\n",
      "Epoch 7/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.7702 - rmse: 0.4974 - r_square: 0.9916 - val_loss: 0.6005 - val_rmse: 0.4881 - val_r_square: 0.9935\n",
      "Epoch 8/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.8323 - rmse: 0.5058 - r_square: 0.9910 - val_loss: 0.4566 - val_rmse: 0.4012 - val_r_square: 0.9951\n",
      "Epoch 9/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.7147 - rmse: 0.4733 - r_square: 0.9923 - val_loss: 0.4596 - val_rmse: 0.3964 - val_r_square: 0.9950\n",
      "Epoch 10/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.6924 - rmse: 0.4607 - r_square: 0.9925 - val_loss: 0.9852 - val_rmse: 0.5850 - val_r_square: 0.9893\n",
      "Epoch 11/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 0.6468 - rmse: 0.4461 - r_square: 0.9930 - val_loss: 1.2878 - val_rmse: 0.6323 - val_r_square: 0.9863\n",
      "Epoch 12/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.6099 - rmse: 0.4343 - r_square: 0.9934 - val_loss: 0.8171 - val_rmse: 0.4914 - val_r_square: 0.9912\n",
      "Epoch 13/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.5812 - rmse: 0.4249 - r_square: 0.9937 - val_loss: 2.1297 - val_rmse: 0.6334 - val_r_square: 0.9775\n",
      "Epoch 14/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.5475 - rmse: 0.4122 - r_square: 0.9941 - val_loss: 0.3474 - val_rmse: 0.3574 - val_r_square: 0.9962\n",
      "Epoch 15/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.5375 - rmse: 0.4044 - r_square: 0.9942 - val_loss: 0.7566 - val_rmse: 0.5185 - val_r_square: 0.9919\n",
      "Epoch 16/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.4816 - rmse: 0.3877 - r_square: 0.9948 - val_loss: 0.4284 - val_rmse: 0.4096 - val_r_square: 0.9954\n",
      "Epoch 17/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.4743 - rmse: 0.3842 - r_square: 0.9948 - val_loss: 0.5461 - val_rmse: 0.4526 - val_r_square: 0.9941\n",
      "Epoch 18/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.4414 - rmse: 0.3703 - r_square: 0.9952 - val_loss: 2.7154 - val_rmse: 0.8657 - val_r_square: 0.9709\n",
      "Epoch 19/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.4466 - rmse: 0.3717 - r_square: 0.9951 - val_loss: 0.2771 - val_rmse: 0.3014 - val_r_square: 0.9970\n",
      "Epoch 20/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 0.4192 - rmse: 0.3572 - r_square: 0.9955 - val_loss: 0.2709 - val_rmse: 0.3095 - val_r_square: 0.9971\n",
      "Epoch 21/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.4036 - rmse: 0.3521 - r_square: 0.9956 - val_loss: 0.4325 - val_rmse: 0.3410 - val_r_square: 0.9954\n",
      "Epoch 22/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.3769 - rmse: 0.3405 - r_square: 0.9959 - val_loss: 0.5576 - val_rmse: 0.3904 - val_r_square: 0.9940\n",
      "Epoch 23/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.3826 - rmse: 0.3411 - r_square: 0.9959 - val_loss: 0.3985 - val_rmse: 0.3446 - val_r_square: 0.9957\n",
      "Epoch 24/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.3666 - rmse: 0.3306 - r_square: 0.9960 - val_loss: 1.4298 - val_rmse: 0.5437 - val_r_square: 0.9849\n",
      "Epoch 25/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.3561 - rmse: 0.3279 - r_square: 0.9961 - val_loss: 0.2314 - val_rmse: 0.2744 - val_r_square: 0.9975\n",
      "Epoch 26/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.3196 - rmse: 0.3145 - r_square: 0.9965 - val_loss: 0.1851 - val_rmse: 0.2458 - val_r_square: 0.9980\n",
      "Epoch 27/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.3056 - rmse: 0.3087 - r_square: 0.9967 - val_loss: 0.2745 - val_rmse: 0.3126 - val_r_square: 0.9970\n",
      "Epoch 28/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.3107 - rmse: 0.3075 - r_square: 0.9966 - val_loss: 0.5235 - val_rmse: 0.4170 - val_r_square: 0.9944\n",
      "Epoch 29/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.3029 - rmse: 0.3035 - r_square: 0.9967 - val_loss: 0.7964 - val_rmse: 0.5142 - val_r_square: 0.9915\n",
      "Epoch 30/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 0.2839 - rmse: 0.2967 - r_square: 0.9969 - val_loss: 0.2912 - val_rmse: 0.2802 - val_r_square: 0.9969\n",
      "Epoch 31/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2913 - rmse: 0.2978 - r_square: 0.9968 - val_loss: 0.2153 - val_rmse: 0.2760 - val_r_square: 0.9977\n",
      "Epoch 32/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2957 - rmse: 0.2964 - r_square: 0.9968 - val_loss: 0.3177 - val_rmse: 0.3248 - val_r_square: 0.9966\n",
      "Epoch 33/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2764 - rmse: 0.2893 - r_square: 0.9970 - val_loss: 0.1802 - val_rmse: 0.2511 - val_r_square: 0.9981\n",
      "Epoch 34/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2581 - rmse: 0.2804 - r_square: 0.9972 - val_loss: 0.1907 - val_rmse: 0.2699 - val_r_square: 0.9979\n",
      "Epoch 35/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2530 - rmse: 0.2783 - r_square: 0.9973 - val_loss: 0.1808 - val_rmse: 0.2456 - val_r_square: 0.9980\n",
      "Epoch 36/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2584 - rmse: 0.2778 - r_square: 0.9972 - val_loss: 0.1690 - val_rmse: 0.2381 - val_r_square: 0.9982\n",
      "Epoch 37/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2410 - rmse: 0.2715 - r_square: 0.9974 - val_loss: 0.4642 - val_rmse: 0.4187 - val_r_square: 0.9950\n",
      "Epoch 38/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2399 - rmse: 0.2712 - r_square: 0.9974 - val_loss: 0.2139 - val_rmse: 0.2545 - val_r_square: 0.9977\n",
      "Epoch 39/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2449 - rmse: 0.2723 - r_square: 0.9973 - val_loss: 0.2148 - val_rmse: 0.2831 - val_r_square: 0.9977\n",
      "Epoch 40/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2344 - rmse: 0.2668 - r_square: 0.9975 - val_loss: 0.1251 - val_rmse: 0.2010 - val_r_square: 0.9986\n",
      "Epoch 41/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2315 - rmse: 0.2656 - r_square: 0.9975 - val_loss: 0.2266 - val_rmse: 0.2826 - val_r_square: 0.9976\n",
      "Epoch 42/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2315 - rmse: 0.2640 - r_square: 0.9975 - val_loss: 0.4431 - val_rmse: 0.3500 - val_r_square: 0.9953\n",
      "Epoch 43/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2172 - rmse: 0.2595 - r_square: 0.9976 - val_loss: 0.1860 - val_rmse: 0.2379 - val_r_square: 0.9980\n",
      "Epoch 44/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2359 - rmse: 0.2654 - r_square: 0.9974 - val_loss: 0.2592 - val_rmse: 0.2897 - val_r_square: 0.9972\n",
      "Epoch 45/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2206 - rmse: 0.2589 - r_square: 0.9976 - val_loss: 0.1991 - val_rmse: 0.2607 - val_r_square: 0.9979\n",
      "Epoch 46/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2161 - rmse: 0.2559 - r_square: 0.9977 - val_loss: 0.1427 - val_rmse: 0.2169 - val_r_square: 0.9985\n",
      "Epoch 47/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2073 - rmse: 0.2523 - r_square: 0.9978 - val_loss: 0.1927 - val_rmse: 0.2402 - val_r_square: 0.9979\n",
      "Epoch 48/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2325 - rmse: 0.2606 - r_square: 0.9975 - val_loss: 0.2017 - val_rmse: 0.2597 - val_r_square: 0.9978\n",
      "Epoch 49/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2129 - rmse: 0.2543 - r_square: 0.9977 - val_loss: 0.3003 - val_rmse: 0.2849 - val_r_square: 0.9968\n",
      "Epoch 50/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1981 - rmse: 0.2469 - r_square: 0.9978 - val_loss: 0.1267 - val_rmse: 0.2001 - val_r_square: 0.9986\n",
      "Epoch 51/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2194 - rmse: 0.2523 - r_square: 0.9976 - val_loss: 0.4016 - val_rmse: 0.3018 - val_r_square: 0.9958\n",
      "Epoch 52/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2142 - rmse: 0.2530 - r_square: 0.9977 - val_loss: 0.1662 - val_rmse: 0.2314 - val_r_square: 0.9982\n",
      "Epoch 53/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2051 - rmse: 0.2488 - r_square: 0.9978 - val_loss: 0.2643 - val_rmse: 0.2551 - val_r_square: 0.9972\n",
      "Epoch 54/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2023 - rmse: 0.2477 - r_square: 0.9978 - val_loss: 0.1334 - val_rmse: 0.2152 - val_r_square: 0.9986\n",
      "Epoch 55/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.2152 - rmse: 0.2479 - r_square: 0.9977 - val_loss: 0.1407 - val_rmse: 0.2138 - val_r_square: 0.9985\n",
      "Epoch 56/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1877 - rmse: 0.2403 - r_square: 0.9980 - val_loss: 0.1301 - val_rmse: 0.2113 - val_r_square: 0.9986\n",
      "Epoch 57/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1900 - rmse: 0.2413 - r_square: 0.9979 - val_loss: 0.5549 - val_rmse: 0.3750 - val_r_square: 0.9941\n",
      "Epoch 58/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1904 - rmse: 0.2405 - r_square: 0.9979 - val_loss: 0.1443 - val_rmse: 0.2132 - val_r_square: 0.9985\n",
      "Epoch 59/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1968 - rmse: 0.2415 - r_square: 0.9979 - val_loss: 0.1915 - val_rmse: 0.2226 - val_r_square: 0.9980\n",
      "Epoch 60/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1896 - rmse: 0.2391 - r_square: 0.9979 - val_loss: 0.1858 - val_rmse: 0.2279 - val_r_square: 0.9980\n",
      "Epoch 61/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1802 - rmse: 0.2347 - r_square: 0.9981 - val_loss: 0.1310 - val_rmse: 0.2077 - val_r_square: 0.9986\n",
      "Epoch 62/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1834 - rmse: 0.2358 - r_square: 0.9980 - val_loss: 0.3974 - val_rmse: 0.3096 - val_r_square: 0.9958\n",
      "Epoch 63/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1855 - rmse: 0.2382 - r_square: 0.9980 - val_loss: 0.2783 - val_rmse: 0.2612 - val_r_square: 0.9970\n",
      "Epoch 64/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1790 - rmse: 0.2343 - r_square: 0.9981 - val_loss: 0.1092 - val_rmse: 0.1889 - val_r_square: 0.9988\n",
      "Epoch 65/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1870 - rmse: 0.2376 - r_square: 0.9980 - val_loss: 0.3493 - val_rmse: 0.3183 - val_r_square: 0.9963\n",
      "Epoch 66/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1762 - rmse: 0.2313 - r_square: 0.9981 - val_loss: 0.1564 - val_rmse: 0.2614 - val_r_square: 0.9983\n",
      "Epoch 67/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1919 - rmse: 0.2388 - r_square: 0.9979 - val_loss: 0.1370 - val_rmse: 0.2222 - val_r_square: 0.9985\n",
      "Epoch 68/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1743 - rmse: 0.2300 - r_square: 0.9981 - val_loss: 0.2063 - val_rmse: 0.2475 - val_r_square: 0.9978\n",
      "Epoch 69/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1751 - rmse: 0.2317 - r_square: 0.9981 - val_loss: 1.0552 - val_rmse: 0.5549 - val_r_square: 0.9886\n",
      "Epoch 70/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1792 - rmse: 0.2318 - r_square: 0.9981 - val_loss: 0.1572 - val_rmse: 0.2526 - val_r_square: 0.9983\n",
      "Epoch 71/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1853 - rmse: 0.2332 - r_square: 0.9980 - val_loss: 0.1771 - val_rmse: 0.2207 - val_r_square: 0.9981\n",
      "Epoch 72/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1709 - rmse: 0.2293 - r_square: 0.9981 - val_loss: 0.2085 - val_rmse: 0.2989 - val_r_square: 0.9977\n",
      "Epoch 73/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1660 - rmse: 0.2265 - r_square: 0.9982 - val_loss: 0.1746 - val_rmse: 0.2611 - val_r_square: 0.9981\n",
      "Epoch 74/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1828 - rmse: 0.2325 - r_square: 0.9980 - val_loss: 0.1147 - val_rmse: 0.1973 - val_r_square: 0.9988\n",
      "Epoch 75/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1649 - rmse: 0.2236 - r_square: 0.9982 - val_loss: 1.5003 - val_rmse: 0.5888 - val_r_square: 0.9842\n",
      "Epoch 76/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1661 - rmse: 0.2249 - r_square: 0.9982 - val_loss: 0.2575 - val_rmse: 0.2984 - val_r_square: 0.9972\n",
      "Epoch 77/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1691 - rmse: 0.2272 - r_square: 0.9982 - val_loss: 0.1793 - val_rmse: 0.2335 - val_r_square: 0.9981\n",
      "Epoch 78/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1691 - rmse: 0.2268 - r_square: 0.9982 - val_loss: 0.2136 - val_rmse: 0.2344 - val_r_square: 0.9977\n",
      "Epoch 79/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1682 - rmse: 0.2251 - r_square: 0.9982 - val_loss: 0.1186 - val_rmse: 0.1966 - val_r_square: 0.9987\n",
      "Epoch 80/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1641 - rmse: 0.2238 - r_square: 0.9982 - val_loss: 0.1705 - val_rmse: 0.2399 - val_r_square: 0.9982\n",
      "Epoch 81/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1617 - rmse: 0.2227 - r_square: 0.9982 - val_loss: 0.1210 - val_rmse: 0.1967 - val_r_square: 0.9987\n",
      "Epoch 82/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1665 - rmse: 0.2245 - r_square: 0.9982 - val_loss: 1.2671 - val_rmse: 0.5933 - val_r_square: 0.9865\n",
      "Epoch 83/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1657 - rmse: 0.2232 - r_square: 0.9982 - val_loss: 0.1243 - val_rmse: 0.1943 - val_r_square: 0.9987\n",
      "Epoch 84/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1585 - rmse: 0.2193 - r_square: 0.9983 - val_loss: 0.1186 - val_rmse: 0.1951 - val_r_square: 0.9987\n",
      "Epoch 85/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1695 - rmse: 0.2262 - r_square: 0.9982 - val_loss: 0.1546 - val_rmse: 0.2265 - val_r_square: 0.9983\n",
      "Epoch 86/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1562 - rmse: 0.2185 - r_square: 0.9983 - val_loss: 0.3783 - val_rmse: 0.3113 - val_r_square: 0.9960\n",
      "Epoch 87/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1575 - rmse: 0.2198 - r_square: 0.9983 - val_loss: 0.2484 - val_rmse: 0.2710 - val_r_square: 0.9973\n",
      "Epoch 88/200\n",
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1564 - rmse: 0.2185 - r_square: 0.9983 - val_loss: 0.2235 - val_rmse: 0.2555 - val_r_square: 0.9976\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911147/911147 [==============================] - 4s 5us/step - loss: 0.1589 - rmse: 0.2189 - r_square: 0.9983 - val_loss: 0.1218 - val_rmse: 0.1976 - val_r_square: 0.9987\n",
      "Epoch 00089: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "result = model.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model13.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.988133  ]\n",
      " [ 0.16768476]\n",
      " [24.407785  ]\n",
      " [ 0.06328553]\n",
      " [ 6.2233644 ]\n",
      " [ 1.0276563 ]\n",
      " [ 6.978905  ]\n",
      " [ 0.06013948]\n",
      " [ 1.1953082 ]\n",
      " [ 9.010826  ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.1 ],\n",
       "       [ 0.14],\n",
       "       [25.4 ],\n",
       "       [ 0.04],\n",
       "       [ 6.05],\n",
       "       [ 1.01],\n",
       "       [ 6.75],\n",
       "       [ 0.04],\n",
       "       [ 1.13],\n",
       "       [ 9.05]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curves including R^2 and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for rmse\n",
    "plt.plot(result.history['rmse'])\n",
    "plt.plot(result.history['val_rmse'])\n",
    "plt.title('rmse')\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VfWd//HX5yY3G2FPQCAgi6CARVCk1BW1dXBvLTPV1mm149CxVtuOtrXLdLF12k5txzq1rVbtMj+rUipqW5e6oOioCCgigiAqSgAhBAiQhOTeez6/P87NNctNAoGbAOf9fDx4eM96v/d48v2c73rM3REREQGI9XQCRETkwKGgICIiGQoKIiKSoaAgIiIZCgoiIpKhoCAiIhkKCiJ7wMx+Z2Y/2MN915rZh/fDd44xs++a2YR9PZfInlJQEOlG6eDSaGa7zGyrmT1mZkdl2e8w4O/AacDfzWxEq+3nmNmzZrbdzN4zs9+YWe9u+hlyCFNQEOl+/+XupcAwYD1wR/ONZtYHeBj4o7ufCvw38IiZDWy2W1/gB8BQYDxQAfykG9IuhzgFBTlkpKttvmJmy8ys1szuMLPBZvawme00s8fNrH+z/c83s9fST9tPmdn4ZtummNlL6ePuBYpafde5ZrY0fexzZjZpb9Pr7vXAHGBys/MWAg8Ac9z9P9L7/RT4BfAXM+uVXvdHd3/E3evcfRvwG+DEvU2DSGsKCnKo+TjwEWAccB7hE/c3gDLC+/1qADMbB9wNfAkoBx4izHQLzKwAuB/4X2AA8Kf0eUkfeyxwJ/A5YCBwK/BgOkPfY+kM/mJgTdM6d29w99Pc/YfN93X3X7r7Ce5e287pTgFe25vvF8lGQUEONf/j7pvcfT3wDLDQ3V929wZgHjAlvd8ngL+5+2PungBuBIqBE4DpQBy4yd0T7j4XWNTsO/4VuNXdF7p7yt1/DzSkj9sT15rZdmAncBLwz/vyg83sI8BngG/vy3lEQEFBDj2bmn2uz7Jcmv48FHinaYO7B8A6wnr+ocB6bzlb5DvNPh8OXJOuOtqezuCHp4/bEze6ez9gZDpNR+7hcW2Y2XTgj8Asd1/d1fOINFFQkKjaQJi5A2BmRpixrwc2AsPS65o07/2zDrjB3fs1+1fi7nfvTQLc/V3gi8DPzax4b3+AmU0BHgQ+6+5P7O3xItkoKEhUzQHOMbMzzCwOXENYBfQc8DyQBK42s3wzuxCY1uzY3wD/ZmYftFCvdBfRve4S6u6PEQao2XtznJkdDTwCXOXuf9nb7xVpj4KCRJK7rwIuAf4H2ELYKH2euze6eyNwIXApsI2w/eG+ZscuJmxX+EV6+5r0vl31E+Cre9lQfQ1hA/kd6TEPu8xMDc2yz0wv2RERkSYqKYiISIaCgoiIZCgoiIhIhoKCiIhk5Pd0AvZWWVmZjxw5sqeTISJyUFmyZMkWdy/vbL+DLiiMHDmSxYsX93QyREQOKmb2Tud7qfpIRESaUVAQEZEMBQUREclQUBARkQwFBRERychZUDCzO81ss5ktb2e7mdnNZrYm/frEY3OVFhER2TO5LCn8DpjZwfazgLHpf7OBX+UwLSIisgdyNk7B3ReY2cgOdrkA+EP67VYvmFk/Mxvi7htzlSbZz9whUQe7a6CoHxSU5OZ7aquhfhvE8iCWH/43SEGQBA/C/wZJSCWgoBTKjtiztNdWwbZ3YNtaSO6GAaNg4BFQOhhavF+nmV2bw+9o/VvdwzTWVUPtlvC/FoPi/nhxP7ywL7H8wvd/Q0GvFt8RBE5i61r83Rex8nEUVEymxTt+3GHLGxAvxnsPIbA8UoHjiTrY/DpWvZpYkCIvPw+zPBxIJhMkEgkS5LF7zDlQ2AsDaDptop6Cd5/B4kVQ1B8r7ksQK8CDFEEQQKqRoHZr+Fvqt9IwcDyJ8g9gZpiBkf6vhcmzmnUUrH8ea9zF7tH/AH2GEYsZQeCkAse2ryW+/S3yvZH8oJE8UiQKB9BQNIjdxYNIFPRtcU2azh+v30LB9jeI5RVg8ULILyIRKyGRX8xuK8GDFNawAxK15DXupKihmsKGagoat7Nz9FnUlVTQmAxIBuGM0E1fYYDhxOu3kJfcRZDfiyBegucVkl+3iYKd71K4410suZtEYT8SBf1IxnuTl9hFXkMNeY3bqSubRF3ZMZlr0qR48yuUbl6MBwEepHDAC0rxgt5Q2Ju6AROoLx5MMuUEWWaqblplQYLCXZWU7FpL0c619Bl/BmVjclup0pOD14YRvsGqSWV6XZugYGazSb+EZMSIEa03H7oS9VC9Bg77QNfP0bALHrkOGnaEGag79CqH4dPwiuNJ9B3N7lTA7sYU9YkUqcCJmYVFyKCRhMVJppxEKvyjSgUBpWsfZ+QL/0F8dzUxT2S+qi4+gJrCoVSVjGb1wDNY138aWH74B+HhzZ9MOQ3JgPjuak5+7w+UN66jX7KKPoktAFQXDae6cDg742UMqH+HofWrGJDYlPWntef1/KO4v/A8nop9iLg3cHLyOc5MzGdi6nWMdMaAk0eQ9fhainnJJvJs7HiejR1H4PDh1DOc5QuYwNsAbKc3m20gAXn0920MoIY4qaznM97Ph5vUU8i7HMY7Ppi6IM7U2CoqbEtm+/JgJH/201gTG8UMFnEmCxlumwFIeB7rvYyAGCPtPfKsbaZihC+ZjqeX6/w7fD9xCQ8FHwRgZmwR34r/PwY1+849sTIYzp9Tp/B8MJEK28wRtoFxsUqOi61ukX4WfJNFwTgeSx3HCNvMybFXOTy2ucNzP5eawKWJr9GYSTUMZit/K/wGZbZjr9LZZMWCP3NJ4pst1hWQ4Mfx25hiaxhi1RRaskvnBqj23pze8FNqMm95hQrbzOMFX6HIEh0cCUuDMTyZOp5lPooxtoGj7F2OjFXSj10UWSPFNNCbeuL2/n21aFdjzoNCTt+nkC4p/NXdj86y7W/AD9392fTyE8BX3X1JR+ecOnWqHzAjmt1h61uw/iVYvwQ2vxY+wQJgMOoUOPkayOs49ro7iZRTn86YdzUkqW1IUv7stxm66vdsHnIaKyZdx86SEdTUJ8h/bykfWPs7yuveYFPBCNYXjGJ9wWieL/ggNY0xdjWkSKQC8sw4Pfk0X6u9kUobSgP5pNw4zKvoY3UAbPNSVgSHs9JHsDI4nD5Wy3Gx1UyNraYfu/h443d5zUdl0lpKHU8WXssOL+HvwVRqvBc7KaEfOxluVQy3zRwTe4veVk+V9+GvqQ8xN3UKKxkVBpuYMSP/Vf6TW+jDLt6yEWxiIJsZgHmKEWzkcDZSzjYqGczq2BGsyR/D9rwyCvICCsyJxxyzGG55BBYjsDySnk+SGOXJ9ziz7i8cltxATV5/ioNaCryRTfHhLC+dToKCMCw47IwPYFvBELYXDiUZK2JQopKyxkoOa3ibI3e+yIBE+HwSECNGwIaSo3i9/2m4B5Q2bKJ3wyaMgNr4AOoLBlIXH0h9QX/q4/2pz+9LzKA02ElxcgdFqV2kUgmCZIIg2Uif5FbKE+sZ2FBJYaqWjX0msbH/VLb0m0TZ9mWM3ziPQbXhK5dTls/aPsezasCp5JnRr3Ej/XevJ8+TbC09gurSsWwrGU2jFZBKpkgFSWJAvKCQwoICBjRu4LjXf8KAHSvZMPBDGAFDqheyrXQsL4+7mkR+KfHGHeQ31pDnSSwWXltieSQL+5MsGkBQUEp51UJGrHuAAdteaXH/1hYdxtb+k6geOJWtZccT5BcypPIRhq1/mH473yCRV8KWsmlUDTqBmn4TaKSQRouTCIxeqRpKE1vov+sNxr3+KyoPv5BXj7sBN4NUgukLPk2fmlUsOe5HJGKFkGwklmqg0OspTNVRENRhsXyCeC9S8d4k472oKxhAbf4ABq97iKNX3sTCU/7AriHTyYuFoXn4itsY88pP2FzxD9SXjmB3yRAS8d7kperJT9QSS+2msaic+tLh1JcOJ5VfQkGihsLGGvITOwnivUgU9qOgoYYPPP5JNo75J96Y9n0Cd8ydDyyYTb/NL/LSzPtJlgzCYrHwwaCxFhp3YvXbGLh5IeXrH6P31lcz1zFZ2I+6fkeRKC4jyCvC84tIFvZhd+lIdvcdRX3p4VRUjGBw371+c2uYI5ktcfepne7Xg0HhVuCppvfamtkqYEZn1UfdHhS2r4Md62HE9Jbr3Unc+xnirz8QLucXw+AJJPOKqW9M0Fhfy8Ca5azrcxz3jb6eLfSjpj7B9voENXWN7GxIUteQorYxSV1j+ITeXBENvFh4JRt9AMNsCwUkuCv1YcZaJSflvcYOSnglNpHhvpHhvoE8Am4rmc2T/S6ktDCfgvwYqcC59L0fcnT9i3x99H0UFhRQUpBHQR4MTbzL8NrlVNQup6xuDQN2vUl+sBuAuuIhbBkwhfIti0gU9OG5M+4jFi8inhfjiFd+zPCVt7PinHlYxVRKC/MpLcynMB4jnhcjP2ZYsgHWPAav/glf9QiWaoAhx8Cxn4atb8Pzv4Dy8TDrDhg8Mft1D1JhVUtXBAGseRxe/kNYFXTMxTDsuParhLJxh80rYfXDkNgNR38cBh3VtfR01YalsO1tGD0Divvv27mCFCy6A578QXgdTv8WHHdZpw8sWVWthveWwYDRUDYOCkvb33fHhrBkmhdvf58mT94AC/4LZv4Ypv8bPPJ1eOGXMOvO8PrvrUQ9/PyYsErw0r+Fv3vXZrj5WBh5Enzynr0/Z2uPfhOevwUufxwqpsLKv8K9n4IzfwAnXNX58TWVsGU1lB8FvYfs3T26lw6GoHAO8AXgbOCDwM3uPq31fq11e1D4zRmwcSn+2b9T1Xcib1XV8tyb1QTL53FtzX9yZ3Imc1Iz2BAfQVFhIZt3NmQOvTC2gBvid7KTEq6LfZm3So6hb3GcPsVx+hTF6Z/fwHlbbueInYt4YPKtBL0GU1yQR2lhPkds+AsTX/wab559D8kBYxj84o/pt3ouqV6D8elXkn/8ZVDUJ/yiZAPcdhoU9YXPPvx+2oMAbhwLY06Dj9/e8e8MUmGpJ14CfYeF6954HO76OHzoC/APN4SZwa8+BMdcBBfcsmfXr34bvDoXlvweNqWfiqb+S3i+eNeeeGQfNNYClrv2n30RBDDnn2HVwzD9ivDh4YP/Bmf9uOvnXHgrPPxV+PQDYXB98GpYehd8fuGetT11pmEn/OL4MPBd+lf45Qnh3+XnFuxZIOxGPR4UzOxuYAZQBmwCvkO6itPdf21hK9ovCHso1QGXpd9926HuCgqpwFn+4hMc88jHSRHjXR/M2Q03UE8Rfa2W+cVfpbF4EE+ffA9b6gO21jayc3eCEQNKGDe4N0ce1pvBfYoorF6Jzfl0mOGOOR2mXgbjZsLaZ+EvV4clEbPwqe3cn72fgDv+IWwIvWrJ+08POzdBcT/Iz/Iq36d+FP67djWUDgrXrV8CvzkdPnYbHPOJrl2Iv34ZFv82vOGf+SlULgnTVNrpZIstucOGl8N2jYpO70uJqoadcPtHoGolVEwLn/DzC7p+vsRu+J9joc+w8O/r1lPgg1fAzP/cf2l+bR786dKw9Fu1Ej77aNuahQPAngaFXPY+uriT7Q5cmavv3yubVsC6hXDcpTSmnJ/+fRV/fmk932z4GWNixfx28Df4wuZvc//YR9hw0g2csPIGCl+pgU/N4xNDR3d87sOOhtlPhUXMl/4A914CxQOgfmtYrL3sYXj1T7DkdzD98+HTy+aVsO4F+Mj3WxYnew9u/3vGnwdP/RBe/1sYeCB80sfgiDO6fm0+8n1480m4+5PQUBMW7fc2IED4O4ZpKIp0orB3WK3zzE/h1Ov2LSAAxIvCdr2//TvcfXHYS+7Ur+yftDaZ8NHwge/NJ2HKJQdkQNgbB93U2ftdsiHMqLe+SaqgN196dRQPvfoe/3hkPhe8+yLB1M9y1TlXw6ObOPL5X3DkhlGw9HdhBj50yp59R1EfOO3rcMpX4I2/w7J7YOBYOOXasAplwGh45R548vvwT78Pg0csDpM/uee/Y9CE8Dwr//J+UFjzWJjGXmV7fVkyCkvhY7fCnTPD7zj+8q6fS2RP9B8J5//P/jvflH+GZ2+Cmnfh7Bv3vX2mNTM49yZ47mY47Zud73+AU1D4v5th65t43+HsfuDfebH2R3zrnOlcnrwX3kkSm/65cL8zvg1vzoenfwx9Krr2Pz8vH446O/zXXO/BcMIXwnOv/T945W4Yf+7eZeZmYWnh+VugfntYTVO5GE796t6ns7UR0+HT94dBpysNkyI9Kb8AzrsJXrsvrKbNhf6Hwzk/zc25u1m05z7a+jY8cyM+8WPcMvTH5CfruHvovVz+oWGw+A4YeyYMHBPum18YNtYOHAvn/bzjHhddccJVYWPVPZ8MG2eP/czen2P8+eEgrtWPhkVZHI74yP5J3+gZ0C9CY0Tk0HLEGWHnCD3UdCq6QcE97JUQy+e+8s9z48vwzPDZjN36FMz9bNjI+8HPtTxm8AS4ajGM/fD+T09hbzj1a7B7e1h8HnXq3p9j6LHQeyisfBDeeCxsu1A9vojshegGhdf/Ftbvn/YN7lqRYMKQPpxx2fVQcTy8/lcoOzJsPOpOx34mfCI/5SsQ68L/mlgsrHZa83jYnjDm9K739ReRSIpmUHAPB8YMPpotEy/l5XXbOXPiYCwvHz76K+g1KGwEzuFAkqzyC8L+1FMu6fo5xp8XzuNTVw1j91PVkYhERjQr2Goqw54IJ/2U+au34g4fHp/u7lk2Fq55/eB9wh5xApQMDIPCmH3oiioikRTNoLBlVfjf8qN48tnNDO5TyMShfd7ffrAGBAgb0qb+Szh0vivjCUQk0qIZFKrCicYa+h/BgtVLOX/ysJbTFB/sTj/4+0qLSM+IZpvCllVQPICF78WobUzx4fGDejpFIiIHhGgGharVUH4kT66qoige48Qj9mHEr4jIISSaQWHLKrxsHI+v3MSJY8ooih/EbQgiIvtR9IJCbTXUVVNVNJLKbfWcMb6DSeZERCImekEh3fNo4c6wyuj0o9SeICLSJHpBoSoMCn/b2Jujh/XhsL5FPZwgEZEDR/SCwpbVeLyEx9bnq4FZRKSV6AWFqtfxgWNJeYzehdEcpiEi0p4IBoXVBAPHApCfF72fLyLSkWjlig27YEclyQHjAMiPHUKjmEVE9oNoBYUt4fQWif5HABBXSUFEpIVo5YpbmuY8aqo+UklBRKS5aAWFqlUQy2d378MBiHflRTYiIoewaOWKW1bDgNEk05PDqqQgItJStIJC1SooG0cyCAD1PhIRaS06uWKyEba+BeVHkkg5AHH1PhIRaSE6QWHrW+ApKDuSZDooqKQgItJSdHLFzCs4x5HIVB+ppCAi0lx0gkL6FZyUjcuUFNT7SESkpehM/jP9Chh3JhT0IpmqB1RSEBFpLTqPyoWlMOQYABJBuqSgoCAi0kJ0gkIzyVS6TUHVRyIiLUQyV0xkeh+ppCAi0lwkg0LT4DVNiCci0lIkc8XMOAUNXhMRaSGSQSGRUklBRCSbSOaKyUBtCiIi2UQzKKj3kYhIVjnNFc1sppmtMrM1ZnZdlu2Hm9kTZrbMzJ4ys4pcpqdJZkI8lRRERFrIWVAwszzgFuAsYAJwsZlNaLXbjcAf3H0ScD3ww1ylpzlNnS0ikl0uc8VpwBp3f8vdG4F7gAta7TMBeCL9eX6W7TmRUO8jEZGschkUhgHrmi1Xptc19wrw8fTnjwG9zWxg6xOZ2WwzW2xmi6uqqvY5YZkJ8VRSEBFpIZe5YrbHcG+1fC1wqpm9DJwKrAeSbQ5yv83dp7r71PLy8n1OWDIIMIM8lRRERFrI5SyplcDwZssVwIbmO7j7BuBCADMrBT7u7jU5TBMQVh9p2mwRkbZymTMuAsaa2SgzKwAuAh5svoOZlZlZUxq+DtyZw/RkJFOBxiiIiGSRs6Dg7kngC8CjwEpgjru/ZmbXm9n56d1mAKvMbDUwGLghV+lpLhm42hNERLLI6Ut23P0h4KFW677d7PNcYG4u05BNIhVojIKISBaRfFxOplyjmUVEsohkzpgI1KYgIpJNJINCMqU2BRGRbCKZMyaDQKOZRUSyiGRQSKRc8x6JiGQRyZwxqd5HIiJZRTMoBK7qIxGRLCIZFBKpQNVHIiJZRDJnDHsfqaQgItJaJINCItDgNRGRbCKZM6qhWUQku4gGBZUURESyiWTOmNDU2SIiWUUzKASBprkQEckikjljWH2kkoKISGuRDAqa5kJEJLtI5ozJQL2PRESyiWZQUO8jEZGsIpkz6nWcIiLZRTIoJANXl1QRkSwiFxTcnZSmuRARySpyOWMi5QCqPhIRySJyQSEZBADqkioikkXkcsamkoIGr4mItBW5oJBMhSUFTXMhItJW5HLGZJAuKahNQUSkjcgFhURTSUG9j0RE2ohczphMqaQgItKe6AUF9T4SEWlX5HLGzDgF9T4SEWkjckHh/eqjyP10EZFORS5nTGSqj1RSEBFpLXJBIZmpPorcTxcR6VTkcsamwWsqKYiItBW5oJAINCGeiEh7IhcUMiUFVR+JiLQRuZwxocFrIiLtilxQaBq8pgnxRETaymnOaGYzzWyVma0xs+uybB9hZvPN7GUzW2ZmZ+cyPdBsnIIGr4mItJGzoGBmecAtwFnABOBiM5vQardvAXPcfQpwEfDLXKWnSUJTZ4uItKvDnNHM8szsc2b2fTM7sdW2b3Vy7mnAGnd/y90bgXuAC1rt40Cf9Oe+wIY9T3rXaOpsEZH2dfa4fCtwKlAN3GxmP2u27cJOjh0GrGu2XJle19x3gUvMrBJ4CLgq24nMbLaZLTazxVVVVZ18bcfU+0hEpH2d5YzT3P2T7n4T8EGg1MzuM7NCoLNH7WzbvdXyxcDv3L0COBv4XzNrkyZ3v83dp7r71PLy8k6+tmOZCfFUUhARaaOzoFDQ9MHdk+4+G1gKPAmUdnJsJTC82XIFbauH/gWYkz7/80ARUNZ5srtOU2eLiLSvs5xxsZnNbL7C3a8HfguM7OTYRcBYMxtlZgWEDckPttrnXeAMADMbTxgU9q1+qBMJ9T4SEWlXh0HB3S9x90eyrL/d3eOdHJsEvgA8Cqwk7GX0mpldb2bnp3e7BvhXM3sFuBu41N1bVzHtV5kJ8VRSEBFpI39PdjKzPHdP7e3J3f0hwgbk5uu+3ezzCuDE1sflUjIIMIM8lRRERNro9HHZzHoDD3RDWrpFIuWaNltEpB2djVMYAjwO3NY9ycm9ZCrQGAURkXZ0Vn30DPAVd2/dQHzQSgauRmYRkXZ0Vo+yjbYDzg5qiVSgRmYRkXZ0ljvOAM4ysyu7IS3dIplyVR+JiLSjsy6ptcD5wJTuSU7uJYJAU1yIiLSj0y6p6a6ol3dDWrpFMuWa4kJEpB1demROz576qf2dmO6QDAJNcSEi0o7OuqT2MbOvm9kvzOxMC10FvAX8U/ckcf9KpFwNzSIi7eis+uh/CXsgPU9YhfQVwknyLnD3pTlOW04kU4Gqj0RE2tFZUBjt7h8AMLPbgS3ACHffmfOU5YjGKYiItK+zepRE04d0g/PbB3NAgHCcgtoURESy66ykcIyZ7Uh/NqA4vWyAu3uf9g89MCVTTmFcQUFEJJsOg4K753VXQrpLInB6aZyCiEhWkcsdE0k1NIuItCdyQSGpEc0iIu2KXO6ouY9ERNoXuaCQCDRLqohIeyKXOyZTGqcgItKeyAWFRMo1TkFEpB2Ryx2TgXofiYi0J3pBIeXqfSQi0o7I5Y4JTYgnItKuyAWFZKAuqSIi7YlUUHB3UoGqj0RE2hOp3DGRcgBVH4mItCNSQSEZBADqkioi0o5I5Y5NJQUNXhMRyS5SQSGZCksKmuZCRCS7SOWOySBdUlCbgohIVpEKCommkoJ6H4mIZBWp3DGZUklBRKQj0QoK6n0kItKhSOWOmXEK6n0kIpJVpILC+9VHkfrZIiJ7LFK5YyJTfaSSgohINpEKCslM9VGkfraIyB7Lae5oZjPNbJWZrTGz67Js/28zW5r+t9rMtucyPU2D11RSEBHJLj9XJzazPOAW4CNAJbDIzB509xVN+7j7l5vtfxUwJVfpAUgEmhBPRKQjuSwpTAPWuPtb7t4I3ANc0MH+FwN35zA975cUVH0kIpJVLnPHYcC6ZsuV6XVtmNnhwCjgyXa2zzazxWa2uKqqqssJSmjwmohIh3IZFLLlvN7OvhcBc909lW2ju9/m7lPdfWp5eXmXE9Q0eE0T4omIZJfL3LESGN5suQLY0M6+F5HjqiNoNk5Bg9dERLLKZVBYBIw1s1FmVkCY8T/YeiczOxLoDzyfw7QAzSbEU0lBRCSrnOWO7p4EvgA8CqwE5rj7a2Z2vZmd32zXi4F73L29qqX9RlNni4h0LGddUgHc/SHgoVbrvt1q+bu5TENz6n0kItKxSOWOmQnxVFIQEckqUkFBU2eLiHQsUrljQr2PREQ6FKmgkJkQTyUFEZGsIpU7JoMAM8hTSUFEJKtIBYVEyjVttohIByKVQyZTgcYoiIh0IFpBIXA1MouIdCBSQSGRCtTILCLSgUjlkMmUq/pIRKQDkQoKiSDQFBciIh2IVA6ZTLmmuBAR6UC0gkIQaIoLEZEORCqHTKTU+0hEpCORCgpJ9T4SEelQpHLIZKDeRyIiHYlUUEikAk1zISLSgUjlkBqnICLSsUgFhURKvY9ERDoSqRwykXIKVFIQEWlXpIJCUiOaRUQ6FKkcUm0KIiIdi1RQSAQapyAi0pFI5ZBJjWgWEelQpIJCIuXqfSQi0oH8nk5Ad0oGgWZJFTnAJBIJKisr2b17d08n5ZBQVFRERUUF8Xi8S8dHKyikXL2PRA4wlZWV9O7dm5EjR2Kmh7Z94e5UV1dTWVnJqFGjunSOSOWQ4es4ddOJHEh2797NwIEDFRD2AzNj4MCB+1TqilRQ0IR4IgcmBYT9Z1+vZWSCgruTClR9JCLSkcjkkImUA6j6SERa2L59O7/85S/3+rizzz6b7du35yBFPSsyQSEZBADqkioiLbQXFFKpVIfHPfTQQ/Tr1y9Xyeoxkel91FRS0OA1kQPX9/7yGis27Niv55wwtA/fOW9iu9uvu+463nzzTSaJuPh2AAAMBUlEQVRPnkw8Hqe0tJQhQ4awdOlSVqxYwUc/+lHWrVvH7t27+eIXv8js2bMBGDlyJIsXL2bXrl2cddZZnHTSSTz33HMMGzaMBx54gOLi4v36O7pLZB6bk6mwpKBpLkSkuR/96EeMGTOGpUuX8pOf/IQXX3yRG264gRUrVgBw5513smTJEhYvXszNN99MdXV1m3O88cYbXHnllbz22mv069ePP//5z939M/abyJQUkkG6pKA2BZEDVkdP9N1l2rRpLfr433zzzcybNw+AdevW8cYbbzBw4MAWx4waNYrJkycDcNxxx7F27dpuS+/+FpmgkGgqKaj3kYh0oFevXpnPTz31FI8//jjPP/88JSUlzJgxI+sYgMLCwsznvLw86uvruyWtuRCZHDKZUklBRNrq3bs3O3fuzLqtpqaG/v37U1JSwuuvv84LL7zQzanrfpEpKaj3kYhkM3DgQE488USOPvpoiouLGTx4cGbbzJkz+fWvf82kSZM48sgjmT59eg+mtHvkNCiY2Uzg50AecLu7/yjLPv8EfBdw4BV3/2Qu0pIZp6DeRyLSyh//+Mes6wsLC3n44YezbmtqNygrK2P58uWZ9ddee+1+T193yllQMLM84BbgI0AlsMjMHnT3Fc32GQt8HTjR3beZ2aBcpef96iOVFERE2pPLHHIasMbd33L3RuAe4IJW+/wrcIu7bwNw9825SkwiU32kkoKISHtyGRSGAeuaLVem1zU3DhhnZv9nZi+kq5vaMLPZZrbYzBZXVVV1KTHJTPWRSgoiIu3JZQ6Z7ZHcWy3nA2OBGcDFwO1m1mbcuLvf5u5T3X1qeXl5lxLTNHhNJQURkfblMihUAsObLVcAG7Ls84C7J9z9bWAVYZDY7xKBJsQTEelMLoPCImCsmY0yswLgIuDBVvvcD5wGYGZlhNVJb+UiMZmSgqqPRETalbMc0t2TwBeAR4GVwBx3f83Mrjez89O7PQpUm9kKYD7wFXdvO7HIfpDQ4DUR2Q9KS0sB2LBhA7Nmzcq6z4wZM1i8eHGH57npppuoq6vLLB8oU3HndJyCuz8EPNRq3bebfXbg39P/cqpp8JomxBOR/WHo0KHMnTu3y8ffdNNNXHLJJZSUlADhVNwHguiMaNbU2SIHvoevg/de3b/nPOwDcFabcbMZX/va1zj88MP5/Oc/D8B3v/tdzIwFCxawbds2EokEP/jBD7jggpY96teuXcu5557L8uXLqa+v57LLLmPFihWMHz++xdxHV1xxBYsWLaK+vp5Zs2bxve99j5tvvpkNGzZw2mmnUVZWxvz58zNTcZeVlfGzn/2MO++8E4DLL7+cL33pS6xdu7ZbpuiOzGNzQlNni0gWF110Effee29mec6cOVx22WXMmzePl156ifnz53PNNdcQVmxk96tf/YqSkhKWLVvGN7/5TZYsWZLZdsMNN7B48WKWLVvG008/zbJly7j66qsZOnQo8+fPZ/78+S3OtWTJEn7729+ycOFCXnjhBX7zm9/w8ssvA90zRXd0SgqaOlvkwNfBE32uTJkyhc2bN7Nhwwaqqqro378/Q4YM4ctf/jILFiwgFouxfv16Nm3axGGHHZb1HAsWLODqq68GYNKkSUyaNCmzbc6cOdx2220kk0k2btzIihUrWmxv7dlnn+VjH/tYZrbWCy+8kGeeeYbzzz+/W6bojk5QUO8jEWnHrFmzmDt3Lu+99x4XXXQRd911F1VVVSxZsoR4PM7IkSOzTpndnFnbB863336bG2+8kUWLFtG/f38uvfTSTs/TUYmkO6bojkwOmZkQTyUFEWnloosu4p577mHu3LnMmjWLmpoaBg0aRDweZ/78+bzzzjsdHn/KKadw1113AbB8+XKWLVsGwI4dO+jVqxd9+/Zl06ZNLSbXa2/K7lNOOYX777+furo6amtrmTdvHieffPJ+/LUdi05JQVNni0g7Jk6cyM6dOxk2bBhDhgzhU5/6FOeddx5Tp05l8uTJHHXUUR0ef8UVV3DZZZcxadIkJk+ezLRp0wA45phjmDJlChMnTmT06NGceOKJmWNmz57NWWedxZAhQ1q0Kxx77LFceumlmXNcfvnlTJkypdve5mYdFVUORFOnTvXO+v9m8/fX3uP+peu56RNTKMhXYBA5UKxcuZLx48f3dDIOKdmuqZktcfepnR0bmZLCmRMP48yJ2RuJREQkpEdmERHJUFAQkR53sFVjH8j29VoqKIhIjyoqKqK6ulqBYT9wd6qrqykqKuryOSLTpiAiB6aKigoqKyvp6gu0pKWioiIqKiq6fLyCgoj0qHg8zqhRo3o6GZKm6iMREclQUBARkQwFBRERyTjoRjSbWRXQ8UQk7SsDtuzH5BwKdE2y03VpS9ekrYPpmhzu7uWd7XTQBYV9YWaL92SYd5TommSn69KWrklbh+I1UfWRiIhkKCiIiEhG1ILCbT2dgAOQrkl2ui5t6Zq0dchdk0i1KYiISMeiVlIQEZEOKCiIiEhGZIKCmc00s1VmtsbMruvp9PQEMxtuZvPNbKWZvWZmX0yvH2Bmj5nZG+n/9u/ptHY3M8szs5fN7K/p5VFmtjB9Te41s4KeTmN3MrN+ZjbXzF5P3y8fivp9YmZfTv/dLDezu82s6FC8TyIRFMwsD7gFOAuYAFxsZhN6NlU9Iglc4+7jgenAlenrcB3whLuPBZ5IL0fNF4GVzZZ/DPx3+ppsA/6lR1LVc34OPOLuRwHHEF6byN4nZjYMuBqY6u5HA3nARRyC90kkggIwDVjj7m+5eyNwD3BBD6ep27n7Rnd/Kf15J+Ef+jDCa/H79G6/Bz7aMynsGWZWAZwD3J5eNuB0YG56l0hdEzPrA5wC3AHg7o3uvp2I3yeEs0oXm1k+UAJs5BC8T6ISFIYB65otV6bXRZaZjQSmAAuBwe6+EcLAAQzquZT1iJuArwJBenkgsN3dk+nlqN0vo4Eq4LfpKrXbzawXEb5P3H09cCPwLmEwqAGWcAjeJ1EJCpZlXWT74ppZKfBn4EvuvqOn09OTzOxcYLO7L2m+OsuuUbpf8oFjgV+5+xSglghVFWWTbj+5ABgFDAV6EVZHt3bQ3ydRCQqVwPBmyxXAhh5KS48yszhhQLjL3e9Lr95kZkPS24cAm3sqfT3gROB8M1tLWK14OmHJoV+6mgCid79UApXuvjC9PJcwSET5Pvkw8La7V7l7ArgPOIFD8D6JSlBYBIxN9xQoIGwgerCH09Tt0nXldwAr3f1nzTY9CHwm/fkzwAPdnbae4u5fd/cKdx9JeF886e6fAuYDs9K7Re2avAesM7Mj06vOAFYQ4fuEsNpoupmVpP+Omq7JIXefRGZEs5mdTfgEmAfc6e439HCSup2ZnQQ8A7zK+/Xn3yBsV5gDjCC8+f/R3bf2SCJ7kJnNAK5193PNbDRhyWEA8DJwibs39GT6upOZTSZseC8A3gIuI3yIjOx9YmbfAz5B2IvvZeBywjaEQ+o+iUxQEBGRzkWl+khERPaAgoKIiGQoKIiISIaCgoiIZCgoiIhIhoKCSDcysxlNM7GKHIgUFEREJENBQSQLM7vEzF40s6Vmdmv6fQu7zOynZvaSmT1hZuXpfSeb2QtmtszM5jW9Z8DMjjCzx83slfQxY9KnL232roK70iNkRQ4ICgoirZjZeMKRqye6+2QgBXyKcBK0l9z9WOBp4DvpQ/4AfM3dJxGOFm9afxdwi7sfQzhPzsb0+inAlwjf7TGacP4lkQNCfue7iETOGcBxwKL0Q3wx4eRvAXBvep//B9xnZn2Bfu7+dHr974E/mVlvYJi7zwNw990A6fO96O6V6eWlwEjg2dz/LJHOKSiItGXA79396y1Wmv1Hq/06miOmoyqh5nPjpNDfoRxAVH0k0tYTwCwzGwSZd1gfTvj30jQj5ieBZ929BthmZien1/8z8HT6PRWVZvbR9DkKzaykW3+FSBfoCUWkFXdfYWbfAv5uZjEgAVxJ+LKZiWa2hPDNW59IH/IZ4NfpTL9pRlEIA8StZnZ9+hz/2I0/Q6RLNEuqyB4ys13uXtrT6RDJJVUfiYhIhkoKIiKSoZKCiIhkKCiIiEiGgoKIiGQoKIiISIaCgoiIZPx/SHMsf9R/Ch4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for R^2\n",
    "plt.plot(result.history['r_square'])\n",
    "plt.plot(result.history['val_r_square'])\n",
    "plt.title('model R^2')\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.199007\n",
      "Mean squared error (MSE):       0.123450\n",
      "Root mean squared error (RMSE): 0.351355\n",
      "R square (R^2):                 0.998734\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm, math\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_test,predictions))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_test,predictions))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_test,predictions)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try batch normalization technique to regularize neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 911147 samples, validate on 227787 samples\n",
      "Epoch 1/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 12.4884 - rmse: 1.6176 - r_square: 0.8677 - val_loss: 5.5381 - val_rmse: 0.9780 - val_r_square: 0.9411\n",
      "Epoch 2/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 3.6827 - rmse: 0.9593 - r_square: 0.9603 - val_loss: 1.4782 - val_rmse: 0.6185 - val_r_square: 0.9842\n",
      "Epoch 3/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 3.3184 - rmse: 0.9046 - r_square: 0.9642 - val_loss: 1.1629 - val_rmse: 0.6006 - val_r_square: 0.9875\n",
      "Epoch 4/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 3.1695 - rmse: 0.8670 - r_square: 0.9658 - val_loss: 1.1002 - val_rmse: 0.5689 - val_r_square: 0.9882\n",
      "Epoch 5/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 3.1751 - rmse: 0.8643 - r_square: 0.9658 - val_loss: 1.3035 - val_rmse: 0.6099 - val_r_square: 0.9860\n",
      "Epoch 6/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.9854 - rmse: 0.8317 - r_square: 0.9680 - val_loss: 1.4908 - val_rmse: 0.6389 - val_r_square: 0.9843\n",
      "Epoch 7/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.8845 - rmse: 0.8200 - r_square: 0.9691 - val_loss: 0.9750 - val_rmse: 0.4942 - val_r_square: 0.9896\n",
      "Epoch 8/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.8157 - rmse: 0.8114 - r_square: 0.9698 - val_loss: 1.4109 - val_rmse: 0.6734 - val_r_square: 0.9847\n",
      "Epoch 9/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.7335 - rmse: 0.7956 - r_square: 0.9706 - val_loss: 2.6889 - val_rmse: 0.7196 - val_r_square: 0.9714\n",
      "Epoch 10/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.7142 - rmse: 0.7922 - r_square: 0.9708 - val_loss: 0.7562 - val_rmse: 0.4363 - val_r_square: 0.9919\n",
      "Epoch 11/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.7429 - rmse: 0.7885 - r_square: 0.9706 - val_loss: 1.2066 - val_rmse: 0.5639 - val_r_square: 0.9870\n",
      "Epoch 12/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.7113 - rmse: 0.7877 - r_square: 0.9708 - val_loss: 0.9602 - val_rmse: 0.4889 - val_r_square: 0.9897\n",
      "Epoch 13/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.5823 - rmse: 0.7708 - r_square: 0.9723 - val_loss: 1.0580 - val_rmse: 0.5368 - val_r_square: 0.9886\n",
      "Epoch 14/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.5783 - rmse: 0.7677 - r_square: 0.9724 - val_loss: 0.7625 - val_rmse: 0.4819 - val_r_square: 0.9919\n",
      "Epoch 15/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.4942 - rmse: 0.7580 - r_square: 0.9734 - val_loss: 1.0936 - val_rmse: 0.5372 - val_r_square: 0.9883\n",
      "Epoch 16/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.5409 - rmse: 0.7584 - r_square: 0.9728 - val_loss: 0.8155 - val_rmse: 0.4497 - val_r_square: 0.9913\n",
      "Epoch 17/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.5238 - rmse: 0.7561 - r_square: 0.9730 - val_loss: 1.7219 - val_rmse: 0.6238 - val_r_square: 0.9818\n",
      "Epoch 18/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.4426 - rmse: 0.7487 - r_square: 0.9738 - val_loss: 0.8210 - val_rmse: 0.4080 - val_r_square: 0.9913\n",
      "Epoch 19/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.5269 - rmse: 0.7509 - r_square: 0.9729 - val_loss: 1.3429 - val_rmse: 0.5095 - val_r_square: 0.9858\n",
      "Epoch 20/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.5417 - rmse: 0.7582 - r_square: 0.9727 - val_loss: 0.7358 - val_rmse: 0.5359 - val_r_square: 0.9921\n",
      "Epoch 21/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.4406 - rmse: 0.7418 - r_square: 0.9738 - val_loss: 1.4743 - val_rmse: 0.4960 - val_r_square: 0.9845\n",
      "Epoch 22/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.4907 - rmse: 0.7470 - r_square: 0.9733 - val_loss: 0.7465 - val_rmse: 0.4291 - val_r_square: 0.9922\n",
      "Epoch 23/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.4987 - rmse: 0.7446 - r_square: 0.9732 - val_loss: 0.6679 - val_rmse: 0.3869 - val_r_square: 0.9929\n",
      "Epoch 24/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3984 - rmse: 0.7383 - r_square: 0.9742 - val_loss: 0.7533 - val_rmse: 0.4268 - val_r_square: 0.9920\n",
      "Epoch 25/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.4154 - rmse: 0.7332 - r_square: 0.9741 - val_loss: 1.6807 - val_rmse: 0.5851 - val_r_square: 0.9819\n",
      "Epoch 26/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.4322 - rmse: 0.7399 - r_square: 0.9738 - val_loss: 0.5645 - val_rmse: 0.3633 - val_r_square: 0.9940\n",
      "Epoch 27/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3965 - rmse: 0.7284 - r_square: 0.9743 - val_loss: 0.6098 - val_rmse: 0.3526 - val_r_square: 0.9936\n",
      "Epoch 28/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.4300 - rmse: 0.7358 - r_square: 0.9739 - val_loss: 0.8236 - val_rmse: 0.4061 - val_r_square: 0.9913\n",
      "Epoch 29/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.4146 - rmse: 0.7324 - r_square: 0.9741 - val_loss: 0.9368 - val_rmse: 0.5158 - val_r_square: 0.9900\n",
      "Epoch 30/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2439 - rmse: 0.7154 - r_square: 0.9758 - val_loss: 0.7131 - val_rmse: 0.3892 - val_r_square: 0.9924\n",
      "Epoch 31/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3484 - rmse: 0.7232 - r_square: 0.9749 - val_loss: 0.6977 - val_rmse: 0.4001 - val_r_square: 0.9926\n",
      "Epoch 32/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3731 - rmse: 0.7246 - r_square: 0.9744 - val_loss: 0.6713 - val_rmse: 0.3959 - val_r_square: 0.9930\n",
      "Epoch 33/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3041 - rmse: 0.7161 - r_square: 0.9752 - val_loss: 0.5038 - val_rmse: 0.3300 - val_r_square: 0.9947\n",
      "Epoch 34/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.4104 - rmse: 0.7311 - r_square: 0.9742 - val_loss: 0.5086 - val_rmse: 0.3538 - val_r_square: 0.9946\n",
      "Epoch 35/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2981 - rmse: 0.7247 - r_square: 0.9754 - val_loss: 0.5673 - val_rmse: 0.3503 - val_r_square: 0.9940\n",
      "Epoch 36/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3352 - rmse: 0.7200 - r_square: 0.9749 - val_loss: 1.1486 - val_rmse: 0.4615 - val_r_square: 0.9878\n",
      "Epoch 37/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3256 - rmse: 0.7223 - r_square: 0.9751 - val_loss: 0.7050 - val_rmse: 0.3944 - val_r_square: 0.9926\n",
      "Epoch 38/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2747 - rmse: 0.7152 - r_square: 0.9755 - val_loss: 0.5261 - val_rmse: 0.3631 - val_r_square: 0.9944\n",
      "Epoch 39/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3401 - rmse: 0.7206 - r_square: 0.9749 - val_loss: 0.4993 - val_rmse: 0.3593 - val_r_square: 0.9947\n",
      "Epoch 40/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3049 - rmse: 0.7134 - r_square: 0.9752 - val_loss: 0.5286 - val_rmse: 0.3438 - val_r_square: 0.9944\n",
      "Epoch 41/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.3329 - rmse: 0.7168 - r_square: 0.9750 - val_loss: 0.7796 - val_rmse: 0.4500 - val_r_square: 0.9918\n",
      "Epoch 42/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3128 - rmse: 0.7184 - r_square: 0.9751 - val_loss: 0.7803 - val_rmse: 0.4593 - val_r_square: 0.9917\n",
      "Epoch 43/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2578 - rmse: 0.7099 - r_square: 0.9757 - val_loss: 1.1051 - val_rmse: 0.5249 - val_r_square: 0.9881\n",
      "Epoch 44/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3186 - rmse: 0.7199 - r_square: 0.9751 - val_loss: 0.6542 - val_rmse: 0.4069 - val_r_square: 0.9930\n",
      "Epoch 45/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2440 - rmse: 0.7077 - r_square: 0.9760 - val_loss: 0.8406 - val_rmse: 0.4654 - val_r_square: 0.9911\n",
      "Epoch 46/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2681 - rmse: 0.7104 - r_square: 0.9757 - val_loss: 0.7056 - val_rmse: 0.3983 - val_r_square: 0.9925\n",
      "Epoch 47/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2507 - rmse: 0.7025 - r_square: 0.9759 - val_loss: 1.0555 - val_rmse: 0.4990 - val_r_square: 0.9887\n",
      "Epoch 48/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2599 - rmse: 0.7097 - r_square: 0.9758 - val_loss: 0.5232 - val_rmse: 0.3468 - val_r_square: 0.9945\n",
      "Epoch 49/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3414 - rmse: 0.7137 - r_square: 0.9750 - val_loss: 0.6413 - val_rmse: 0.3815 - val_r_square: 0.9932\n",
      "Epoch 50/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2521 - rmse: 0.7047 - r_square: 0.9759 - val_loss: 0.9222 - val_rmse: 0.4751 - val_r_square: 0.9901\n",
      "Epoch 51/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2218 - rmse: 0.7039 - r_square: 0.9761 - val_loss: 0.5752 - val_rmse: 0.3936 - val_r_square: 0.9940\n",
      "Epoch 52/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.3080 - rmse: 0.7167 - r_square: 0.9752 - val_loss: 0.7915 - val_rmse: 0.4440 - val_r_square: 0.9915\n",
      "Epoch 53/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2569 - rmse: 0.7082 - r_square: 0.9757 - val_loss: 0.4939 - val_rmse: 0.3329 - val_r_square: 0.9948\n",
      "Epoch 54/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2483 - rmse: 0.7063 - r_square: 0.9759 - val_loss: 0.6383 - val_rmse: 0.4296 - val_r_square: 0.9934\n",
      "Epoch 55/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2570 - rmse: 0.7094 - r_square: 0.9756 - val_loss: 0.8646 - val_rmse: 0.4196 - val_r_square: 0.9908\n",
      "Epoch 56/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2916 - rmse: 0.7030 - r_square: 0.9754 - val_loss: 0.9638 - val_rmse: 0.5568 - val_r_square: 0.9897\n",
      "Epoch 57/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2693 - rmse: 0.7079 - r_square: 0.9755 - val_loss: 0.9084 - val_rmse: 0.4436 - val_r_square: 0.9903\n",
      "Epoch 58/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2115 - rmse: 0.6985 - r_square: 0.9763 - val_loss: 1.0079 - val_rmse: 0.4659 - val_r_square: 0.9892\n",
      "Epoch 59/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2668 - rmse: 0.7102 - r_square: 0.9756 - val_loss: 0.6714 - val_rmse: 0.3792 - val_r_square: 0.9929\n",
      "Epoch 60/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2284 - rmse: 0.7039 - r_square: 0.9759 - val_loss: 0.8354 - val_rmse: 0.4750 - val_r_square: 0.9913\n",
      "Epoch 61/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.1706 - rmse: 0.6953 - r_square: 0.9767 - val_loss: 0.8830 - val_rmse: 0.4572 - val_r_square: 0.9906\n",
      "Epoch 62/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2239 - rmse: 0.7046 - r_square: 0.9762 - val_loss: 0.7435 - val_rmse: 0.4258 - val_r_square: 0.9921\n",
      "Epoch 63/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2432 - rmse: 0.7065 - r_square: 0.9759 - val_loss: 0.6658 - val_rmse: 0.3709 - val_r_square: 0.9929\n",
      "Epoch 64/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2456 - rmse: 0.7019 - r_square: 0.9762 - val_loss: 0.8811 - val_rmse: 0.5380 - val_r_square: 0.9906\n",
      "Epoch 65/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2473 - rmse: 0.7037 - r_square: 0.9760 - val_loss: 0.7174 - val_rmse: 0.4080 - val_r_square: 0.9923\n",
      "Epoch 66/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2035 - rmse: 0.6985 - r_square: 0.9763 - val_loss: 0.7322 - val_rmse: 0.4606 - val_r_square: 0.9922\n",
      "Epoch 67/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2454 - rmse: 0.7033 - r_square: 0.9760 - val_loss: 0.8201 - val_rmse: 0.4206 - val_r_square: 0.9912\n",
      "Epoch 68/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2405 - rmse: 0.7005 - r_square: 0.9757 - val_loss: 0.6213 - val_rmse: 0.4193 - val_r_square: 0.9934\n",
      "Epoch 69/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.1914 - rmse: 0.6958 - r_square: 0.9764 - val_loss: 0.7739 - val_rmse: 0.4508 - val_r_square: 0.9918\n",
      "Epoch 70/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.1891 - rmse: 0.6992 - r_square: 0.9765 - val_loss: 0.6886 - val_rmse: 0.3795 - val_r_square: 0.9927\n",
      "Epoch 71/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.1800 - rmse: 0.6934 - r_square: 0.9768 - val_loss: 0.7637 - val_rmse: 0.3993 - val_r_square: 0.9919\n",
      "Epoch 72/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2047 - rmse: 0.6988 - r_square: 0.9764 - val_loss: 0.6414 - val_rmse: 0.4347 - val_r_square: 0.9932\n",
      "Epoch 73/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2157 - rmse: 0.7040 - r_square: 0.9762 - val_loss: 0.9604 - val_rmse: 0.4305 - val_r_square: 0.9898\n",
      "Epoch 74/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2362 - rmse: 0.7057 - r_square: 0.9759 - val_loss: 0.7040 - val_rmse: 0.3790 - val_r_square: 0.9926\n",
      "Epoch 75/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.1829 - rmse: 0.6988 - r_square: 0.9766 - val_loss: 0.8226 - val_rmse: 0.4099 - val_r_square: 0.9914\n",
      "Epoch 76/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2156 - rmse: 0.7026 - r_square: 0.9761 - val_loss: 0.6760 - val_rmse: 0.4223 - val_r_square: 0.9928\n",
      "Epoch 77/200\n",
      "911147/911147 [==============================] - 5s 6us/step - loss: 2.1646 - rmse: 0.6942 - r_square: 0.9768 - val_loss: 0.7266 - val_rmse: 0.4095 - val_r_square: 0.9923\n",
      "Epoch 78/200\n",
      "911147/911147 [==============================] - 5s 5us/step - loss: 2.2034 - rmse: 0.6944 - r_square: 0.9762 - val_loss: 0.6745 - val_rmse: 0.3849 - val_r_square: 0.9929\n",
      "Epoch 00078: early stopping\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model3.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result3 = model3.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.7645283e+00]\n",
      " [ 1.7856395e-01]\n",
      " [ 2.4396765e+01]\n",
      " [-1.6550899e-02]\n",
      " [ 6.1647387e+00]\n",
      " [ 9.1036761e-01]\n",
      " [ 6.8106346e+00]\n",
      " [ 9.2254996e-02]\n",
      " [ 1.0353720e+00]\n",
      " [ 6.9386244e+00]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.386960\n",
      "Mean squared error (MSE):       0.673518\n",
      "Root mean squared error (RMSE): 0.820682\n",
      "R square (R^2):                 0.993094\n"
     ]
    }
   ],
   "source": [
    "predictions3 = model3.predict(X_test)\n",
    "print(predictions3[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_test,predictions3))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_test,predictions3))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_test,predictions3)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_test,predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference: \n",
    "&emsp;&emsp;What does 'Accuracy' mean in Regression? https://github.com/keras-team/keras/issues/7947 <br>\n",
    "&emsp;&emsp;https://keras.io/metrics/<br>\n",
    "&emsp;&emsp;Scale, Standardize, or Normalize with Scikit-Learn https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02 <br>\n",
    "&emsp;&emsp;The Day my Computer Won the Nobel Prize (Neural Network Option Pricing)  https://medium.com/datadriveninvestor/the-day-my-computer-won-the-nobel-prize-neural-network-option-pricing-d29b4379f1d2 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
