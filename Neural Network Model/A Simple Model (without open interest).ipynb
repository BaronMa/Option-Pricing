{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl (1.4MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-19.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: pyyaml in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/58/34bfa8fa17f86333361172b3b502e805195180f19a7496ad0f6149138d55/tensorflow-1.13.1-cp36-cp36m-win_amd64.whl (63.1MB)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/59/ec6c6075dd628f2efd33dbe11b259e63e1de7cbc26e45b38de767df528d4/protobuf-3.8.0-cp36-cp36m-win_amd64.whl (1.1MB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/6a/e83233ed636bdf8668f0e79897fd70bce04869482dd88f3cfc4c42404fb2/grpcio-1.21.1-cp36-cp36m-win_amd64.whl (1.6MB)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.3)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: termcolor, gast, absl-py\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\ee\\98\\38\\46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "Successfully built termcolor gast absl-py\n",
      "Installing collected packages: protobuf, termcolor, gast, absl-py, grpcio, astor, markdown, tensorboard, mock, tensorflow-estimator, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 grpcio-1.21.1 markdown-3.1.1 mock-3.0.5 protobuf-3.8.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading https://files.pythonhosted.org/packages/20/ed/e036d31a9b2c750f270cbb1cfc1c0f94ac78ae504eea7eec3267be4e294a/numpy-1.16.4-cp36-cp36m-win_amd64.whl (11.9MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.16.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "!pip install --user keras\n",
    "!pip install --user tensorflow\n",
    "!pip install --user -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and do data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_withoutNaN.csv')\n",
    "df.drop(['Unnamed: 0', 'Open Interest for the Option', 'The Date of this Price', 'Expiration Date of the Option'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strike Price</th>\n",
       "      <th>Lowest  Closing Ask Across All Exchanges</th>\n",
       "      <th>Implied Volatility of the Option</th>\n",
       "      <th>Underlying Price</th>\n",
       "      <th>maturity</th>\n",
       "      <th>C=Call, P=Put_C</th>\n",
       "      <th>C=Call, P=Put_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590.0</td>\n",
       "      <td>85.50</td>\n",
       "      <td>0.636391</td>\n",
       "      <td>674.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>610.0</td>\n",
       "      <td>65.45</td>\n",
       "      <td>0.495483</td>\n",
       "      <td>674.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>615.0</td>\n",
       "      <td>60.25</td>\n",
       "      <td>0.408294</td>\n",
       "      <td>674.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>620.0</td>\n",
       "      <td>55.25</td>\n",
       "      <td>0.376411</td>\n",
       "      <td>674.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625.0</td>\n",
       "      <td>50.25</td>\n",
       "      <td>0.363375</td>\n",
       "      <td>674.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Strike Price  Lowest  Closing Ask Across All Exchanges  \\\n",
       "0         590.0                                     85.50   \n",
       "1         610.0                                     65.45   \n",
       "2         615.0                                     60.25   \n",
       "3         620.0                                     55.25   \n",
       "4         625.0                                     50.25   \n",
       "\n",
       "   Implied Volatility of the Option  Underlying Price  maturity  \\\n",
       "0                          0.636391            674.97         3   \n",
       "1                          0.495483            674.97         3   \n",
       "2                          0.408294            674.97         3   \n",
       "3                          0.376411            674.97         3   \n",
       "4                          0.363375            674.97         3   \n",
       "\n",
       "   C=Call, P=Put_C  C=Call, P=Put_P  \n",
       "0                1                0  \n",
       "1                1                0  \n",
       "2                1                0  \n",
       "3                1                0  \n",
       "4                1                0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Lowest  Closing Ask Across All Exchanges'].values\n",
    "df.drop(['Lowest  Closing Ask Across All Exchanges'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to build a regression neural network model\n",
    "sc= preprocessing.MinMaxScaler()\n",
    "X= sc.fit_transform(df)\n",
    "y= y.reshape(-1,1)\n",
    "y=sc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487123, 6)\n",
      "(487123, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XX_train, XX_validation, yy_train, yy_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built Keras sequential model with 3 hidden layer, and after the first hidden layer, dropout 25% neurons.\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(6,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable early stopping based on the loss of validation data\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is a simple regression problem, we should custom metrics function\n",
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1))\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean_squared_error to compile regression model loss\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 487123 samples, validate on 239927 samples\n",
      "Epoch 1/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 4.5229e-04 - rmse: 0.0077 - r_square: 0.9821 - val_loss: 6.0664e-05 - val_rmse: 0.0049 - val_r_square: 0.9975\n",
      "Epoch 2/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.6905e-05 - rmse: 0.0036 - r_square: 0.9989 - val_loss: 3.7201e-05 - val_rmse: 0.0047 - val_r_square: 0.9985\n",
      "Epoch 3/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.7087e-05 - rmse: 0.0029 - r_square: 0.9993 - val_loss: 2.3812e-05 - val_rmse: 0.0040 - val_r_square: 0.9990\n",
      "Epoch 4/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3028e-05 - rmse: 0.0026 - r_square: 0.9995 - val_loss: 7.1861e-06 - val_rmse: 0.0019 - val_r_square: 0.9997\n",
      "Epoch 5/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4173e-05 - rmse: 0.0024 - r_square: 0.9994 - val_loss: 5.1523e-06 - val_rmse: 0.0016 - val_r_square: 0.9998\n",
      "Epoch 6/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 7.5247e-06 - rmse: 0.0020 - r_square: 0.9997 - val_loss: 6.3031e-06 - val_rmse: 0.0019 - val_r_square: 0.9997\n",
      "Epoch 7/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 6.8365e-06 - rmse: 0.0019 - r_square: 0.9997 - val_loss: 4.1810e-06 - val_rmse: 0.0015 - val_r_square: 0.9998\n",
      "Epoch 8/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 5.9207e-06 - rmse: 0.0018 - r_square: 0.9998 - val_loss: 4.1420e-06 - val_rmse: 0.0014 - val_r_square: 0.9998\n",
      "Epoch 9/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.9469e-06 - rmse: 0.0016 - r_square: 0.9998 - val_loss: 2.4766e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 10/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 7.1678e-06 - rmse: 0.0017 - r_square: 0.9997 - val_loss: 3.0106e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 11/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.2294e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 5.1102e-06 - val_rmse: 0.0016 - val_r_square: 0.9998\n",
      "Epoch 12/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.2345e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 5.3267e-06 - val_rmse: 0.0018 - val_r_square: 0.9998\n",
      "Epoch 13/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 3.5457e-06 - rmse: 0.0013 - r_square: 0.9999 - val_loss: 2.4728e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 14/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 3.6452e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 3.8953e-06 - val_rmse: 0.0016 - val_r_square: 0.9998\n",
      "Epoch 15/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 6.4521e-06 - rmse: 0.0015 - r_square: 0.9997 - val_loss: 8.7421e-06 - val_rmse: 0.0022 - val_r_square: 0.9996\n",
      "Epoch 16/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 3.0418e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 2.7059e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 17/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.9400e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 3.3288e-06 - val_rmse: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 18/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.8492e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 2.5950e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 19/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.8024e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 3.2361e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 20/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.7185e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 1.1727e-06 - val_rmse: 7.6919e-04 - val_r_square: 1.0000\n",
      "Epoch 21/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.3907e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 2.5043e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 22/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.4870e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 5.3328e-06 - val_rmse: 0.0017 - val_r_square: 0.9998\n",
      "Epoch 23/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.5079e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.1235e-06 - val_rmse: 7.3231e-04 - val_r_square: 1.0000\n",
      "Epoch 24/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.3633e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 3.0404e-06 - val_rmse: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 25/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.6524e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.6481e-05 - val_rmse: 0.0028 - val_r_square: 0.9993\n",
      "Epoch 26/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.6648e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.7454e-06 - val_rmse: 8.5236e-04 - val_r_square: 0.9999\n",
      "Epoch 27/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.1990e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 2.2875e-06 - val_rmse: 9.9675e-04 - val_r_square: 0.9999\n",
      "Epoch 28/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.1636e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 2.0918e-06 - val_rmse: 9.7274e-04 - val_r_square: 0.9999\n",
      "Epoch 29/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.0223e-06 - rmse: 9.7122e-04 - r_square: 0.9999 - val_loss: 4.6319e-06 - val_rmse: 0.0016 - val_r_square: 0.9998\n",
      "Epoch 30/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.1242e-06 - rmse: 9.9783e-04 - r_square: 0.9999 - val_loss: 1.2230e-06 - val_rmse: 7.6601e-04 - val_r_square: 0.9999\n",
      "Epoch 31/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.0480e-06 - rmse: 9.7414e-04 - r_square: 0.9999 - val_loss: 1.9541e-06 - val_rmse: 9.5248e-04 - val_r_square: 0.9999\n",
      "Epoch 32/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.9632e-06 - rmse: 9.5601e-04 - r_square: 0.9999 - val_loss: 9.2161e-07 - val_rmse: 6.3902e-04 - val_r_square: 1.0000\n",
      "Epoch 33/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 2.0015e-06 - rmse: 9.5951e-04 - r_square: 0.9999 - val_loss: 2.9710e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 34/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.8557e-06 - rmse: 9.2705e-04 - r_square: 0.9999 - val_loss: 1.4835e-06 - val_rmse: 8.4511e-04 - val_r_square: 0.9999\n",
      "Epoch 35/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.8961e-06 - rmse: 9.2219e-04 - r_square: 0.9999 - val_loss: 1.2511e-06 - val_rmse: 8.2923e-04 - val_r_square: 0.9999\n",
      "Epoch 36/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.7501e-06 - rmse: 9.0775e-04 - r_square: 0.9999 - val_loss: 1.0594e-06 - val_rmse: 7.3595e-04 - val_r_square: 1.0000\n",
      "Epoch 37/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.7962e-06 - rmse: 9.0950e-04 - r_square: 0.9999 - val_loss: 1.3483e-06 - val_rmse: 7.4728e-04 - val_r_square: 0.9999\n",
      "Epoch 38/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.8638e-06 - rmse: 9.1000e-04 - r_square: 0.9999 - val_loss: 1.0744e-06 - val_rmse: 7.2372e-04 - val_r_square: 1.0000\n",
      "Epoch 39/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.7660e-06 - rmse: 8.9463e-04 - r_square: 0.9999 - val_loss: 1.1042e-06 - val_rmse: 7.5136e-04 - val_r_square: 1.0000\n",
      "Epoch 40/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.8181e-06 - rmse: 9.1088e-04 - r_square: 0.9999 - val_loss: 9.0004e-07 - val_rmse: 6.5433e-04 - val_r_square: 1.0000\n",
      "Epoch 41/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.7008e-06 - rmse: 8.7586e-04 - r_square: 0.9999 - val_loss: 1.1545e-06 - val_rmse: 7.4419e-04 - val_r_square: 1.0000\n",
      "Epoch 42/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.6875e-06 - rmse: 8.7681e-04 - r_square: 0.9999 - val_loss: 1.1160e-06 - val_rmse: 7.3246e-04 - val_r_square: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.6361e-06 - rmse: 8.6314e-04 - r_square: 0.9999 - val_loss: 1.8090e-06 - val_rmse: 8.8276e-04 - val_r_square: 0.9999\n",
      "Epoch 44/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.7165e-06 - rmse: 8.7436e-04 - r_square: 0.9999 - val_loss: 1.0365e-06 - val_rmse: 6.8585e-04 - val_r_square: 1.0000\n",
      "Epoch 45/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.7056e-06 - rmse: 8.7164e-04 - r_square: 0.9999 - val_loss: 1.7651e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 46/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.5650e-06 - rmse: 8.3403e-04 - r_square: 0.9999 - val_loss: 1.5877e-06 - val_rmse: 8.7818e-04 - val_r_square: 0.9999\n",
      "Epoch 47/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.6592e-06 - rmse: 8.6192e-04 - r_square: 0.9999 - val_loss: 1.4115e-06 - val_rmse: 8.2919e-04 - val_r_square: 0.9999\n",
      "Epoch 48/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.6140e-06 - rmse: 8.3537e-04 - r_square: 0.9999 - val_loss: 1.6055e-06 - val_rmse: 8.5667e-04 - val_r_square: 0.9999\n",
      "Epoch 49/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.5011e-06 - rmse: 8.2046e-04 - r_square: 0.9999 - val_loss: 8.3831e-07 - val_rmse: 6.2536e-04 - val_r_square: 1.0000\n",
      "Epoch 50/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.6482e-06 - rmse: 8.5549e-04 - r_square: 0.9999 - val_loss: 8.5849e-07 - val_rmse: 6.3254e-04 - val_r_square: 1.0000\n",
      "Epoch 51/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.5569e-06 - rmse: 8.3357e-04 - r_square: 0.9999 - val_loss: 4.6769e-06 - val_rmse: 0.0015 - val_r_square: 0.9998\n",
      "Epoch 52/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4819e-06 - rmse: 8.1225e-04 - r_square: 0.9999 - val_loss: 1.1772e-06 - val_rmse: 7.4525e-04 - val_r_square: 1.0000\n",
      "Epoch 53/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.5505e-06 - rmse: 8.3557e-04 - r_square: 0.9999 - val_loss: 9.5631e-07 - val_rmse: 6.2407e-04 - val_r_square: 1.0000\n",
      "Epoch 54/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4324e-06 - rmse: 7.9112e-04 - r_square: 0.9999 - val_loss: 9.4437e-07 - val_rmse: 6.7262e-04 - val_r_square: 1.0000\n",
      "Epoch 55/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.5035e-06 - rmse: 8.1091e-04 - r_square: 0.9999 - val_loss: 4.8352e-06 - val_rmse: 0.0017 - val_r_square: 0.9998\n",
      "Epoch 56/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4708e-06 - rmse: 8.0601e-04 - r_square: 0.9999 - val_loss: 1.8727e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 57/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4708e-06 - rmse: 8.0195e-04 - r_square: 0.9999 - val_loss: 1.9572e-06 - val_rmse: 8.8536e-04 - val_r_square: 0.9999\n",
      "Epoch 58/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4241e-06 - rmse: 7.8993e-04 - r_square: 0.9999 - val_loss: 2.0807e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 59/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.5122e-06 - rmse: 8.1124e-04 - r_square: 0.9999 - val_loss: 1.0251e-06 - val_rmse: 6.6959e-04 - val_r_square: 1.0000\n",
      "Epoch 60/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4537e-06 - rmse: 7.9560e-04 - r_square: 0.9999 - val_loss: 1.6277e-06 - val_rmse: 8.4645e-04 - val_r_square: 0.9999\n",
      "Epoch 61/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4174e-06 - rmse: 7.9242e-04 - r_square: 0.9999 - val_loss: 1.4455e-06 - val_rmse: 8.2568e-04 - val_r_square: 0.9999\n",
      "Epoch 62/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3970e-06 - rmse: 7.7739e-04 - r_square: 0.9999 - val_loss: 9.9644e-07 - val_rmse: 6.6987e-04 - val_r_square: 1.0000\n",
      "Epoch 63/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4132e-06 - rmse: 7.8110e-04 - r_square: 0.9999 - val_loss: 9.6447e-07 - val_rmse: 6.7535e-04 - val_r_square: 1.0000\n",
      "Epoch 64/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3558e-06 - rmse: 7.6892e-04 - r_square: 0.9999 - val_loss: 8.3741e-07 - val_rmse: 6.1012e-04 - val_r_square: 1.0000\n",
      "Epoch 65/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3502e-06 - rmse: 7.6304e-04 - r_square: 0.9999 - val_loss: 1.3333e-06 - val_rmse: 7.9809e-04 - val_r_square: 0.9999\n",
      "Epoch 66/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3278e-06 - rmse: 7.6075e-04 - r_square: 0.9999 - val_loss: 2.8571e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 67/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.5177e-06 - rmse: 7.8758e-04 - r_square: 0.9999 - val_loss: 1.1114e-06 - val_rmse: 7.5514e-04 - val_r_square: 1.0000\n",
      "Epoch 68/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.4017e-06 - rmse: 7.7093e-04 - r_square: 0.9999 - val_loss: 1.8902e-06 - val_rmse: 8.8950e-04 - val_r_square: 0.9999\n",
      "Epoch 69/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2750e-06 - rmse: 7.4664e-04 - r_square: 0.9999 - val_loss: 1.0511e-06 - val_rmse: 6.6590e-04 - val_r_square: 1.0000\n",
      "Epoch 70/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3317e-06 - rmse: 7.5962e-04 - r_square: 0.9999 - val_loss: 1.3465e-06 - val_rmse: 7.6266e-04 - val_r_square: 0.9999\n",
      "Epoch 71/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3186e-06 - rmse: 7.5278e-04 - r_square: 0.9999 - val_loss: 7.9335e-07 - val_rmse: 5.9199e-04 - val_r_square: 1.0000\n",
      "Epoch 72/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3982e-06 - rmse: 7.7537e-04 - r_square: 0.9999 - val_loss: 2.7475e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 73/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3835e-06 - rmse: 7.5764e-04 - r_square: 0.9999 - val_loss: 2.7526e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 74/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3743e-06 - rmse: 7.5236e-04 - r_square: 0.9999 - val_loss: 8.2325e-07 - val_rmse: 5.9782e-04 - val_r_square: 1.0000\n",
      "Epoch 75/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2644e-06 - rmse: 7.3932e-04 - r_square: 0.9999 - val_loss: 2.4511e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 76/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3165e-06 - rmse: 7.5068e-04 - r_square: 0.9999 - val_loss: 1.0853e-06 - val_rmse: 7.5617e-04 - val_r_square: 1.0000\n",
      "Epoch 77/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2491e-06 - rmse: 7.3948e-04 - r_square: 0.9999 - val_loss: 8.6454e-07 - val_rmse: 6.2260e-04 - val_r_square: 1.0000\n",
      "Epoch 78/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.3049e-06 - rmse: 7.4419e-04 - r_square: 0.9999 - val_loss: 1.0295e-06 - val_rmse: 6.4415e-04 - val_r_square: 1.0000\n",
      "Epoch 79/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2955e-06 - rmse: 7.4894e-04 - r_square: 0.9999 - val_loss: 1.1037e-06 - val_rmse: 7.0679e-04 - val_r_square: 1.0000\n",
      "Epoch 80/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2923e-06 - rmse: 7.4479e-04 - r_square: 0.9999 - val_loss: 7.0836e-07 - val_rmse: 5.5559e-04 - val_r_square: 1.0000\n",
      "Epoch 81/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2876e-06 - rmse: 7.4150e-04 - r_square: 0.9999 - val_loss: 9.4717e-07 - val_rmse: 6.3053e-04 - val_r_square: 1.0000\n",
      "Epoch 82/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2879e-06 - rmse: 7.4616e-04 - r_square: 0.9999 - val_loss: 7.8256e-07 - val_rmse: 5.7040e-04 - val_r_square: 1.0000\n",
      "Epoch 83/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2582e-06 - rmse: 7.3459e-04 - r_square: 0.9999 - val_loss: 1.0610e-06 - val_rmse: 7.2319e-04 - val_r_square: 1.0000\n",
      "Epoch 84/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2608e-06 - rmse: 7.2794e-04 - r_square: 0.9999 - val_loss: 9.7427e-07 - val_rmse: 6.3954e-04 - val_r_square: 1.0000\n",
      "Epoch 85/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1763e-06 - rmse: 7.1774e-04 - r_square: 1.0000 - val_loss: 8.0038e-07 - val_rmse: 5.7679e-04 - val_r_square: 1.0000\n",
      "Epoch 86/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2599e-06 - rmse: 7.2935e-04 - r_square: 0.9999 - val_loss: 9.3013e-07 - val_rmse: 5.8603e-04 - val_r_square: 1.0000\n",
      "Epoch 87/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1883e-06 - rmse: 7.1399e-04 - r_square: 1.0000 - val_loss: 7.8514e-07 - val_rmse: 6.0219e-04 - val_r_square: 1.0000\n",
      "Epoch 88/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2742e-06 - rmse: 7.2773e-04 - r_square: 0.9999 - val_loss: 8.0128e-07 - val_rmse: 5.8727e-04 - val_r_square: 1.0000\n",
      "Epoch 89/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2722e-06 - rmse: 7.4130e-04 - r_square: 0.9999 - val_loss: 7.0093e-07 - val_rmse: 5.2898e-04 - val_r_square: 1.0000\n",
      "Epoch 90/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1346e-06 - rmse: 6.9460e-04 - r_square: 1.0000 - val_loss: 1.0377e-06 - val_rmse: 7.4577e-04 - val_r_square: 1.0000\n",
      "Epoch 91/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1334e-06 - rmse: 7.0072e-04 - r_square: 1.0000 - val_loss: 1.0881e-06 - val_rmse: 7.0153e-04 - val_r_square: 1.0000\n",
      "Epoch 92/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1826e-06 - rmse: 7.1171e-04 - r_square: 1.0000 - val_loss: 8.4832e-07 - val_rmse: 6.1791e-04 - val_r_square: 1.0000\n",
      "Epoch 93/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2672e-06 - rmse: 7.2697e-04 - r_square: 0.9999 - val_loss: 1.4471e-06 - val_rmse: 8.4609e-04 - val_r_square: 0.9999\n",
      "Epoch 94/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1475e-06 - rmse: 7.0024e-04 - r_square: 1.0000 - val_loss: 9.9207e-07 - val_rmse: 6.7267e-04 - val_r_square: 1.0000\n",
      "Epoch 95/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2119e-06 - rmse: 7.1204e-04 - r_square: 1.0000 - val_loss: 1.1516e-06 - val_rmse: 7.2121e-04 - val_r_square: 1.0000\n",
      "Epoch 96/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1707e-06 - rmse: 7.0521e-04 - r_square: 1.0000 - val_loss: 1.0619e-06 - val_rmse: 6.9788e-04 - val_r_square: 1.0000\n",
      "Epoch 97/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1752e-06 - rmse: 7.1013e-04 - r_square: 1.0000 - val_loss: 6.5860e-07 - val_rmse: 5.0633e-04 - val_r_square: 1.0000\n",
      "Epoch 98/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1870e-06 - rmse: 7.1031e-04 - r_square: 1.0000 - val_loss: 1.4824e-06 - val_rmse: 7.7439e-04 - val_r_square: 0.9999\n",
      "Epoch 99/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1724e-06 - rmse: 7.0776e-04 - r_square: 1.0000 - val_loss: 8.7243e-07 - val_rmse: 6.2340e-04 - val_r_square: 1.0000\n",
      "Epoch 100/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1807e-06 - rmse: 7.0832e-04 - r_square: 1.0000 - val_loss: 2.0513e-06 - val_rmse: 9.5946e-04 - val_r_square: 0.9999\n",
      "Epoch 101/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1403e-06 - rmse: 6.9784e-04 - r_square: 1.0000 - val_loss: 1.4065e-06 - val_rmse: 7.8013e-04 - val_r_square: 0.9999\n",
      "Epoch 102/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1851e-06 - rmse: 7.0490e-04 - r_square: 1.0000 - val_loss: 1.0471e-06 - val_rmse: 6.5764e-04 - val_r_square: 1.0000\n",
      "Epoch 103/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1593e-06 - rmse: 6.9895e-04 - r_square: 1.0000 - val_loss: 2.1668e-06 - val_rmse: 9.5737e-04 - val_r_square: 0.9999\n",
      "Epoch 104/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.2167e-06 - rmse: 7.0838e-04 - r_square: 0.9999 - val_loss: 9.7284e-07 - val_rmse: 6.8768e-04 - val_r_square: 1.0000\n",
      "Epoch 105/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1816e-06 - rmse: 7.1290e-04 - r_square: 1.0000 - val_loss: 8.2813e-07 - val_rmse: 5.8629e-04 - val_r_square: 1.0000\n",
      "Epoch 106/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1095e-06 - rmse: 6.8944e-04 - r_square: 1.0000 - val_loss: 1.0025e-06 - val_rmse: 6.3945e-04 - val_r_square: 1.0000\n",
      "Epoch 107/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1307e-06 - rmse: 6.9312e-04 - r_square: 1.0000 - val_loss: 7.5152e-07 - val_rmse: 5.8321e-04 - val_r_square: 1.0000\n",
      "Epoch 108/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1476e-06 - rmse: 6.9550e-04 - r_square: 1.0000 - val_loss: 8.8853e-07 - val_rmse: 6.2468e-04 - val_r_square: 1.0000\n",
      "Epoch 109/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1700e-06 - rmse: 7.0714e-04 - r_square: 1.0000 - val_loss: 8.7685e-07 - val_rmse: 6.0929e-04 - val_r_square: 1.0000\n",
      "Epoch 110/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1339e-06 - rmse: 6.9126e-04 - r_square: 1.0000 - val_loss: 1.4644e-06 - val_rmse: 8.0193e-04 - val_r_square: 0.9999\n",
      "Epoch 111/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1187e-06 - rmse: 6.9037e-04 - r_square: 1.0000 - val_loss: 8.6681e-07 - val_rmse: 6.1056e-04 - val_r_square: 1.0000\n",
      "Epoch 112/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1662e-06 - rmse: 6.9694e-04 - r_square: 1.0000 - val_loss: 8.9830e-07 - val_rmse: 6.2712e-04 - val_r_square: 1.0000\n",
      "Epoch 113/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0868e-06 - rmse: 6.7414e-04 - r_square: 1.0000 - val_loss: 8.8367e-07 - val_rmse: 6.0644e-04 - val_r_square: 1.0000\n",
      "Epoch 114/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0805e-06 - rmse: 6.7456e-04 - r_square: 1.0000 - val_loss: 9.6825e-07 - val_rmse: 6.2543e-04 - val_r_square: 1.0000\n",
      "Epoch 115/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1093e-06 - rmse: 6.8669e-04 - r_square: 1.0000 - val_loss: 9.4879e-07 - val_rmse: 6.4596e-04 - val_r_square: 1.0000\n",
      "Epoch 116/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1164e-06 - rmse: 6.8323e-04 - r_square: 1.0000 - val_loss: 1.1396e-06 - val_rmse: 7.0430e-04 - val_r_square: 1.0000\n",
      "Epoch 117/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1262e-06 - rmse: 6.9565e-04 - r_square: 1.0000 - val_loss: 8.7277e-07 - val_rmse: 5.7666e-04 - val_r_square: 1.0000\n",
      "Epoch 118/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1037e-06 - rmse: 6.8409e-04 - r_square: 1.0000 - val_loss: 7.1234e-07 - val_rmse: 5.4928e-04 - val_r_square: 1.0000\n",
      "Epoch 119/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1917e-06 - rmse: 6.9819e-04 - r_square: 1.0000 - val_loss: 7.4476e-07 - val_rmse: 5.8170e-04 - val_r_square: 1.0000\n",
      "Epoch 120/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0035e-06 - rmse: 6.5270e-04 - r_square: 1.0000 - val_loss: 7.2141e-07 - val_rmse: 5.6976e-04 - val_r_square: 1.0000\n",
      "Epoch 121/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1148e-06 - rmse: 6.8536e-04 - r_square: 1.0000 - val_loss: 7.6254e-07 - val_rmse: 5.7055e-04 - val_r_square: 1.0000\n",
      "Epoch 122/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1223e-06 - rmse: 6.8531e-04 - r_square: 1.0000 - val_loss: 1.2151e-06 - val_rmse: 8.3822e-04 - val_r_square: 0.9999\n",
      "Epoch 123/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0887e-06 - rmse: 6.8057e-04 - r_square: 1.0000 - val_loss: 8.3879e-07 - val_rmse: 6.1554e-04 - val_r_square: 1.0000\n",
      "Epoch 124/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0930e-06 - rmse: 6.7986e-04 - r_square: 1.0000 - val_loss: 7.5946e-07 - val_rmse: 5.7901e-04 - val_r_square: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0515e-06 - rmse: 6.6591e-04 - r_square: 1.0000 - val_loss: 7.3642e-07 - val_rmse: 5.7498e-04 - val_r_square: 1.0000\n",
      "Epoch 126/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1308e-06 - rmse: 6.8841e-04 - r_square: 1.0000 - val_loss: 8.8690e-07 - val_rmse: 6.1736e-04 - val_r_square: 1.0000\n",
      "Epoch 127/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0801e-06 - rmse: 6.7411e-04 - r_square: 1.0000 - val_loss: 6.8010e-07 - val_rmse: 5.4489e-04 - val_r_square: 1.0000\n",
      "Epoch 128/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1159e-06 - rmse: 6.8319e-04 - r_square: 1.0000 - val_loss: 1.2348e-06 - val_rmse: 7.7387e-04 - val_r_square: 0.9999\n",
      "Epoch 129/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0613e-06 - rmse: 6.6457e-04 - r_square: 1.0000 - val_loss: 1.0822e-06 - val_rmse: 6.6602e-04 - val_r_square: 1.0000\n",
      "Epoch 130/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.1345e-06 - rmse: 6.8298e-04 - r_square: 1.0000 - val_loss: 1.1245e-06 - val_rmse: 7.2923e-04 - val_r_square: 1.0000\n",
      "Epoch 131/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0956e-06 - rmse: 6.7719e-04 - r_square: 1.0000 - val_loss: 1.1253e-06 - val_rmse: 7.3862e-04 - val_r_square: 1.0000\n",
      "Epoch 132/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0178e-06 - rmse: 6.5752e-04 - r_square: 1.0000 - val_loss: 1.0436e-06 - val_rmse: 6.5484e-04 - val_r_square: 1.0000\n",
      "Epoch 133/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0490e-06 - rmse: 6.6546e-04 - r_square: 1.0000 - val_loss: 1.0148e-06 - val_rmse: 6.7169e-04 - val_r_square: 1.0000\n",
      "Epoch 134/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0958e-06 - rmse: 6.7729e-04 - r_square: 1.0000 - val_loss: 1.4168e-06 - val_rmse: 8.1934e-04 - val_r_square: 0.9999\n",
      "Epoch 135/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0846e-06 - rmse: 6.7230e-04 - r_square: 1.0000 - val_loss: 7.4559e-07 - val_rmse: 5.7471e-04 - val_r_square: 1.0000\n",
      "Epoch 136/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0626e-06 - rmse: 6.7189e-04 - r_square: 1.0000 - val_loss: 8.0449e-07 - val_rmse: 5.7125e-04 - val_r_square: 1.0000\n",
      "Epoch 137/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0348e-06 - rmse: 6.5977e-04 - r_square: 1.0000 - val_loss: 1.4307e-06 - val_rmse: 8.3794e-04 - val_r_square: 0.9999\n",
      "Epoch 138/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0477e-06 - rmse: 6.6838e-04 - r_square: 1.0000 - val_loss: 1.1061e-06 - val_rmse: 7.1988e-04 - val_r_square: 1.0000\n",
      "Epoch 139/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0817e-06 - rmse: 6.7287e-04 - r_square: 1.0000 - val_loss: 6.5316e-07 - val_rmse: 5.2852e-04 - val_r_square: 1.0000\n",
      "Epoch 140/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0713e-06 - rmse: 6.7181e-04 - r_square: 1.0000 - val_loss: 7.0410e-07 - val_rmse: 5.5327e-04 - val_r_square: 1.0000\n",
      "Epoch 141/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0830e-06 - rmse: 6.7084e-04 - r_square: 1.0000 - val_loss: 7.6534e-07 - val_rmse: 5.7349e-04 - val_r_square: 1.0000\n",
      "Epoch 142/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0063e-06 - rmse: 6.4832e-04 - r_square: 1.0000 - val_loss: 9.6871e-07 - val_rmse: 6.4275e-04 - val_r_square: 1.0000\n",
      "Epoch 143/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0845e-06 - rmse: 6.7180e-04 - r_square: 1.0000 - val_loss: 1.1041e-06 - val_rmse: 6.6923e-04 - val_r_square: 1.0000\n",
      "Epoch 144/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0431e-06 - rmse: 6.5563e-04 - r_square: 1.0000 - val_loss: 6.5504e-07 - val_rmse: 5.1223e-04 - val_r_square: 1.0000\n",
      "Epoch 145/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0539e-06 - rmse: 6.6378e-04 - r_square: 1.0000 - val_loss: 6.8347e-07 - val_rmse: 5.3420e-04 - val_r_square: 1.0000\n",
      "Epoch 146/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.9620e-07 - rmse: 6.4595e-04 - r_square: 1.0000 - val_loss: 7.1364e-07 - val_rmse: 5.2911e-04 - val_r_square: 1.0000\n",
      "Epoch 147/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0216e-06 - rmse: 6.5389e-04 - r_square: 1.0000 - val_loss: 8.9462e-07 - val_rmse: 6.1693e-04 - val_r_square: 1.0000\n",
      "Epoch 148/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0506e-06 - rmse: 6.6174e-04 - r_square: 1.0000 - val_loss: 7.7050e-07 - val_rmse: 5.8355e-04 - val_r_square: 1.0000\n",
      "Epoch 149/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0128e-06 - rmse: 6.5029e-04 - r_square: 1.0000 - val_loss: 1.4210e-06 - val_rmse: 7.4460e-04 - val_r_square: 0.9999\n",
      "Epoch 150/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0361e-06 - rmse: 6.6023e-04 - r_square: 1.0000 - val_loss: 6.9782e-07 - val_rmse: 5.3750e-04 - val_r_square: 1.0000\n",
      "Epoch 151/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0291e-06 - rmse: 6.5754e-04 - r_square: 1.0000 - val_loss: 9.6757e-07 - val_rmse: 6.5196e-04 - val_r_square: 1.0000\n",
      "Epoch 152/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0000e-06 - rmse: 6.4688e-04 - r_square: 1.0000 - val_loss: 8.0113e-07 - val_rmse: 5.8305e-04 - val_r_square: 1.0000\n",
      "Epoch 153/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0430e-06 - rmse: 6.6135e-04 - r_square: 1.0000 - val_loss: 8.0575e-07 - val_rmse: 5.4859e-04 - val_r_square: 1.0000\n",
      "Epoch 154/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0536e-06 - rmse: 6.6321e-04 - r_square: 1.0000 - val_loss: 6.8760e-07 - val_rmse: 5.3763e-04 - val_r_square: 1.0000\n",
      "Epoch 155/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0153e-06 - rmse: 6.5147e-04 - r_square: 1.0000 - val_loss: 7.4796e-07 - val_rmse: 5.9453e-04 - val_r_square: 1.0000\n",
      "Epoch 156/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.8891e-07 - rmse: 6.4554e-04 - r_square: 1.0000 - val_loss: 8.8172e-07 - val_rmse: 6.1628e-04 - val_r_square: 1.0000\n",
      "Epoch 157/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0787e-06 - rmse: 6.7004e-04 - r_square: 1.0000 - val_loss: 6.3890e-07 - val_rmse: 5.2137e-04 - val_r_square: 1.0000\n",
      "Epoch 158/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.8830e-07 - rmse: 6.4107e-04 - r_square: 1.0000 - val_loss: 1.1821e-06 - val_rmse: 7.3133e-04 - val_r_square: 1.0000\n",
      "Epoch 159/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.7374e-07 - rmse: 6.3716e-04 - r_square: 1.0000 - val_loss: 1.2024e-06 - val_rmse: 7.2043e-04 - val_r_square: 1.0000\n",
      "Epoch 160/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0003e-06 - rmse: 6.4673e-04 - r_square: 1.0000 - val_loss: 1.3559e-06 - val_rmse: 7.7602e-04 - val_r_square: 0.9999\n",
      "Epoch 161/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.8353e-07 - rmse: 6.4082e-04 - r_square: 1.0000 - val_loss: 6.5860e-07 - val_rmse: 5.2672e-04 - val_r_square: 1.0000\n",
      "Epoch 162/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.7967e-07 - rmse: 6.4167e-04 - r_square: 1.0000 - val_loss: 7.2768e-07 - val_rmse: 5.3314e-04 - val_r_square: 1.0000\n",
      "Epoch 163/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.6448e-07 - rmse: 6.3590e-04 - r_square: 1.0000 - val_loss: 9.2802e-07 - val_rmse: 6.1724e-04 - val_r_square: 1.0000\n",
      "Epoch 164/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0153e-06 - rmse: 6.4967e-04 - r_square: 1.0000 - val_loss: 1.2588e-06 - val_rmse: 6.8717e-04 - val_r_square: 0.9999\n",
      "Epoch 165/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.9229e-07 - rmse: 6.3390e-04 - r_square: 1.0000 - val_loss: 1.1256e-06 - val_rmse: 6.2615e-04 - val_r_square: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.7912e-07 - rmse: 6.3707e-04 - r_square: 1.0000 - val_loss: 1.1669e-06 - val_rmse: 7.1193e-04 - val_r_square: 1.0000\n",
      "Epoch 167/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.8182e-07 - rmse: 6.4276e-04 - r_square: 1.0000 - val_loss: 6.8825e-07 - val_rmse: 5.0755e-04 - val_r_square: 1.0000\n",
      "Epoch 168/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.9172e-07 - rmse: 6.3900e-04 - r_square: 1.0000 - val_loss: 9.5825e-07 - val_rmse: 6.3045e-04 - val_r_square: 1.0000\n",
      "Epoch 169/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0248e-06 - rmse: 6.4653e-04 - r_square: 1.0000 - val_loss: 1.2472e-06 - val_rmse: 7.9566e-04 - val_r_square: 0.9999\n",
      "Epoch 170/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0498e-06 - rmse: 6.5114e-04 - r_square: 1.0000 - val_loss: 9.4220e-07 - val_rmse: 6.8352e-04 - val_r_square: 1.0000\n",
      "Epoch 171/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.9607e-07 - rmse: 6.3368e-04 - r_square: 1.0000 - val_loss: 9.8413e-07 - val_rmse: 6.5956e-04 - val_r_square: 1.0000\n",
      "Epoch 172/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.7149e-07 - rmse: 6.3808e-04 - r_square: 1.0000 - val_loss: 1.2643e-06 - val_rmse: 7.5227e-04 - val_r_square: 0.9999\n",
      "Epoch 173/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.6893e-07 - rmse: 6.3356e-04 - r_square: 1.0000 - val_loss: 1.0309e-06 - val_rmse: 6.2389e-04 - val_r_square: 1.0000\n",
      "Epoch 174/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.8495e-07 - rmse: 6.4307e-04 - r_square: 1.0000 - val_loss: 6.5584e-07 - val_rmse: 5.2348e-04 - val_r_square: 1.0000\n",
      "Epoch 175/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0065e-06 - rmse: 6.4569e-04 - r_square: 1.0000 - val_loss: 6.7358e-07 - val_rmse: 5.4409e-04 - val_r_square: 1.0000\n",
      "Epoch 176/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.9720e-07 - rmse: 6.3901e-04 - r_square: 1.0000 - val_loss: 8.5732e-07 - val_rmse: 5.9622e-04 - val_r_square: 1.0000\n",
      "Epoch 177/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.6961e-07 - rmse: 6.3572e-04 - r_square: 1.0000 - val_loss: 6.7566e-07 - val_rmse: 5.2423e-04 - val_r_square: 1.0000\n",
      "Epoch 178/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.4525e-07 - rmse: 6.3000e-04 - r_square: 1.0000 - val_loss: 1.0401e-06 - val_rmse: 6.8549e-04 - val_r_square: 1.0000\n",
      "Epoch 179/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0566e-06 - rmse: 6.5602e-04 - r_square: 1.0000 - val_loss: 7.5630e-07 - val_rmse: 5.8044e-04 - val_r_square: 1.0000\n",
      "Epoch 180/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.1720e-07 - rmse: 6.1872e-04 - r_square: 1.0000 - val_loss: 8.1116e-07 - val_rmse: 5.7183e-04 - val_r_square: 1.0000\n",
      "Epoch 181/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.6282e-07 - rmse: 6.3306e-04 - r_square: 1.0000 - val_loss: 9.0931e-07 - val_rmse: 6.6099e-04 - val_r_square: 1.0000\n",
      "Epoch 182/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.9549e-07 - rmse: 6.3740e-04 - r_square: 1.0000 - val_loss: 1.0434e-06 - val_rmse: 6.2429e-04 - val_r_square: 1.0000\n",
      "Epoch 183/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0019e-06 - rmse: 6.4098e-04 - r_square: 1.0000 - val_loss: 1.4634e-06 - val_rmse: 8.4949e-04 - val_r_square: 0.9999\n",
      "Epoch 184/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.4112e-07 - rmse: 6.2534e-04 - r_square: 1.0000 - val_loss: 6.7469e-07 - val_rmse: 5.4471e-04 - val_r_square: 1.0000\n",
      "Epoch 185/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 1.0132e-06 - rmse: 6.4612e-04 - r_square: 1.0000 - val_loss: 6.7255e-07 - val_rmse: 5.3626e-04 - val_r_square: 1.0000\n",
      "Epoch 186/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.4380e-07 - rmse: 6.2691e-04 - r_square: 1.0000 - val_loss: 2.0019e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 187/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.6165e-07 - rmse: 6.3185e-04 - r_square: 1.0000 - val_loss: 6.8459e-07 - val_rmse: 5.6651e-04 - val_r_square: 1.0000\n",
      "Epoch 188/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.4276e-07 - rmse: 6.2935e-04 - r_square: 1.0000 - val_loss: 7.6822e-07 - val_rmse: 5.5508e-04 - val_r_square: 1.0000\n",
      "Epoch 189/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 8.9162e-07 - rmse: 6.0841e-04 - r_square: 1.0000 - val_loss: 1.0765e-06 - val_rmse: 7.2228e-04 - val_r_square: 1.0000\n",
      "Epoch 190/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.8565e-07 - rmse: 6.4099e-04 - r_square: 1.0000 - val_loss: 7.7501e-07 - val_rmse: 5.7448e-04 - val_r_square: 1.0000\n",
      "Epoch 191/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.0624e-07 - rmse: 6.1269e-04 - r_square: 1.0000 - val_loss: 8.8647e-07 - val_rmse: 5.8946e-04 - val_r_square: 1.0000\n",
      "Epoch 192/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.7067e-07 - rmse: 6.3671e-04 - r_square: 1.0000 - val_loss: 1.9719e-06 - val_rmse: 9.4185e-04 - val_r_square: 0.9999\n",
      "Epoch 193/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.1965e-07 - rmse: 6.1719e-04 - r_square: 1.0000 - val_loss: 7.8904e-07 - val_rmse: 5.9563e-04 - val_r_square: 1.0000\n",
      "Epoch 194/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.5611e-07 - rmse: 6.3026e-04 - r_square: 1.0000 - val_loss: 1.3071e-06 - val_rmse: 7.7296e-04 - val_r_square: 0.9999\n",
      "Epoch 195/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.0764e-07 - rmse: 6.1421e-04 - r_square: 1.0000 - val_loss: 1.2377e-06 - val_rmse: 7.3953e-04 - val_r_square: 0.9999\n",
      "Epoch 196/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.2476e-07 - rmse: 6.2116e-04 - r_square: 1.0000 - val_loss: 6.2810e-07 - val_rmse: 4.9547e-04 - val_r_square: 1.0000\n",
      "Epoch 197/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.2465e-07 - rmse: 6.2150e-04 - r_square: 1.0000 - val_loss: 9.2699e-07 - val_rmse: 6.5707e-04 - val_r_square: 1.0000\n",
      "Epoch 198/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.3153e-07 - rmse: 6.1887e-04 - r_square: 1.0000 - val_loss: 8.4462e-07 - val_rmse: 6.0869e-04 - val_r_square: 1.0000\n",
      "Epoch 199/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.2855e-07 - rmse: 6.1811e-04 - r_square: 1.0000 - val_loss: 1.0163e-06 - val_rmse: 6.5482e-04 - val_r_square: 1.0000\n",
      "Epoch 200/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 9.4062e-07 - rmse: 6.2444e-04 - r_square: 1.0000 - val_loss: 6.5723e-07 - val_rmse: 5.0934e-04 - val_r_square: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "result = model.fit(X_train, \n",
    "                   y_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.2696994e-02]\n",
      " [ 3.7414992e-01]\n",
      " [ 1.3007532e-01]\n",
      " [ 4.9810112e-02]\n",
      " [ 3.1291690e-02]\n",
      " [ 1.6660685e-02]\n",
      " [ 5.7047880e-01]\n",
      " [-1.6936648e-04]\n",
      " [ 8.9563470e-04]\n",
      " [ 1.9883688e-01]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.29719291e-02],\n",
       "       [3.73104071e-01],\n",
       "       [1.29315320e-01],\n",
       "       [5.07406147e-02],\n",
       "       [3.17998195e-02],\n",
       "       [1.70023232e-02],\n",
       "       [5.70946596e-01],\n",
       "       [4.43924888e-05],\n",
       "       [9.76634753e-04],\n",
       "       [1.98123677e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curves including R^2 and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for rmse\n",
    "plt.plot(result.history['rmse'])\n",
    "plt.plot(result.history['val_rmse'])\n",
    "plt.title('rmse')\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for R^2\n",
    "plt.plot(result.history['r_square'])\n",
    "plt.plot(result.history['val_r_square'])\n",
    "plt.title('model R^2')\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.000509\n",
      "Mean squared error (MSE):       0.000001\n",
      "Root mean squared error (RMSE): 0.000811\n",
      "R square (R^2):                 0.999973\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm, math\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_test,predictions))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_test,predictions))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(sklearn.metrics.mean_squared_error(y_test,predictions)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 487123 samples, validate on 239927 samples\n",
      "Epoch 1/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 8.1509e-04 - rmse: 0.0152 - r_square: 0.9663 - val_loss: 3.6486e-04 - val_rmse: 0.0120 - val_r_square: 0.9851\n",
      "Epoch 2/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 9.8044e-05 - rmse: 0.0066 - r_square: 0.9960 - val_loss: 6.8964e-04 - val_rmse: 0.0177 - val_r_square: 0.9717\n",
      "Epoch 3/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 5.4191e-05 - rmse: 0.0050 - r_square: 0.9978 - val_loss: 9.2445e-04 - val_rmse: 0.0192 - val_r_square: 0.9621\n",
      "Epoch 4/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 3.8468e-05 - rmse: 0.0041 - r_square: 0.9984 - val_loss: 6.8090e-04 - val_rmse: 0.0167 - val_r_square: 0.9721\n",
      "Epoch 5/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 3.2426e-05 - rmse: 0.0037 - r_square: 0.9987 - val_loss: 8.1807e-04 - val_rmse: 0.0173 - val_r_square: 0.9665\n",
      "Epoch 6/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5551e-05 - rmse: 0.0033 - r_square: 0.9989 - val_loss: 6.9434e-04 - val_rmse: 0.0164 - val_r_square: 0.9716\n",
      "Epoch 7/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.9741e-05 - rmse: 0.0030 - r_square: 0.9992 - val_loss: 6.7436e-04 - val_rmse: 0.0160 - val_r_square: 0.9724\n",
      "Epoch 8/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.8486e-05 - rmse: 0.0031 - r_square: 0.9989 - val_loss: 6.6540e-04 - val_rmse: 0.0154 - val_r_square: 0.9728\n",
      "Epoch 9/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.6225e-05 - rmse: 0.0027 - r_square: 0.9993 - val_loss: 6.0598e-04 - val_rmse: 0.0153 - val_r_square: 0.9752\n",
      "Epoch 10/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.8670e-05 - rmse: 0.0027 - r_square: 0.9992 - val_loss: 7.0970e-04 - val_rmse: 0.0159 - val_r_square: 0.9710\n",
      "Epoch 11/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.2911e-05 - rmse: 0.0024 - r_square: 0.9995 - val_loss: 6.6428e-04 - val_rmse: 0.0151 - val_r_square: 0.9729\n",
      "Epoch 12/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.4809e-05 - rmse: 0.0025 - r_square: 0.9994 - val_loss: 6.1734e-04 - val_rmse: 0.0146 - val_r_square: 0.9748\n",
      "Epoch 13/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.4707e-05 - rmse: 0.0025 - r_square: 0.9994 - val_loss: 5.7039e-04 - val_rmse: 0.0139 - val_r_square: 0.9767\n",
      "Epoch 14/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.1126e-05 - rmse: 0.0022 - r_square: 0.9995 - val_loss: 6.5485e-04 - val_rmse: 0.0157 - val_r_square: 0.9732\n",
      "Epoch 15/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.4167e-05 - rmse: 0.0022 - r_square: 0.9994 - val_loss: 5.4822e-04 - val_rmse: 0.0136 - val_r_square: 0.9776\n",
      "Epoch 16/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.1804e-05 - rmse: 0.0021 - r_square: 0.9995 - val_loss: 4.5187e-04 - val_rmse: 0.0134 - val_r_square: 0.9816\n",
      "Epoch 17/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.6032e-05 - rmse: 0.0022 - r_square: 0.9993 - val_loss: 5.3392e-04 - val_rmse: 0.0141 - val_r_square: 0.9782\n",
      "Epoch 18/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 9.5589e-06 - rmse: 0.0019 - r_square: 0.9996 - val_loss: 5.5702e-04 - val_rmse: 0.0146 - val_r_square: 0.9773\n",
      "Epoch 19/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.1470e-05 - rmse: 0.0020 - r_square: 0.9995 - val_loss: 5.2684e-04 - val_rmse: 0.0134 - val_r_square: 0.9785\n",
      "Epoch 20/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 7.7497e-06 - rmse: 0.0018 - r_square: 0.9997 - val_loss: 5.2923e-04 - val_rmse: 0.0139 - val_r_square: 0.9784\n",
      "Epoch 21/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 8.6726e-06 - rmse: 0.0019 - r_square: 0.9996 - val_loss: 5.4377e-04 - val_rmse: 0.0135 - val_r_square: 0.9778\n",
      "Epoch 22/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 6.9127e-06 - rmse: 0.0017 - r_square: 0.9997 - val_loss: 5.4261e-04 - val_rmse: 0.0138 - val_r_square: 0.9779\n",
      "Epoch 23/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 1.0141e-05 - rmse: 0.0019 - r_square: 0.9996 - val_loss: 5.3984e-04 - val_rmse: 0.0142 - val_r_square: 0.9780\n",
      "Epoch 24/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 6.6219e-06 - rmse: 0.0017 - r_square: 0.9997 - val_loss: 5.2410e-04 - val_rmse: 0.0135 - val_r_square: 0.9786\n",
      "Epoch 25/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 8.5868e-06 - rmse: 0.0018 - r_square: 0.9996 - val_loss: 5.4704e-04 - val_rmse: 0.0138 - val_r_square: 0.9777\n",
      "Epoch 26/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 6.9264e-06 - rmse: 0.0016 - r_square: 0.9997 - val_loss: 5.0122e-04 - val_rmse: 0.0134 - val_r_square: 0.9795\n",
      "Epoch 27/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 6.6320e-06 - rmse: 0.0017 - r_square: 0.9997 - val_loss: 5.1439e-04 - val_rmse: 0.0134 - val_r_square: 0.9790\n",
      "Epoch 28/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 5.8726e-06 - rmse: 0.0016 - r_square: 0.9998 - val_loss: 5.3583e-04 - val_rmse: 0.0136 - val_r_square: 0.9781\n",
      "Epoch 29/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 9.1550e-06 - rmse: 0.0017 - r_square: 0.9996 - val_loss: 5.2371e-04 - val_rmse: 0.0136 - val_r_square: 0.9786\n",
      "Epoch 30/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 6.2490e-06 - rmse: 0.0016 - r_square: 0.9997 - val_loss: 5.3074e-04 - val_rmse: 0.0140 - val_r_square: 0.9783\n",
      "Epoch 31/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 7.2429e-06 - rmse: 0.0016 - r_square: 0.9997 - val_loss: 5.2523e-04 - val_rmse: 0.0137 - val_r_square: 0.9786\n",
      "Epoch 32/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 5.4386e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 4.9777e-04 - val_rmse: 0.0132 - val_r_square: 0.9797\n",
      "Epoch 33/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 5.9180e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 5.2632e-04 - val_rmse: 0.0148 - val_r_square: 0.9785\n",
      "Epoch 34/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 5.5762e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 5.1998e-04 - val_rmse: 0.0137 - val_r_square: 0.9788\n",
      "Epoch 35/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 6.3184e-06 - rmse: 0.0016 - r_square: 0.9997 - val_loss: 5.2607e-04 - val_rmse: 0.0140 - val_r_square: 0.9785\n",
      "Epoch 36/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 5.4209e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 4.9746e-04 - val_rmse: 0.0135 - val_r_square: 0.9797\n",
      "Epoch 37/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 5.5591e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 5.0773e-04 - val_rmse: 0.0135 - val_r_square: 0.9793\n",
      "Epoch 38/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 5.2694e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 5.1454e-04 - val_rmse: 0.0138 - val_r_square: 0.9790\n",
      "Epoch 39/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 4.8377e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 4.6302e-04 - val_rmse: 0.0130 - val_r_square: 0.9811\n",
      "Epoch 40/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 6.8875e-06 - rmse: 0.0016 - r_square: 0.9997 - val_loss: 5.2221e-04 - val_rmse: 0.0139 - val_r_square: 0.9787\n",
      "Epoch 41/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.8709e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 5.3683e-04 - val_rmse: 0.0137 - val_r_square: 0.9781\n",
      "Epoch 42/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 4.7251e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 4.9532e-04 - val_rmse: 0.0134 - val_r_square: 0.9798\n",
      "Epoch 43/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 5.0400e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 5.1756e-04 - val_rmse: 0.0140 - val_r_square: 0.9789\n",
      "Epoch 44/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.5864e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 4.7368e-04 - val_rmse: 0.0135 - val_r_square: 0.9806\n",
      "Epoch 45/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 5.1531e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 5.0196e-04 - val_rmse: 0.0138 - val_r_square: 0.9795\n",
      "Epoch 46/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.8841e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 4.8919e-04 - val_rmse: 0.0135 - val_r_square: 0.9800\n",
      "Epoch 47/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 7.0508e-06 - rmse: 0.0015 - r_square: 0.9997 - val_loss: 5.1046e-04 - val_rmse: 0.0137 - val_r_square: 0.9791\n",
      "Epoch 48/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.1819e-06 - rmse: 0.0013 - r_square: 0.9998 - val_loss: 4.9785e-04 - val_rmse: 0.0138 - val_r_square: 0.9797\n",
      "Epoch 49/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.7243e-06 - rmse: 0.0014 - r_square: 0.9998 - val_loss: 4.7034e-04 - val_rmse: 0.0131 - val_r_square: 0.9808\n",
      "Epoch 50/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.1976e-06 - rmse: 0.0013 - r_square: 0.9998 - val_loss: 5.0245e-04 - val_rmse: 0.0138 - val_r_square: 0.9795\n",
      "Epoch 51/200\n",
      "487123/487123 [==============================] - 3s 6us/step - loss: 4.4051e-06 - rmse: 0.0013 - r_square: 0.9998 - val_loss: 4.8407e-04 - val_rmse: 0.0133 - val_r_square: 0.9802\n",
      "Epoch 00051: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(6,)),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model2.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result2 = model2.fit(X_train, \n",
    "                   y_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.5972891e-02]\n",
      " [3.7647626e-01]\n",
      " [1.0803577e-01]\n",
      " [3.7441004e-02]\n",
      " [3.8380090e-02]\n",
      " [4.9043383e-02]\n",
      " [5.0099188e-01]\n",
      " [2.2799615e-04]\n",
      " [3.0210556e-03]\n",
      " [2.1721044e-01]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.013301\n",
      "Mean squared error (MSE):       0.000484\n",
      "Root mean squared error (RMSE): 0.022002\n",
      "R square (R^2):                 0.980362\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model2.predict(X_test)\n",
    "print(predictions2[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_test,predictions2))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_test,predictions2))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(sklearn.metrics.mean_squared_error(y_test,predictions2)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_test,predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try batch normalization technique to regularize neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 487123 samples, validate on 239927 samples\n",
      "Epoch 1/200\n",
      "487123/487123 [==============================] - 4s 8us/step - loss: 0.0010 - rmse: 0.0176 - r_square: 0.9569 - val_loss: 1.4472e-04 - val_rmse: 0.0078 - val_r_square: 0.9940\n",
      "Epoch 2/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 3.5415e-04 - rmse: 0.0125 - r_square: 0.9854 - val_loss: 6.6277e-05 - val_rmse: 0.0060 - val_r_square: 0.9973\n",
      "Epoch 3/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 3.1503e-04 - rmse: 0.0114 - r_square: 0.9871 - val_loss: 1.5766e-04 - val_rmse: 0.0077 - val_r_square: 0.9935\n",
      "Epoch 4/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 3.0017e-04 - rmse: 0.0109 - r_square: 0.9877 - val_loss: 1.3407e-04 - val_rmse: 0.0090 - val_r_square: 0.9944\n",
      "Epoch 5/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.9197e-04 - rmse: 0.0109 - r_square: 0.9880 - val_loss: 1.4660e-04 - val_rmse: 0.0089 - val_r_square: 0.9940\n",
      "Epoch 6/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.8454e-04 - rmse: 0.0105 - r_square: 0.9883 - val_loss: 1.4590e-04 - val_rmse: 0.0068 - val_r_square: 0.9941\n",
      "Epoch 7/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5636e-04 - rmse: 0.0100 - r_square: 0.9894 - val_loss: 3.2742e-05 - val_rmse: 0.0042 - val_r_square: 0.9986\n",
      "Epoch 8/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5502e-04 - rmse: 0.0099 - r_square: 0.9895 - val_loss: 1.3824e-04 - val_rmse: 0.0077 - val_r_square: 0.9943\n",
      "Epoch 9/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5413e-04 - rmse: 0.0099 - r_square: 0.9896 - val_loss: 3.6484e-05 - val_rmse: 0.0042 - val_r_square: 0.9985\n",
      "Epoch 10/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5418e-04 - rmse: 0.0098 - r_square: 0.9895 - val_loss: 6.0479e-05 - val_rmse: 0.0055 - val_r_square: 0.9975\n",
      "Epoch 11/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5245e-04 - rmse: 0.0099 - r_square: 0.9896 - val_loss: 3.8806e-05 - val_rmse: 0.0044 - val_r_square: 0.9984\n",
      "Epoch 12/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.6297e-04 - rmse: 0.0100 - r_square: 0.9892 - val_loss: 2.4315e-05 - val_rmse: 0.0032 - val_r_square: 0.9990\n",
      "Epoch 13/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4506e-04 - rmse: 0.0097 - r_square: 0.9898 - val_loss: 3.0089e-05 - val_rmse: 0.0032 - val_r_square: 0.9988\n",
      "Epoch 14/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5724e-04 - rmse: 0.0098 - r_square: 0.9894 - val_loss: 1.9008e-05 - val_rmse: 0.0028 - val_r_square: 0.9992\n",
      "Epoch 15/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4267e-04 - rmse: 0.0095 - r_square: 0.9900 - val_loss: 8.3593e-05 - val_rmse: 0.0061 - val_r_square: 0.9966\n",
      "Epoch 16/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4752e-04 - rmse: 0.0097 - r_square: 0.9898 - val_loss: 1.3307e-04 - val_rmse: 0.0072 - val_r_square: 0.9946\n",
      "Epoch 17/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3897e-04 - rmse: 0.0094 - r_square: 0.9903 - val_loss: 7.3407e-05 - val_rmse: 0.0053 - val_r_square: 0.9970\n",
      "Epoch 18/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3634e-04 - rmse: 0.0094 - r_square: 0.9902 - val_loss: 1.7224e-05 - val_rmse: 0.0029 - val_r_square: 0.9993\n",
      "Epoch 19/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4679e-04 - rmse: 0.0096 - r_square: 0.9898 - val_loss: 5.2111e-05 - val_rmse: 0.0053 - val_r_square: 0.9979\n",
      "Epoch 20/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4215e-04 - rmse: 0.0096 - r_square: 0.9900 - val_loss: 3.7329e-05 - val_rmse: 0.0040 - val_r_square: 0.9985\n",
      "Epoch 21/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2942e-04 - rmse: 0.0093 - r_square: 0.9906 - val_loss: 2.2811e-05 - val_rmse: 0.0029 - val_r_square: 0.9991\n",
      "Epoch 22/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4971e-04 - rmse: 0.0097 - r_square: 0.9898 - val_loss: 2.4531e-05 - val_rmse: 0.0032 - val_r_square: 0.9990\n",
      "Epoch 23/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3881e-04 - rmse: 0.0094 - r_square: 0.9902 - val_loss: 5.2940e-05 - val_rmse: 0.0046 - val_r_square: 0.9978\n",
      "Epoch 24/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3484e-04 - rmse: 0.0094 - r_square: 0.9903 - val_loss: 2.5193e-05 - val_rmse: 0.0035 - val_r_square: 0.9990\n",
      "Epoch 25/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3831e-04 - rmse: 0.0095 - r_square: 0.9902 - val_loss: 3.4562e-05 - val_rmse: 0.0043 - val_r_square: 0.9986\n",
      "Epoch 26/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3410e-04 - rmse: 0.0093 - r_square: 0.9904 - val_loss: 3.5790e-05 - val_rmse: 0.0039 - val_r_square: 0.9985\n",
      "Epoch 27/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3963e-04 - rmse: 0.0095 - r_square: 0.9901 - val_loss: 5.8185e-05 - val_rmse: 0.0054 - val_r_square: 0.9976\n",
      "Epoch 28/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3109e-04 - rmse: 0.0092 - r_square: 0.9905 - val_loss: 3.8614e-05 - val_rmse: 0.0036 - val_r_square: 0.9984\n",
      "Epoch 29/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3334e-04 - rmse: 0.0093 - r_square: 0.9905 - val_loss: 1.9158e-05 - val_rmse: 0.0029 - val_r_square: 0.9992\n",
      "Epoch 30/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2940e-04 - rmse: 0.0093 - r_square: 0.9905 - val_loss: 2.0703e-05 - val_rmse: 0.0027 - val_r_square: 0.9991\n",
      "Epoch 31/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2816e-04 - rmse: 0.0093 - r_square: 0.9906 - val_loss: 3.6843e-05 - val_rmse: 0.0041 - val_r_square: 0.9985\n",
      "Epoch 32/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2853e-04 - rmse: 0.0093 - r_square: 0.9906 - val_loss: 3.7567e-05 - val_rmse: 0.0038 - val_r_square: 0.9985\n",
      "Epoch 33/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2363e-04 - rmse: 0.0093 - r_square: 0.9908 - val_loss: 2.8971e-05 - val_rmse: 0.0034 - val_r_square: 0.9988\n",
      "Epoch 34/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2115e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 1.7335e-05 - val_rmse: 0.0027 - val_r_square: 0.9993\n",
      "Epoch 35/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3398e-04 - rmse: 0.0094 - r_square: 0.9904 - val_loss: 2.3413e-05 - val_rmse: 0.0033 - val_r_square: 0.9990\n",
      "Epoch 36/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3700e-04 - rmse: 0.0095 - r_square: 0.9902 - val_loss: 2.6944e-05 - val_rmse: 0.0033 - val_r_square: 0.9989\n",
      "Epoch 37/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3066e-04 - rmse: 0.0093 - r_square: 0.9905 - val_loss: 1.8262e-05 - val_rmse: 0.0025 - val_r_square: 0.9992\n",
      "Epoch 38/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3079e-04 - rmse: 0.0093 - r_square: 0.9905 - val_loss: 7.0820e-05 - val_rmse: 0.0057 - val_r_square: 0.9971\n",
      "Epoch 39/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2840e-04 - rmse: 0.0093 - r_square: 0.9906 - val_loss: 5.1693e-05 - val_rmse: 0.0046 - val_r_square: 0.9979\n",
      "Epoch 40/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4427e-04 - rmse: 0.0095 - r_square: 0.9899 - val_loss: 3.1388e-05 - val_rmse: 0.0035 - val_r_square: 0.9987\n",
      "Epoch 41/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2237e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 2.7407e-05 - val_rmse: 0.0037 - val_r_square: 0.9989\n",
      "Epoch 42/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2086e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 6.4634e-05 - val_rmse: 0.0055 - val_r_square: 0.9974\n",
      "Epoch 43/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2498e-04 - rmse: 0.0092 - r_square: 0.9908 - val_loss: 1.8365e-05 - val_rmse: 0.0026 - val_r_square: 0.9992\n",
      "Epoch 44/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2660e-04 - rmse: 0.0091 - r_square: 0.9907 - val_loss: 5.7419e-05 - val_rmse: 0.0059 - val_r_square: 0.9976\n",
      "Epoch 45/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2331e-04 - rmse: 0.0092 - r_square: 0.9907 - val_loss: 1.5006e-05 - val_rmse: 0.0025 - val_r_square: 0.9994\n",
      "Epoch 46/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2514e-04 - rmse: 0.0091 - r_square: 0.9907 - val_loss: 2.1396e-05 - val_rmse: 0.0033 - val_r_square: 0.9991\n",
      "Epoch 47/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1763e-04 - rmse: 0.0090 - r_square: 0.9910 - val_loss: 3.9048e-05 - val_rmse: 0.0045 - val_r_square: 0.9984\n",
      "Epoch 48/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2386e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 2.5654e-05 - val_rmse: 0.0032 - val_r_square: 0.9989\n",
      "Epoch 49/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3553e-04 - rmse: 0.0094 - r_square: 0.9904 - val_loss: 3.1644e-05 - val_rmse: 0.0045 - val_r_square: 0.9987\n",
      "Epoch 50/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2581e-04 - rmse: 0.0092 - r_square: 0.9907 - val_loss: 3.1348e-05 - val_rmse: 0.0037 - val_r_square: 0.9987\n",
      "Epoch 51/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2108e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.9372e-05 - val_rmse: 0.0035 - val_r_square: 0.9988\n",
      "Epoch 52/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2228e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 4.8100e-05 - val_rmse: 0.0047 - val_r_square: 0.9980\n",
      "Epoch 53/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2258e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 1.5655e-05 - val_rmse: 0.0024 - val_r_square: 0.9994\n",
      "Epoch 54/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2098e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.3211e-05 - val_rmse: 0.0032 - val_r_square: 0.9990\n",
      "Epoch 55/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2657e-04 - rmse: 0.0092 - r_square: 0.9907 - val_loss: 1.9761e-05 - val_rmse: 0.0026 - val_r_square: 0.9992\n",
      "Epoch 56/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2287e-04 - rmse: 0.0092 - r_square: 0.9909 - val_loss: 2.0357e-05 - val_rmse: 0.0029 - val_r_square: 0.9992\n",
      "Epoch 57/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2106e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.4313e-05 - val_rmse: 0.0033 - val_r_square: 0.9990\n",
      "Epoch 58/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3131e-04 - rmse: 0.0093 - r_square: 0.9904 - val_loss: 3.0427e-05 - val_rmse: 0.0039 - val_r_square: 0.9987\n",
      "Epoch 59/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1997e-04 - rmse: 0.0091 - r_square: 0.9910 - val_loss: 2.3945e-05 - val_rmse: 0.0031 - val_r_square: 0.9990\n",
      "Epoch 60/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2447e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 3.6661e-05 - val_rmse: 0.0034 - val_r_square: 0.9985\n",
      "Epoch 61/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1865e-04 - rmse: 0.0090 - r_square: 0.9910 - val_loss: 2.4775e-05 - val_rmse: 0.0032 - val_r_square: 0.9990\n",
      "Epoch 62/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2732e-04 - rmse: 0.0092 - r_square: 0.9906 - val_loss: 1.6062e-05 - val_rmse: 0.0024 - val_r_square: 0.9993\n",
      "Epoch 63/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1205e-04 - rmse: 0.0090 - r_square: 0.9912 - val_loss: 7.4692e-05 - val_rmse: 0.0054 - val_r_square: 0.9969\n",
      "Epoch 64/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1079e-04 - rmse: 0.0089 - r_square: 0.9913 - val_loss: 6.7484e-05 - val_rmse: 0.0051 - val_r_square: 0.9972\n",
      "Epoch 65/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1771e-04 - rmse: 0.0090 - r_square: 0.9910 - val_loss: 2.3371e-05 - val_rmse: 0.0035 - val_r_square: 0.9990\n",
      "Epoch 66/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2135e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.2457e-05 - val_rmse: 0.0031 - val_r_square: 0.9991\n",
      "Epoch 67/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2335e-04 - rmse: 0.0092 - r_square: 0.9909 - val_loss: 2.0304e-05 - val_rmse: 0.0028 - val_r_square: 0.9992\n",
      "Epoch 68/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1315e-04 - rmse: 0.0089 - r_square: 0.9912 - val_loss: 2.7621e-05 - val_rmse: 0.0035 - val_r_square: 0.9989\n",
      "Epoch 69/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1295e-04 - rmse: 0.0090 - r_square: 0.9913 - val_loss: 1.9383e-05 - val_rmse: 0.0031 - val_r_square: 0.9992\n",
      "Epoch 70/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1914e-04 - rmse: 0.0091 - r_square: 0.9910 - val_loss: 2.7297e-05 - val_rmse: 0.0038 - val_r_square: 0.9989\n",
      "Epoch 71/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2291e-04 - rmse: 0.0092 - r_square: 0.9908 - val_loss: 6.4090e-05 - val_rmse: 0.0049 - val_r_square: 0.9973\n",
      "Epoch 72/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2204e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.0816e-05 - val_rmse: 0.0029 - val_r_square: 0.9991\n",
      "Epoch 73/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1317e-04 - rmse: 0.0090 - r_square: 0.9912 - val_loss: 6.2106e-05 - val_rmse: 0.0062 - val_r_square: 0.9974\n",
      "Epoch 74/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2238e-04 - rmse: 0.0092 - r_square: 0.9908 - val_loss: 3.0137e-05 - val_rmse: 0.0036 - val_r_square: 0.9988\n",
      "Epoch 75/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2305e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 1.9085e-05 - val_rmse: 0.0025 - val_r_square: 0.9992\n",
      "Epoch 76/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1560e-04 - rmse: 0.0090 - r_square: 0.9911 - val_loss: 3.2413e-05 - val_rmse: 0.0040 - val_r_square: 0.9987\n",
      "Epoch 77/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2431e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 2.1438e-05 - val_rmse: 0.0032 - val_r_square: 0.9991\n",
      "Epoch 78/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0469e-04 - rmse: 0.0088 - r_square: 0.9915 - val_loss: 4.7530e-05 - val_rmse: 0.0041 - val_r_square: 0.9980\n",
      "Epoch 79/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1649e-04 - rmse: 0.0091 - r_square: 0.9911 - val_loss: 2.4759e-05 - val_rmse: 0.0033 - val_r_square: 0.9990\n",
      "Epoch 80/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2199e-04 - rmse: 0.0092 - r_square: 0.9909 - val_loss: 2.1750e-05 - val_rmse: 0.0029 - val_r_square: 0.9991\n",
      "Epoch 81/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1651e-04 - rmse: 0.0090 - r_square: 0.9911 - val_loss: 1.8060e-05 - val_rmse: 0.0030 - val_r_square: 0.9993\n",
      "Epoch 82/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1302e-04 - rmse: 0.0089 - r_square: 0.9912 - val_loss: 2.2619e-05 - val_rmse: 0.0028 - val_r_square: 0.9991\n",
      "Epoch 83/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2407e-04 - rmse: 0.0092 - r_square: 0.9907 - val_loss: 2.9842e-05 - val_rmse: 0.0034 - val_r_square: 0.9988\n",
      "Epoch 84/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1314e-04 - rmse: 0.0089 - r_square: 0.9912 - val_loss: 3.1316e-05 - val_rmse: 0.0038 - val_r_square: 0.9987\n",
      "Epoch 85/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1724e-04 - rmse: 0.0090 - r_square: 0.9911 - val_loss: 2.4251e-05 - val_rmse: 0.0039 - val_r_square: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1264e-04 - rmse: 0.0090 - r_square: 0.9912 - val_loss: 2.0521e-05 - val_rmse: 0.0029 - val_r_square: 0.9992\n",
      "Epoch 87/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2124e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 1.7220e-05 - val_rmse: 0.0027 - val_r_square: 0.9993\n",
      "Epoch 88/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0725e-04 - rmse: 0.0088 - r_square: 0.9915 - val_loss: 3.5184e-05 - val_rmse: 0.0041 - val_r_square: 0.9986\n",
      "Epoch 89/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1255e-04 - rmse: 0.0090 - r_square: 0.9913 - val_loss: 2.6888e-05 - val_rmse: 0.0031 - val_r_square: 0.9989\n",
      "Epoch 90/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0636e-04 - rmse: 0.0088 - r_square: 0.9915 - val_loss: 1.9418e-05 - val_rmse: 0.0028 - val_r_square: 0.9992\n",
      "Epoch 91/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0932e-04 - rmse: 0.0089 - r_square: 0.9913 - val_loss: 3.1192e-05 - val_rmse: 0.0041 - val_r_square: 0.9987\n",
      "Epoch 92/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0490e-04 - rmse: 0.0089 - r_square: 0.9916 - val_loss: 3.2297e-05 - val_rmse: 0.0047 - val_r_square: 0.9987\n",
      "Epoch 93/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1912e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.8050e-05 - val_rmse: 0.0036 - val_r_square: 0.9988\n",
      "Epoch 94/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2103e-04 - rmse: 0.0091 - r_square: 0.9910 - val_loss: 1.5035e-05 - val_rmse: 0.0023 - val_r_square: 0.9994\n",
      "Epoch 95/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1224e-04 - rmse: 0.0089 - r_square: 0.9912 - val_loss: 3.0091e-05 - val_rmse: 0.0036 - val_r_square: 0.9988\n",
      "Epoch 00095: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model3 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', input_shape=(6,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model3.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result3 = model3.fit(X_train, \n",
    "                   y_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04051611]\n",
      " [ 0.34659985]\n",
      " [ 0.12310097]\n",
      " [ 0.05491048]\n",
      " [ 0.02672598]\n",
      " [ 0.01006674]\n",
      " [ 0.5663377 ]\n",
      " [-0.00239683]\n",
      " [-0.00114246]\n",
      " [ 0.18679872]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.003646\n",
      "Mean squared error (MSE):       0.000030\n",
      "Root mean squared error (RMSE): 0.005486\n",
      "R square (R^2):                 0.998779\n"
     ]
    }
   ],
   "source": [
    "predictions3 = model3.predict(X_test)\n",
    "print(predictions3[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_test,predictions3))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_test,predictions3))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(sklearn.metrics.mean_squared_error(y_test,predictions3)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_test,predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference: \n",
    "&emsp;&emsp;What does 'Accuracy' mean in Regression? https://github.com/keras-team/keras/issues/7947 <br>\n",
    "&emsp;&emsp;https://keras.io/metrics/<br>\n",
    "&emsp;&emsp;Scale, Standardize, or Normalize with Scikit-Learn https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02 <br>\n",
    "&emsp;&emsp;The Day my Computer Won the Nobel Prize (Neural Network Option Pricing)  https://medium.com/datadriveninvestor/the-day-my-computer-won-the-nobel-prize-neural-network-option-pricing-d29b4379f1d2 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
