{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl (1.4MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-19.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.14.3)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/4a/5c86ed8b245aa48f9f819b13a0a9039e9126ba19fdd0c7e0b8026c12315a/tensorflow-1.14.0-cp36-cp36m-win_amd64.whl (68.3MB)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.1)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/93/297ff3656f1073fba84e2f9633ad3b27a007eb59ad22099ac30142f80365/grpcio-1.22.0-cp36-cp36m-win_amd64.whl (1.6MB)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/59/ec6c6075dd628f2efd33dbe11b259e63e1de7cbc26e45b38de767df528d4/protobuf-3.8.0-cp36-cp36m-win_amd64.whl (1.1MB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/ed/e036d31a9b2c750f270cbb1cfc1c0f94ac78ae504eea7eec3267be4e294a/numpy-1.16.4-cp36-cp36m-win_amd64.whl (11.9MB)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.0.8)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Building wheels for collected packages: termcolor, absl-py, wrapt, gast\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\ee\\98\\38\\46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\d7\\de\\2e\\efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built termcolor absl-py wrapt gast\n",
      "Installing collected packages: google-pasta, tensorflow-estimator, grpcio, protobuf, termcolor, absl-py, numpy, markdown, tensorboard, astor, wrapt, gast, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.22.0 markdown-3.1.1 numpy-1.16.4 protobuf-3.8.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.11.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "!pip install --user keras\n",
    "!pip install --user tensorflow\n",
    "!pip install --user -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and do data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_withoutNaN_2.csv')\n",
    "df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Value'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The Date of this Price</th>\n",
       "      <th>Expiration Date of the Option</th>\n",
       "      <th>Strike Price</th>\n",
       "      <th>Lowest  Closing Ask Across All Exchanges</th>\n",
       "      <th>Underlying Price</th>\n",
       "      <th>volatility</th>\n",
       "      <th>Value</th>\n",
       "      <th>Maturity</th>\n",
       "      <th>C=Call, P=Put_C</th>\n",
       "      <th>C=Call, P=Put_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>590.0</td>\n",
       "      <td>85.50</td>\n",
       "      <td>674.97</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>595.0</td>\n",
       "      <td>80.80</td>\n",
       "      <td>674.97</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>600.0</td>\n",
       "      <td>75.15</td>\n",
       "      <td>674.97</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>605.0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>674.97</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>610.0</td>\n",
       "      <td>65.45</td>\n",
       "      <td>674.97</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  The Date of this Price Expiration Date of the Option  Strike Price  \\\n",
       "0             2012-09-04                    2012-09-07         590.0   \n",
       "1             2012-09-04                    2012-09-07         595.0   \n",
       "2             2012-09-04                    2012-09-07         600.0   \n",
       "3             2012-09-04                    2012-09-07         605.0   \n",
       "4             2012-09-04                    2012-09-07         610.0   \n",
       "\n",
       "   Lowest  Closing Ask Across All Exchanges  Underlying Price  volatility  \\\n",
       "0                                     85.50            674.97    0.174659   \n",
       "1                                     80.80            674.97    0.174659   \n",
       "2                                     75.15            674.97    0.174659   \n",
       "3                                     70.70            674.97    0.174659   \n",
       "4                                     65.45            674.97    0.174659   \n",
       "\n",
       "   Value  Maturity  C=Call, P=Put_C  C=Call, P=Put_P  \n",
       "0  0.001         3                1                0  \n",
       "1  0.001         3                1                0  \n",
       "2  0.001         3                1                0  \n",
       "3  0.001         3                1                0  \n",
       "4  0.001         3                1                0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Lowest  Closing Ask Across All Exchanges'].values\n",
    "X = df[['Strike Price', 'Underlying Price', 'volatility', 'Maturity', 'Value', 'C=Call, P=Put_C', 'C=Call, P=Put_P']]\n",
    "#df.drop(['Lowest  Closing Ask Across All Exchanges'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to build a regression neural network model\n",
    "sc= preprocessing.MinMaxScaler()\n",
    "X= sc.fit_transform(X)\n",
    "y= y.reshape(-1,1)\n",
    "y=sc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828205, 7)\n",
      "(828205, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XX_train, XX_validation, yy_train, yy_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built Keras sequential model with 3 hidden layer, and after the first hidden layer, dropout 25% neurons.\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable early stopping based on the loss of validation data\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is a simple regression problem, we should custom metrics function\n",
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1))\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean_squared_error to compile regression model loss\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 828205 samples, validate on 207052 samples\n",
      "Epoch 1/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.2589e-04 - rmse: 0.0072 - r_square: 0.9891 - val_loss: 5.3931e-05 - val_rmse: 0.0053 - val_r_square: 0.9982\n",
      "Epoch 2/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.8368e-05 - rmse: 0.0036 - r_square: 0.9990 - val_loss: 9.2863e-06 - val_rmse: 0.0022 - val_r_square: 0.9997\n",
      "Epoch 3/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4629e-05 - rmse: 0.0029 - r_square: 0.9995 - val_loss: 1.4833e-05 - val_rmse: 0.0032 - val_r_square: 0.9995\n",
      "Epoch 4/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3540e-05 - rmse: 0.0026 - r_square: 0.9995 - val_loss: 1.6059e-05 - val_rmse: 0.0033 - val_r_square: 0.9995\n",
      "Epoch 5/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.1115e-05 - rmse: 0.0024 - r_square: 0.9996 - val_loss: 8.7013e-06 - val_rmse: 0.0022 - val_r_square: 0.9997\n",
      "Epoch 6/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 8.3059e-06 - rmse: 0.0022 - r_square: 0.9997 - val_loss: 2.4043e-05 - val_rmse: 0.0040 - val_r_square: 0.9992\n",
      "Epoch 7/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 7.5576e-06 - rmse: 0.0020 - r_square: 0.9997 - val_loss: 6.3593e-06 - val_rmse: 0.0019 - val_r_square: 0.9998\n",
      "Epoch 8/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 6.8268e-06 - rmse: 0.0019 - r_square: 0.9998 - val_loss: 5.5975e-06 - val_rmse: 0.0018 - val_r_square: 0.9998\n",
      "Epoch 9/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 6.2224e-06 - rmse: 0.0018 - r_square: 0.9998 - val_loss: 1.5727e-05 - val_rmse: 0.0029 - val_r_square: 0.9995\n",
      "Epoch 10/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 5.9516e-06 - rmse: 0.0018 - r_square: 0.9998 - val_loss: 3.9890e-06 - val_rmse: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 11/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 5.3511e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 1.4099e-05 - val_rmse: 0.0029 - val_r_square: 0.9995\n",
      "Epoch 12/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 5.1470e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 3.1516e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 13/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 5.0656e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 1.2808e-05 - val_rmse: 0.0025 - val_r_square: 0.9996\n",
      "Epoch 14/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 4.6503e-06 - rmse: 0.0016 - r_square: 0.9998 - val_loss: 4.5461e-06 - val_rmse: 0.0016 - val_r_square: 0.9998\n",
      "Epoch 15/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 4.4757e-06 - rmse: 0.0015 - r_square: 0.9998 - val_loss: 7.4696e-06 - val_rmse: 0.0021 - val_r_square: 0.9997\n",
      "Epoch 16/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 4.3483e-06 - rmse: 0.0015 - r_square: 0.9999 - val_loss: 8.3276e-06 - val_rmse: 0.0021 - val_r_square: 0.9997\n",
      "Epoch 17/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 4.2480e-06 - rmse: 0.0015 - r_square: 0.9999 - val_loss: 3.0045e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 18/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.9464e-06 - rmse: 0.0014 - r_square: 0.9999 - val_loss: 3.0291e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 19/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.9128e-06 - rmse: 0.0014 - r_square: 0.9999 - val_loss: 2.9674e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 20/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.8243e-06 - rmse: 0.0014 - r_square: 0.9999 - val_loss: 5.4407e-06 - val_rmse: 0.0017 - val_r_square: 0.9998\n",
      "Epoch 21/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.7330e-06 - rmse: 0.0014 - r_square: 0.9999 - val_loss: 2.6230e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 22/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.6818e-06 - rmse: 0.0014 - r_square: 0.9999 - val_loss: 2.7258e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 23/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.5274e-06 - rmse: 0.0014 - r_square: 0.9999 - val_loss: 3.2102e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 24/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.4101e-06 - rmse: 0.0013 - r_square: 0.9999 - val_loss: 2.3595e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 25/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.3981e-06 - rmse: 0.0013 - r_square: 0.9999 - val_loss: 4.2080e-06 - val_rmse: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 26/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.3223e-06 - rmse: 0.0013 - r_square: 0.9999 - val_loss: 2.9502e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 27/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.1387e-06 - rmse: 0.0013 - r_square: 0.9999 - val_loss: 2.6349e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 28/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.1222e-06 - rmse: 0.0013 - r_square: 0.9999 - val_loss: 3.9565e-06 - val_rmse: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 29/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.0681e-06 - rmse: 0.0013 - r_square: 0.9999 - val_loss: 6.7883e-06 - val_rmse: 0.0019 - val_r_square: 0.9998\n",
      "Epoch 30/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 3.0066e-06 - rmse: 0.0013 - r_square: 0.9999 - val_loss: 3.0899e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 31/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.9681e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 3.4323e-06 - val_rmse: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 32/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.9590e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 4.5397e-06 - val_rmse: 0.0015 - val_r_square: 0.9998\n",
      "Epoch 33/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.8251e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 2.5063e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 34/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.8213e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 2.8463e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 35/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.7237e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 4.4504e-06 - val_rmse: 0.0016 - val_r_square: 0.9998\n",
      "Epoch 36/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.8234e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 2.4036e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 37/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.6101e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 2.3604e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 38/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.6585e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 9.5804e-06 - val_rmse: 0.0022 - val_r_square: 0.9997\n",
      "Epoch 39/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.6692e-06 - rmse: 0.0012 - r_square: 0.9999 - val_loss: 4.1409e-06 - val_rmse: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 40/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.5034e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 3.8605e-06 - val_rmse: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 41/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.5700e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 5.1445e-06 - val_rmse: 0.0017 - val_r_square: 0.9998\n",
      "Epoch 42/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.5072e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 2.7767e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.4632e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 3.2479e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 44/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.4217e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 2.3729e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 45/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.4153e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 4.6714e-06 - val_rmse: 0.0016 - val_r_square: 0.9998\n",
      "Epoch 46/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.4201e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 2.3887e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 47/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.3544e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.9893e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 48/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.4113e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.9466e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 49/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.3686e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.8736e-06 - val_rmse: 9.7027e-04 - val_r_square: 0.9999\n",
      "Epoch 50/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.3064e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.6099e-06 - val_rmse: 8.9790e-04 - val_r_square: 0.9999\n",
      "Epoch 51/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.2799e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 2.6682e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 52/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.2562e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.7845e-06 - val_rmse: 9.5528e-04 - val_r_square: 0.9999\n",
      "Epoch 53/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.2465e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 3.6135e-06 - val_rmse: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 54/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.2233e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.8386e-06 - val_rmse: 9.7810e-04 - val_r_square: 0.9999\n",
      "Epoch 55/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.1908e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 3.2960e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 56/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.1684e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.8168e-06 - val_rmse: 9.7053e-04 - val_r_square: 0.9999\n",
      "Epoch 57/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.1527e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 2.7099e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 58/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.1605e-06 - rmse: 0.0011 - r_square: 0.9999 - val_loss: 1.6419e-06 - val_rmse: 9.3551e-04 - val_r_square: 0.9999\n",
      "Epoch 59/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.0891e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 2.0439e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 60/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.1073e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 2.7685e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 61/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.0948e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 2.0773e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 62/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.0725e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 2.4805e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 63/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.9892e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 1.4148e-06 - val_rmse: 8.3241e-04 - val_r_square: 1.0000\n",
      "Epoch 64/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.0252e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 2.1367e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 65/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.0212e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 1.4817e-06 - val_rmse: 8.9773e-04 - val_r_square: 0.9999\n",
      "Epoch 66/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 2.0073e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 1.8116e-06 - val_rmse: 9.6549e-04 - val_r_square: 0.9999\n",
      "Epoch 67/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.9807e-06 - rmse: 0.0010 - r_square: 0.9999 - val_loss: 1.8456e-06 - val_rmse: 9.8379e-04 - val_r_square: 0.9999\n",
      "Epoch 68/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.9593e-06 - rmse: 9.9833e-04 - r_square: 0.9999 - val_loss: 4.5327e-06 - val_rmse: 0.0015 - val_r_square: 0.9998\n",
      "Epoch 69/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.9407e-06 - rmse: 9.9874e-04 - r_square: 0.9999 - val_loss: 4.2068e-06 - val_rmse: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 70/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.9091e-06 - rmse: 9.8756e-04 - r_square: 0.9999 - val_loss: 2.3542e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 71/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.9209e-06 - rmse: 9.9021e-04 - r_square: 0.9999 - val_loss: 2.4217e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 72/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8949e-06 - rmse: 9.8372e-04 - r_square: 0.9999 - val_loss: 1.7552e-06 - val_rmse: 9.6758e-04 - val_r_square: 0.9999\n",
      "Epoch 73/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8835e-06 - rmse: 9.8154e-04 - r_square: 0.9999 - val_loss: 6.1421e-06 - val_rmse: 0.0019 - val_r_square: 0.9998\n",
      "Epoch 74/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8533e-06 - rmse: 9.7348e-04 - r_square: 0.9999 - val_loss: 2.9266e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 75/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8997e-06 - rmse: 9.8573e-04 - r_square: 0.9999 - val_loss: 1.8768e-06 - val_rmse: 9.8086e-04 - val_r_square: 0.9999\n",
      "Epoch 76/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8283e-06 - rmse: 9.7001e-04 - r_square: 0.9999 - val_loss: 1.9638e-06 - val_rmse: 9.9321e-04 - val_r_square: 0.9999\n",
      "Epoch 77/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8977e-06 - rmse: 9.8104e-04 - r_square: 0.9999 - val_loss: 2.1411e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 78/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7978e-06 - rmse: 9.6101e-04 - r_square: 0.9999 - val_loss: 1.5401e-06 - val_rmse: 8.9912e-04 - val_r_square: 0.9999\n",
      "Epoch 79/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8094e-06 - rmse: 9.6333e-04 - r_square: 0.9999 - val_loss: 2.2150e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 80/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8466e-06 - rmse: 9.6803e-04 - r_square: 0.9999 - val_loss: 1.6104e-06 - val_rmse: 9.1264e-04 - val_r_square: 0.9999\n",
      "Epoch 81/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7886e-06 - rmse: 9.5219e-04 - r_square: 0.9999 - val_loss: 3.1316e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 82/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.8146e-06 - rmse: 9.6289e-04 - r_square: 0.9999 - val_loss: 1.3589e-06 - val_rmse: 8.3884e-04 - val_r_square: 1.0000\n",
      "Epoch 83/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7747e-06 - rmse: 9.5448e-04 - r_square: 0.9999 - val_loss: 1.6540e-06 - val_rmse: 9.5981e-04 - val_r_square: 0.9999\n",
      "Epoch 84/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7597e-06 - rmse: 9.4926e-04 - r_square: 0.9999 - val_loss: 1.3637e-06 - val_rmse: 8.3119e-04 - val_r_square: 1.0000\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7676e-06 - rmse: 9.5261e-04 - r_square: 0.9999 - val_loss: 2.0906e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 86/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7482e-06 - rmse: 9.4293e-04 - r_square: 0.9999 - val_loss: 1.9986e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 87/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7186e-06 - rmse: 9.3518e-04 - r_square: 0.9999 - val_loss: 1.2737e-06 - val_rmse: 8.1876e-04 - val_r_square: 1.0000\n",
      "Epoch 88/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7343e-06 - rmse: 9.4057e-04 - r_square: 0.9999 - val_loss: 3.2291e-06 - val_rmse: 0.0013 - val_r_square: 0.9999\n",
      "Epoch 89/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7155e-06 - rmse: 9.3569e-04 - r_square: 0.9999 - val_loss: 1.5804e-06 - val_rmse: 9.0855e-04 - val_r_square: 0.9999\n",
      "Epoch 90/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7048e-06 - rmse: 9.3425e-04 - r_square: 0.9999 - val_loss: 1.2728e-06 - val_rmse: 8.0513e-04 - val_r_square: 1.0000\n",
      "Epoch 91/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7049e-06 - rmse: 9.3218e-04 - r_square: 0.9999 - val_loss: 1.4367e-06 - val_rmse: 8.4774e-04 - val_r_square: 1.0000\n",
      "Epoch 92/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6722e-06 - rmse: 9.2246e-04 - r_square: 0.9999 - val_loss: 1.2966e-06 - val_rmse: 8.0006e-04 - val_r_square: 1.0000\n",
      "Epoch 93/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6761e-06 - rmse: 9.2462e-04 - r_square: 0.9999 - val_loss: 1.9476e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 94/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6551e-06 - rmse: 9.2125e-04 - r_square: 0.9999 - val_loss: 1.5968e-06 - val_rmse: 8.9589e-04 - val_r_square: 0.9999\n",
      "Epoch 95/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6857e-06 - rmse: 9.2312e-04 - r_square: 0.9999 - val_loss: 1.5895e-06 - val_rmse: 9.1809e-04 - val_r_square: 0.9999\n",
      "Epoch 96/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.7175e-06 - rmse: 9.3031e-04 - r_square: 0.9999 - val_loss: 1.2487e-06 - val_rmse: 7.8945e-04 - val_r_square: 1.0000\n",
      "Epoch 97/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6640e-06 - rmse: 9.1745e-04 - r_square: 0.9999 - val_loss: 1.1988e-06 - val_rmse: 7.8195e-04 - val_r_square: 1.0000\n",
      "Epoch 98/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6689e-06 - rmse: 9.1958e-04 - r_square: 0.9999 - val_loss: 1.8591e-06 - val_rmse: 9.8295e-04 - val_r_square: 0.9999\n",
      "Epoch 99/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6750e-06 - rmse: 9.2155e-04 - r_square: 0.9999 - val_loss: 1.1226e-06 - val_rmse: 7.5400e-04 - val_r_square: 1.0000\n",
      "Epoch 100/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6103e-06 - rmse: 9.0590e-04 - r_square: 0.9999 - val_loss: 2.0512e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 101/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6315e-06 - rmse: 9.1123e-04 - r_square: 0.9999 - val_loss: 1.4280e-06 - val_rmse: 8.6583e-04 - val_r_square: 1.0000\n",
      "Epoch 102/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6250e-06 - rmse: 9.0961e-04 - r_square: 0.9999 - val_loss: 2.3832e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 103/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6230e-06 - rmse: 9.0793e-04 - r_square: 0.9999 - val_loss: 2.8744e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 104/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6239e-06 - rmse: 9.0797e-04 - r_square: 0.9999 - val_loss: 1.2897e-06 - val_rmse: 7.9070e-04 - val_r_square: 1.0000\n",
      "Epoch 105/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.6020e-06 - rmse: 9.0542e-04 - r_square: 0.9999 - val_loss: 2.2425e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 106/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5585e-06 - rmse: 8.9203e-04 - r_square: 0.9999 - val_loss: 1.3267e-06 - val_rmse: 8.3519e-04 - val_r_square: 1.0000\n",
      "Epoch 107/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5867e-06 - rmse: 8.9638e-04 - r_square: 0.9999 - val_loss: 1.4115e-06 - val_rmse: 8.4790e-04 - val_r_square: 1.0000\n",
      "Epoch 108/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5857e-06 - rmse: 8.9971e-04 - r_square: 0.9999 - val_loss: 1.4185e-06 - val_rmse: 8.5135e-04 - val_r_square: 1.0000\n",
      "Epoch 109/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5523e-06 - rmse: 8.9095e-04 - r_square: 0.9999 - val_loss: 1.8039e-06 - val_rmse: 9.5878e-04 - val_r_square: 0.9999\n",
      "Epoch 110/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5728e-06 - rmse: 8.9474e-04 - r_square: 0.9999 - val_loss: 2.0362e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 111/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5811e-06 - rmse: 8.9827e-04 - r_square: 0.9999 - val_loss: 2.5486e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 112/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5629e-06 - rmse: 8.9031e-04 - r_square: 0.9999 - val_loss: 1.1498e-06 - val_rmse: 7.5632e-04 - val_r_square: 1.0000\n",
      "Epoch 113/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5839e-06 - rmse: 8.9568e-04 - r_square: 0.9999 - val_loss: 1.2730e-06 - val_rmse: 8.2676e-04 - val_r_square: 1.0000\n",
      "Epoch 114/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5147e-06 - rmse: 8.8066e-04 - r_square: 0.9999 - val_loss: 1.2206e-06 - val_rmse: 7.7149e-04 - val_r_square: 1.0000\n",
      "Epoch 115/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5595e-06 - rmse: 8.9037e-04 - r_square: 0.9999 - val_loss: 1.8264e-06 - val_rmse: 9.5096e-04 - val_r_square: 0.9999\n",
      "Epoch 116/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5483e-06 - rmse: 8.8493e-04 - r_square: 0.9999 - val_loss: 2.1067e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 117/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5455e-06 - rmse: 8.8596e-04 - r_square: 0.9999 - val_loss: 1.3847e-06 - val_rmse: 8.4177e-04 - val_r_square: 1.0000\n",
      "Epoch 118/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5275e-06 - rmse: 8.8170e-04 - r_square: 0.9999 - val_loss: 1.2495e-06 - val_rmse: 8.3289e-04 - val_r_square: 1.0000\n",
      "Epoch 119/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5161e-06 - rmse: 8.7643e-04 - r_square: 0.9999 - val_loss: 1.7313e-06 - val_rmse: 9.7820e-04 - val_r_square: 0.9999\n",
      "Epoch 120/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5391e-06 - rmse: 8.8319e-04 - r_square: 0.9999 - val_loss: 4.0570e-06 - val_rmse: 0.0015 - val_r_square: 0.9999\n",
      "Epoch 121/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5284e-06 - rmse: 8.8017e-04 - r_square: 0.9999 - val_loss: 1.3358e-06 - val_rmse: 8.5804e-04 - val_r_square: 1.0000\n",
      "Epoch 122/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5111e-06 - rmse: 8.7753e-04 - r_square: 0.9999 - val_loss: 1.7314e-06 - val_rmse: 9.4856e-04 - val_r_square: 0.9999\n",
      "Epoch 123/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5134e-06 - rmse: 8.7618e-04 - r_square: 0.9999 - val_loss: 1.2479e-06 - val_rmse: 7.9952e-04 - val_r_square: 1.0000\n",
      "Epoch 124/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5026e-06 - rmse: 8.7419e-04 - r_square: 0.9999 - val_loss: 1.9183e-06 - val_rmse: 9.7606e-04 - val_r_square: 0.9999\n",
      "Epoch 125/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4751e-06 - rmse: 8.6773e-04 - r_square: 0.9999 - val_loss: 1.6373e-06 - val_rmse: 9.1011e-04 - val_r_square: 0.9999\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4776e-06 - rmse: 8.6894e-04 - r_square: 0.9999 - val_loss: 1.0860e-06 - val_rmse: 7.4061e-04 - val_r_square: 1.0000\n",
      "Epoch 127/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.5125e-06 - rmse: 8.7656e-04 - r_square: 0.9999 - val_loss: 1.8893e-06 - val_rmse: 9.8516e-04 - val_r_square: 0.9999\n",
      "Epoch 128/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4770e-06 - rmse: 8.6586e-04 - r_square: 0.9999 - val_loss: 1.9260e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 129/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4487e-06 - rmse: 8.6035e-04 - r_square: 1.0000 - val_loss: 1.2120e-06 - val_rmse: 7.8755e-04 - val_r_square: 1.0000\n",
      "Epoch 130/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4442e-06 - rmse: 8.5599e-04 - r_square: 1.0000 - val_loss: 1.7751e-06 - val_rmse: 9.7791e-04 - val_r_square: 0.9999\n",
      "Epoch 131/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4610e-06 - rmse: 8.6255e-04 - r_square: 1.0000 - val_loss: 5.7436e-06 - val_rmse: 0.0017 - val_r_square: 0.9998\n",
      "Epoch 132/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4346e-06 - rmse: 8.5448e-04 - r_square: 1.0000 - val_loss: 1.3362e-06 - val_rmse: 8.3028e-04 - val_r_square: 1.0000\n",
      "Epoch 133/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4841e-06 - rmse: 8.6666e-04 - r_square: 0.9999 - val_loss: 1.2062e-06 - val_rmse: 7.8754e-04 - val_r_square: 1.0000\n",
      "Epoch 134/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4460e-06 - rmse: 8.5995e-04 - r_square: 1.0000 - val_loss: 1.0217e-06 - val_rmse: 7.1482e-04 - val_r_square: 1.0000\n",
      "Epoch 135/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4461e-06 - rmse: 8.5578e-04 - r_square: 1.0000 - val_loss: 2.1484e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 136/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4877e-06 - rmse: 8.7005e-04 - r_square: 0.9999 - val_loss: 1.3205e-06 - val_rmse: 8.2705e-04 - val_r_square: 1.0000\n",
      "Epoch 137/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4311e-06 - rmse: 8.5156e-04 - r_square: 1.0000 - val_loss: 1.2684e-06 - val_rmse: 8.0412e-04 - val_r_square: 1.0000\n",
      "Epoch 138/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4211e-06 - rmse: 8.5124e-04 - r_square: 1.0000 - val_loss: 1.3130e-05 - val_rmse: 0.0026 - val_r_square: 0.9996\n",
      "Epoch 139/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4763e-06 - rmse: 8.6162e-04 - r_square: 0.9999 - val_loss: 1.4974e-06 - val_rmse: 8.9054e-04 - val_r_square: 0.9999\n",
      "Epoch 140/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4441e-06 - rmse: 8.5711e-04 - r_square: 1.0000 - val_loss: 1.0515e-06 - val_rmse: 7.2808e-04 - val_r_square: 1.0000\n",
      "Epoch 141/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4138e-06 - rmse: 8.4604e-04 - r_square: 1.0000 - val_loss: 1.5615e-06 - val_rmse: 8.8865e-04 - val_r_square: 0.9999\n",
      "Epoch 142/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4187e-06 - rmse: 8.4940e-04 - r_square: 1.0000 - val_loss: 1.9653e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 143/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4339e-06 - rmse: 8.5074e-04 - r_square: 1.0000 - val_loss: 4.1112e-06 - val_rmse: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 144/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4049e-06 - rmse: 8.4521e-04 - r_square: 1.0000 - val_loss: 2.2212e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 145/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4300e-06 - rmse: 8.5083e-04 - r_square: 1.0000 - val_loss: 1.7562e-06 - val_rmse: 9.6339e-04 - val_r_square: 0.9999\n",
      "Epoch 146/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4186e-06 - rmse: 8.4908e-04 - r_square: 1.0000 - val_loss: 1.2345e-06 - val_rmse: 7.9504e-04 - val_r_square: 1.0000\n",
      "Epoch 147/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4345e-06 - rmse: 8.4814e-04 - r_square: 1.0000 - val_loss: 1.3830e-06 - val_rmse: 8.5669e-04 - val_r_square: 1.0000\n",
      "Epoch 148/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4184e-06 - rmse: 8.4785e-04 - r_square: 1.0000 - val_loss: 1.1865e-06 - val_rmse: 7.8515e-04 - val_r_square: 1.0000\n",
      "Epoch 149/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3832e-06 - rmse: 8.3884e-04 - r_square: 1.0000 - val_loss: 2.0789e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 150/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4132e-06 - rmse: 8.4638e-04 - r_square: 1.0000 - val_loss: 1.6719e-06 - val_rmse: 9.2857e-04 - val_r_square: 0.9999\n",
      "Epoch 151/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3956e-06 - rmse: 8.4297e-04 - r_square: 1.0000 - val_loss: 1.8827e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 152/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4019e-06 - rmse: 8.4385e-04 - r_square: 1.0000 - val_loss: 1.0279e-06 - val_rmse: 7.0738e-04 - val_r_square: 1.0000\n",
      "Epoch 153/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3772e-06 - rmse: 8.3724e-04 - r_square: 1.0000 - val_loss: 2.2651e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 154/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.4268e-06 - rmse: 8.4892e-04 - r_square: 1.0000 - val_loss: 2.4849e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 155/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3462e-06 - rmse: 8.2739e-04 - r_square: 1.0000 - val_loss: 1.4699e-06 - val_rmse: 8.8234e-04 - val_r_square: 1.0000\n",
      "Epoch 156/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3786e-06 - rmse: 8.3694e-04 - r_square: 1.0000 - val_loss: 1.8473e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 157/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3795e-06 - rmse: 8.3519e-04 - r_square: 1.0000 - val_loss: 1.4093e-06 - val_rmse: 8.5362e-04 - val_r_square: 1.0000\n",
      "Epoch 158/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3670e-06 - rmse: 8.3301e-04 - r_square: 1.0000 - val_loss: 1.0507e-06 - val_rmse: 7.2786e-04 - val_r_square: 1.0000\n",
      "Epoch 159/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3410e-06 - rmse: 8.2445e-04 - r_square: 1.0000 - val_loss: 2.6545e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 160/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3952e-06 - rmse: 8.3577e-04 - r_square: 1.0000 - val_loss: 1.2124e-06 - val_rmse: 7.9162e-04 - val_r_square: 1.0000\n",
      "Epoch 161/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3605e-06 - rmse: 8.3091e-04 - r_square: 1.0000 - val_loss: 2.3886e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 162/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3475e-06 - rmse: 8.2800e-04 - r_square: 1.0000 - val_loss: 1.3396e-06 - val_rmse: 8.3260e-04 - val_r_square: 1.0000\n",
      "Epoch 163/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3579e-06 - rmse: 8.3100e-04 - r_square: 1.0000 - val_loss: 2.4969e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 164/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3620e-06 - rmse: 8.3406e-04 - r_square: 1.0000 - val_loss: 1.4759e-06 - val_rmse: 8.8981e-04 - val_r_square: 0.9999\n",
      "Epoch 165/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3250e-06 - rmse: 8.2057e-04 - r_square: 1.0000 - val_loss: 2.6149e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 166/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3519e-06 - rmse: 8.2770e-04 - r_square: 1.0000 - val_loss: 9.4628e-07 - val_rmse: 6.9821e-04 - val_r_square: 1.0000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3260e-06 - rmse: 8.2314e-04 - r_square: 1.0000 - val_loss: 1.6272e-06 - val_rmse: 9.1657e-04 - val_r_square: 0.9999\n",
      "Epoch 168/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3219e-06 - rmse: 8.1918e-04 - r_square: 1.0000 - val_loss: 1.0479e-06 - val_rmse: 7.3202e-04 - val_r_square: 1.0000\n",
      "Epoch 169/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3580e-06 - rmse: 8.2942e-04 - r_square: 1.0000 - val_loss: 9.4361e-07 - val_rmse: 6.8010e-04 - val_r_square: 1.0000\n",
      "Epoch 170/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3185e-06 - rmse: 8.1606e-04 - r_square: 1.0000 - val_loss: 1.6328e-06 - val_rmse: 9.2178e-04 - val_r_square: 0.9999\n",
      "Epoch 171/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3073e-06 - rmse: 8.1571e-04 - r_square: 1.0000 - val_loss: 1.0404e-06 - val_rmse: 7.2663e-04 - val_r_square: 1.0000\n",
      "Epoch 172/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3331e-06 - rmse: 8.2287e-04 - r_square: 1.0000 - val_loss: 1.2116e-06 - val_rmse: 7.8165e-04 - val_r_square: 1.0000\n",
      "Epoch 173/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3216e-06 - rmse: 8.1844e-04 - r_square: 1.0000 - val_loss: 3.4739e-06 - val_rmse: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 174/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3129e-06 - rmse: 8.1592e-04 - r_square: 1.0000 - val_loss: 2.7481e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 175/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3429e-06 - rmse: 8.2307e-04 - r_square: 1.0000 - val_loss: 1.8053e-06 - val_rmse: 9.6038e-04 - val_r_square: 0.9999\n",
      "Epoch 176/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3141e-06 - rmse: 8.1501e-04 - r_square: 1.0000 - val_loss: 1.1715e-06 - val_rmse: 7.6332e-04 - val_r_square: 1.0000\n",
      "Epoch 177/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3133e-06 - rmse: 8.1546e-04 - r_square: 1.0000 - val_loss: 1.9290e-06 - val_rmse: 0.0010 - val_r_square: 0.9999\n",
      "Epoch 178/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3314e-06 - rmse: 8.1489e-04 - r_square: 1.0000 - val_loss: 1.5230e-06 - val_rmse: 8.7830e-04 - val_r_square: 0.9999\n",
      "Epoch 179/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2873e-06 - rmse: 8.0915e-04 - r_square: 1.0000 - val_loss: 1.3979e-06 - val_rmse: 8.5747e-04 - val_r_square: 1.0000\n",
      "Epoch 180/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3339e-06 - rmse: 8.2005e-04 - r_square: 1.0000 - val_loss: 1.4223e-06 - val_rmse: 8.5697e-04 - val_r_square: 1.0000\n",
      "Epoch 181/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2977e-06 - rmse: 8.1303e-04 - r_square: 1.0000 - val_loss: 1.8692e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 182/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2805e-06 - rmse: 8.0762e-04 - r_square: 1.0000 - val_loss: 1.4057e-06 - val_rmse: 8.5949e-04 - val_r_square: 1.0000\n",
      "Epoch 183/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2707e-06 - rmse: 8.0402e-04 - r_square: 1.0000 - val_loss: 1.0042e-06 - val_rmse: 7.2369e-04 - val_r_square: 1.0000\n",
      "Epoch 184/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2909e-06 - rmse: 8.1076e-04 - r_square: 1.0000 - val_loss: 5.9429e-06 - val_rmse: 0.0016 - val_r_square: 0.9998\n",
      "Epoch 185/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2870e-06 - rmse: 8.0698e-04 - r_square: 1.0000 - val_loss: 1.7867e-06 - val_rmse: 9.8908e-04 - val_r_square: 0.9999\n",
      "Epoch 186/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.3062e-06 - rmse: 8.1237e-04 - r_square: 1.0000 - val_loss: 1.1565e-06 - val_rmse: 7.5832e-04 - val_r_square: 1.0000\n",
      "Epoch 187/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2798e-06 - rmse: 8.0533e-04 - r_square: 1.0000 - val_loss: 3.4492e-06 - val_rmse: 0.0014 - val_r_square: 0.9999\n",
      "Epoch 188/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2772e-06 - rmse: 8.0403e-04 - r_square: 1.0000 - val_loss: 2.2995e-06 - val_rmse: 0.0011 - val_r_square: 0.9999\n",
      "Epoch 189/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2642e-06 - rmse: 8.0200e-04 - r_square: 1.0000 - val_loss: 1.8673e-06 - val_rmse: 9.7517e-04 - val_r_square: 0.9999\n",
      "Epoch 190/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2775e-06 - rmse: 8.0576e-04 - r_square: 1.0000 - val_loss: 1.0064e-06 - val_rmse: 7.0850e-04 - val_r_square: 1.0000\n",
      "Epoch 191/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2829e-06 - rmse: 8.0559e-04 - r_square: 1.0000 - val_loss: 1.4240e-06 - val_rmse: 8.6339e-04 - val_r_square: 1.0000\n",
      "Epoch 192/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2801e-06 - rmse: 8.0464e-04 - r_square: 1.0000 - val_loss: 4.8427e-06 - val_rmse: 0.0017 - val_r_square: 0.9998\n",
      "Epoch 193/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2676e-06 - rmse: 8.0142e-04 - r_square: 1.0000 - val_loss: 1.2912e-06 - val_rmse: 8.3195e-04 - val_r_square: 1.0000\n",
      "Epoch 194/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2770e-06 - rmse: 8.0420e-04 - r_square: 1.0000 - val_loss: 1.0790e-06 - val_rmse: 7.3710e-04 - val_r_square: 1.0000\n",
      "Epoch 195/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2605e-06 - rmse: 8.0049e-04 - r_square: 1.0000 - val_loss: 1.0626e-06 - val_rmse: 7.3364e-04 - val_r_square: 1.0000\n",
      "Epoch 196/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2552e-06 - rmse: 7.9599e-04 - r_square: 1.0000 - val_loss: 1.6133e-06 - val_rmse: 9.2038e-04 - val_r_square: 0.9999\n",
      "Epoch 197/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2663e-06 - rmse: 8.0059e-04 - r_square: 1.0000 - val_loss: 1.4315e-06 - val_rmse: 8.7406e-04 - val_r_square: 1.0000\n",
      "Epoch 198/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2540e-06 - rmse: 7.9752e-04 - r_square: 1.0000 - val_loss: 2.7400e-06 - val_rmse: 0.0012 - val_r_square: 0.9999\n",
      "Epoch 199/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2727e-06 - rmse: 8.0138e-04 - r_square: 1.0000 - val_loss: 1.3980e-06 - val_rmse: 8.5009e-04 - val_r_square: 1.0000\n",
      "Epoch 200/200\n",
      "828205/828205 [==============================] - 4s 5us/step - loss: 1.2542e-06 - rmse: 7.9929e-04 - r_square: 1.0000 - val_loss: 1.3147e-06 - val_rmse: 8.1760e-04 - val_r_square: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "result = model.fit(X_train, \n",
    "                   y_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.0357647]\n",
      " [  7.629406 ]\n",
      " [  0.880803 ]\n",
      " [  9.843321 ]\n",
      " [101.22771  ]\n",
      " [246.6744   ]\n",
      " [ 65.10281  ]\n",
      " [207.85027  ]\n",
      " [ 21.172096 ]\n",
      " [ 13.6375065]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "pre_act = sc.inverse_transform(predictions)\n",
    "y_act = sc.inverse_transform(y_test)\n",
    "print(pre_act[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.86],\n",
       "       [  7.55],\n",
       "       [  1.03],\n",
       "       [  9.3 ],\n",
       "       [100.  ],\n",
       "       [247.25],\n",
       "       [ 64.4 ],\n",
       "       [206.8 ],\n",
       "       [ 26.05],\n",
       "       [ 14.35]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_act[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curves including R^2 and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for rmse\n",
    "plt.plot(result.history['rmse'])\n",
    "plt.plot(result.history['val_rmse'])\n",
    "plt.title('rmse')\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for R^2\n",
    "plt.plot(result.history['r_square'])\n",
    "plt.plot(result.history['val_r_square'])\n",
    "plt.title('model R^2')\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.552527\n",
      "Mean squared error (MSE):       0.600395\n",
      "Root mean squared error (RMSE): 0.774851\n",
      "R square (R^2):                 0.999956\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm, math\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 828205 samples, validate on 207052 samples\n",
      "Epoch 1/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 0.0011 - rmse: 0.0161 - r_square: 0.9646 - val_loss: 7.2390e-04 - val_rmse: 0.0166 - val_r_square: 0.9758\n",
      "Epoch 2/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 9.0424e-05 - rmse: 0.0063 - r_square: 0.9969 - val_loss: 0.0013 - val_rmse: 0.0258 - val_r_square: 0.9552\n",
      "Epoch 3/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 4.5156e-05 - rmse: 0.0045 - r_square: 0.9985 - val_loss: 0.0016 - val_rmse: 0.0287 - val_r_square: 0.9475\n",
      "Epoch 4/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.2496e-05 - rmse: 0.0038 - r_square: 0.9989 - val_loss: 0.0015 - val_rmse: 0.0274 - val_r_square: 0.9494\n",
      "Epoch 5/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.3164e-05 - rmse: 0.0033 - r_square: 0.9992 - val_loss: 0.0016 - val_rmse: 0.0277 - val_r_square: 0.9472\n",
      "Epoch 6/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.1968e-05 - rmse: 0.0031 - r_square: 0.9993 - val_loss: 0.0015 - val_rmse: 0.0276 - val_r_square: 0.9500\n",
      "Epoch 7/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.7193e-05 - rmse: 0.0028 - r_square: 0.9994 - val_loss: 0.0016 - val_rmse: 0.0282 - val_r_square: 0.9469\n",
      "Epoch 8/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.7132e-05 - rmse: 0.0027 - r_square: 0.9994 - val_loss: 0.0014 - val_rmse: 0.0265 - val_r_square: 0.9520\n",
      "Epoch 9/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.4292e-05 - rmse: 0.0026 - r_square: 0.9995 - val_loss: 0.0013 - val_rmse: 0.0265 - val_r_square: 0.9552\n",
      "Epoch 10/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.4068e-05 - rmse: 0.0025 - r_square: 0.9995 - val_loss: 0.0015 - val_rmse: 0.0278 - val_r_square: 0.9495\n",
      "Epoch 11/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.1971e-05 - rmse: 0.0024 - r_square: 0.9996 - val_loss: 0.0016 - val_rmse: 0.0290 - val_r_square: 0.9476\n",
      "Epoch 12/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.2280e-05 - rmse: 0.0023 - r_square: 0.9996 - val_loss: 0.0017 - val_rmse: 0.0292 - val_r_square: 0.9430\n",
      "Epoch 13/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.2826e-05 - rmse: 0.0023 - r_square: 0.9996 - val_loss: 0.0016 - val_rmse: 0.0300 - val_r_square: 0.9449\n",
      "Epoch 14/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.2075e-05 - rmse: 0.0023 - r_square: 0.9996 - val_loss: 0.0014 - val_rmse: 0.0279 - val_r_square: 0.9515\n",
      "Epoch 15/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.0245e-05 - rmse: 0.0022 - r_square: 0.9997 - val_loss: 0.0014 - val_rmse: 0.0265 - val_r_square: 0.9543\n",
      "Epoch 16/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.0122e-05 - rmse: 0.0022 - r_square: 0.9997 - val_loss: 0.0016 - val_rmse: 0.0297 - val_r_square: 0.9448\n",
      "Epoch 17/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 9.7936e-06 - rmse: 0.0021 - r_square: 0.9997 - val_loss: 0.0015 - val_rmse: 0.0282 - val_r_square: 0.9493\n",
      "Epoch 18/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 1.1193e-05 - rmse: 0.0021 - r_square: 0.9996 - val_loss: 0.0015 - val_rmse: 0.0288 - val_r_square: 0.9486\n",
      "Epoch 19/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 9.1418e-06 - rmse: 0.0020 - r_square: 0.9997 - val_loss: 0.0014 - val_rmse: 0.0270 - val_r_square: 0.9533\n",
      "Epoch 20/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 9.1171e-06 - rmse: 0.0020 - r_square: 0.9997 - val_loss: 0.0014 - val_rmse: 0.0274 - val_r_square: 0.9525\n",
      "Epoch 21/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 8.7968e-06 - rmse: 0.0020 - r_square: 0.9997 - val_loss: 0.0013 - val_rmse: 0.0264 - val_r_square: 0.9550\n",
      "Epoch 22/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 9.4150e-06 - rmse: 0.0020 - r_square: 0.9997 - val_loss: 0.0013 - val_rmse: 0.0268 - val_r_square: 0.9544\n",
      "Epoch 23/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 8.6506e-06 - rmse: 0.0020 - r_square: 0.9997 - val_loss: 0.0014 - val_rmse: 0.0277 - val_r_square: 0.9525\n",
      "Epoch 24/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 8.3626e-06 - rmse: 0.0019 - r_square: 0.9997 - val_loss: 0.0014 - val_rmse: 0.0278 - val_r_square: 0.9519\n",
      "Epoch 25/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 8.5947e-06 - rmse: 0.0019 - r_square: 0.9997 - val_loss: 0.0013 - val_rmse: 0.0267 - val_r_square: 0.9546\n",
      "Epoch 26/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.6934e-06 - rmse: 0.0019 - r_square: 0.9997 - val_loss: 0.0015 - val_rmse: 0.0286 - val_r_square: 0.9495\n",
      "Epoch 27/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 8.0490e-06 - rmse: 0.0019 - r_square: 0.9997 - val_loss: 0.0014 - val_rmse: 0.0273 - val_r_square: 0.9527\n",
      "Epoch 28/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 8.6382e-06 - rmse: 0.0019 - r_square: 0.9997 - val_loss: 0.0014 - val_rmse: 0.0274 - val_r_square: 0.9528\n",
      "Epoch 29/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.7370e-06 - rmse: 0.0019 - r_square: 0.9997 - val_loss: 0.0015 - val_rmse: 0.0279 - val_r_square: 0.9508\n",
      "Epoch 30/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.2781e-06 - rmse: 0.0018 - r_square: 0.9998 - val_loss: 0.0014 - val_rmse: 0.0272 - val_r_square: 0.9535\n",
      "Epoch 31/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.0482e-06 - rmse: 0.0018 - r_square: 0.9998 - val_loss: 0.0013 - val_rmse: 0.0266 - val_r_square: 0.9550\n",
      "Epoch 32/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.5849e-06 - rmse: 0.0018 - r_square: 0.9997 - val_loss: 0.0013 - val_rmse: 0.0260 - val_r_square: 0.9570\n",
      "Epoch 33/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.4771e-06 - rmse: 0.0018 - r_square: 0.9997 - val_loss: 0.0014 - val_rmse: 0.0272 - val_r_square: 0.9538\n",
      "Epoch 34/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.7743e-06 - rmse: 0.0018 - r_square: 0.9998 - val_loss: 0.0014 - val_rmse: 0.0277 - val_r_square: 0.9528\n",
      "Epoch 35/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.2049e-06 - rmse: 0.0018 - r_square: 0.9998 - val_loss: 0.0012 - val_rmse: 0.0256 - val_r_square: 0.9586\n",
      "Epoch 36/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.5186e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0012 - val_rmse: 0.0257 - val_r_square: 0.9585\n",
      "Epoch 37/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.6184e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0013 - val_rmse: 0.0264 - val_r_square: 0.9565\n",
      "Epoch 38/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.6007e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0012 - val_rmse: 0.0251 - val_r_square: 0.9605\n",
      "Epoch 39/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.7081e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0012 - val_rmse: 0.0252 - val_r_square: 0.9607\n",
      "Epoch 40/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.8975e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0012 - val_rmse: 0.0252 - val_r_square: 0.9601\n",
      "Epoch 41/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.2769e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0012 - val_rmse: 0.0252 - val_r_square: 0.9602\n",
      "Epoch 42/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.2337e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0011 - val_rmse: 0.0242 - val_r_square: 0.9630\n",
      "Epoch 43/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.7833e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0012 - val_rmse: 0.0252 - val_r_square: 0.9601\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.2180e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0011 - val_rmse: 0.0248 - val_r_square: 0.9613\n",
      "Epoch 45/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.0765e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0011 - val_rmse: 0.0235 - val_r_square: 0.9644\n",
      "Epoch 46/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.5312e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0011 - val_rmse: 0.0238 - val_r_square: 0.9639\n",
      "Epoch 47/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 5.7860e-06 - rmse: 0.0016 - r_square: 0.9998 - val_loss: 0.0011 - val_rmse: 0.0243 - val_r_square: 0.9633\n",
      "Epoch 48/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.5161e-06 - rmse: 0.0017 - r_square: 0.9997 - val_loss: 0.0011 - val_rmse: 0.0241 - val_r_square: 0.9633\n",
      "Epoch 49/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.0013e-06 - rmse: 0.0016 - r_square: 0.9998 - val_loss: 0.0011 - val_rmse: 0.0239 - val_r_square: 0.9635\n",
      "Epoch 50/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 6.4721e-06 - rmse: 0.0017 - r_square: 0.9998 - val_loss: 0.0011 - val_rmse: 0.0238 - val_r_square: 0.9639\n",
      "Epoch 51/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 5.7092e-06 - rmse: 0.0016 - r_square: 0.9998 - val_loss: 0.0011 - val_rmse: 0.0238 - val_r_square: 0.9638\n",
      "Epoch 00051: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model2.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result2 = model2.fit(X_train, \n",
    "                   y_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.5129986]\n",
      " [ 21.123335 ]\n",
      " [  1.4793724]\n",
      " [  8.794034 ]\n",
      " [128.70859  ]\n",
      " [263.5434   ]\n",
      " [ 49.767467 ]\n",
      " [177.5032   ]\n",
      " [ 15.492077 ]\n",
      " [ 26.267944 ]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      16.084057\n",
      "Mean squared error (MSE):       489.496359\n",
      "Root mean squared error (RMSE): 22.124565\n",
      "R square (R^2):                 0.964373\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model2.predict(X_test)\n",
    "pre_act_2 = sc.inverse_transform(predictions2)\n",
    "print(pre_act_2[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act_2))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act_2))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act_2)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try batch normalization technique to regularize neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 828205 samples, validate on 207052 samples\n",
      "Epoch 1/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 7.4824e-04 - rmse: 0.0170 - r_square: 0.9748 - val_loss: 1.1173e-04 - val_rmse: 0.0082 - val_r_square: 0.9962\n",
      "Epoch 2/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 4.2099e-04 - rmse: 0.0130 - r_square: 0.9857 - val_loss: 2.0923e-04 - val_rmse: 0.0108 - val_r_square: 0.9929\n",
      "Epoch 3/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.9674e-04 - rmse: 0.0123 - r_square: 0.9866 - val_loss: 2.4948e-04 - val_rmse: 0.0059 - val_r_square: 0.9918\n",
      "Epoch 4/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.7015e-04 - rmse: 0.0119 - r_square: 0.9874 - val_loss: 6.1095e-05 - val_rmse: 0.0052 - val_r_square: 0.9980\n",
      "Epoch 5/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.6446e-04 - rmse: 0.0117 - r_square: 0.9877 - val_loss: 4.8681e-05 - val_rmse: 0.0046 - val_r_square: 0.9984\n",
      "Epoch 6/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.4710e-04 - rmse: 0.0114 - r_square: 0.9882 - val_loss: 3.3241e-05 - val_rmse: 0.0041 - val_r_square: 0.9989\n",
      "Epoch 7/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.5601e-04 - rmse: 0.0115 - r_square: 0.9880 - val_loss: 8.2175e-05 - val_rmse: 0.0066 - val_r_square: 0.9972\n",
      "Epoch 8/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.4108e-04 - rmse: 0.0113 - r_square: 0.9884 - val_loss: 3.9455e-04 - val_rmse: 0.0067 - val_r_square: 0.9870\n",
      "Epoch 9/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.2181e-04 - rmse: 0.0112 - r_square: 0.9890 - val_loss: 3.3479e-05 - val_rmse: 0.0046 - val_r_square: 0.9989\n",
      "Epoch 10/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.3298e-04 - rmse: 0.0113 - r_square: 0.9887 - val_loss: 1.2500e-04 - val_rmse: 0.0081 - val_r_square: 0.9958\n",
      "Epoch 11/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.1553e-04 - rmse: 0.0110 - r_square: 0.9893 - val_loss: 3.4118e-05 - val_rmse: 0.0038 - val_r_square: 0.9988\n",
      "Epoch 12/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.2760e-04 - rmse: 0.0110 - r_square: 0.9889 - val_loss: 4.1887e-05 - val_rmse: 0.0047 - val_r_square: 0.9986\n",
      "Epoch 13/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0279e-04 - rmse: 0.0109 - r_square: 0.9897 - val_loss: 2.7942e-05 - val_rmse: 0.0040 - val_r_square: 0.9991\n",
      "Epoch 14/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0128e-04 - rmse: 0.0108 - r_square: 0.9898 - val_loss: 3.0141e-05 - val_rmse: 0.0038 - val_r_square: 0.9990\n",
      "Epoch 15/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.3249e-04 - rmse: 0.0111 - r_square: 0.9887 - val_loss: 2.3856e-05 - val_rmse: 0.0037 - val_r_square: 0.9992\n",
      "Epoch 16/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.1856e-04 - rmse: 0.0109 - r_square: 0.9892 - val_loss: 8.2581e-05 - val_rmse: 0.0058 - val_r_square: 0.9973\n",
      "Epoch 17/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.1128e-04 - rmse: 0.0110 - r_square: 0.9894 - val_loss: 1.7667e-05 - val_rmse: 0.0030 - val_r_square: 0.9994\n",
      "Epoch 18/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.1136e-04 - rmse: 0.0107 - r_square: 0.9895 - val_loss: 2.3820e-05 - val_rmse: 0.0031 - val_r_square: 0.9992\n",
      "Epoch 19/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.1690e-04 - rmse: 0.0109 - r_square: 0.9893 - val_loss: 3.9654e-05 - val_rmse: 0.0044 - val_r_square: 0.9987\n",
      "Epoch 20/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0604e-04 - rmse: 0.0108 - r_square: 0.9897 - val_loss: 1.2635e-04 - val_rmse: 0.0076 - val_r_square: 0.9958\n",
      "Epoch 21/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.1430e-04 - rmse: 0.0109 - r_square: 0.9893 - val_loss: 5.6335e-05 - val_rmse: 0.0047 - val_r_square: 0.9981\n",
      "Epoch 22/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0093e-04 - rmse: 0.0107 - r_square: 0.9898 - val_loss: 1.1598e-04 - val_rmse: 0.0072 - val_r_square: 0.9961\n",
      "Epoch 23/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.1370e-04 - rmse: 0.0109 - r_square: 0.9894 - val_loss: 5.6249e-05 - val_rmse: 0.0051 - val_r_square: 0.9981\n",
      "Epoch 24/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9162e-04 - rmse: 0.0106 - r_square: 0.9902 - val_loss: 1.4809e-05 - val_rmse: 0.0025 - val_r_square: 0.9995\n",
      "Epoch 25/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0082e-04 - rmse: 0.0106 - r_square: 0.9899 - val_loss: 3.1996e-05 - val_rmse: 0.0039 - val_r_square: 0.9989\n",
      "Epoch 26/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0888e-04 - rmse: 0.0109 - r_square: 0.9895 - val_loss: 2.3411e-05 - val_rmse: 0.0031 - val_r_square: 0.9992\n",
      "Epoch 27/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.2016e-04 - rmse: 0.0110 - r_square: 0.9891 - val_loss: 3.7244e-05 - val_rmse: 0.0041 - val_r_square: 0.9987\n",
      "Epoch 28/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8891e-04 - rmse: 0.0106 - r_square: 0.9902 - val_loss: 3.9486e-05 - val_rmse: 0.0041 - val_r_square: 0.9987\n",
      "Epoch 29/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0481e-04 - rmse: 0.0108 - r_square: 0.9896 - val_loss: 5.5705e-05 - val_rmse: 0.0049 - val_r_square: 0.9981\n",
      "Epoch 30/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.1144e-04 - rmse: 0.0109 - r_square: 0.9895 - val_loss: 2.7853e-05 - val_rmse: 0.0037 - val_r_square: 0.9991\n",
      "Epoch 31/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0397e-04 - rmse: 0.0108 - r_square: 0.9897 - val_loss: 6.3075e-05 - val_rmse: 0.0050 - val_r_square: 0.9979\n",
      "Epoch 32/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9580e-04 - rmse: 0.0106 - r_square: 0.9900 - val_loss: 3.5500e-05 - val_rmse: 0.0044 - val_r_square: 0.9988\n",
      "Epoch 33/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7968e-04 - rmse: 0.0104 - r_square: 0.9905 - val_loss: 1.7670e-05 - val_rmse: 0.0030 - val_r_square: 0.9994\n",
      "Epoch 34/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9512e-04 - rmse: 0.0106 - r_square: 0.9901 - val_loss: 3.7230e-05 - val_rmse: 0.0041 - val_r_square: 0.9987\n",
      "Epoch 35/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9768e-04 - rmse: 0.0107 - r_square: 0.9899 - val_loss: 2.8452e-05 - val_rmse: 0.0037 - val_r_square: 0.9990\n",
      "Epoch 36/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0279e-04 - rmse: 0.0107 - r_square: 0.9898 - val_loss: 1.7230e-05 - val_rmse: 0.0029 - val_r_square: 0.9994\n",
      "Epoch 37/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0193e-04 - rmse: 0.0107 - r_square: 0.9898 - val_loss: 3.0087e-05 - val_rmse: 0.0040 - val_r_square: 0.9990\n",
      "Epoch 38/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8574e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 1.6703e-05 - val_rmse: 0.0029 - val_r_square: 0.9994\n",
      "Epoch 39/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0707e-04 - rmse: 0.0107 - r_square: 0.9896 - val_loss: 5.5585e-05 - val_rmse: 0.0048 - val_r_square: 0.9981\n",
      "Epoch 40/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9303e-04 - rmse: 0.0106 - r_square: 0.9901 - val_loss: 7.7355e-05 - val_rmse: 0.0045 - val_r_square: 0.9975\n",
      "Epoch 41/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0745e-04 - rmse: 0.0108 - r_square: 0.9896 - val_loss: 3.8642e-05 - val_rmse: 0.0044 - val_r_square: 0.9987\n",
      "Epoch 42/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8705e-04 - rmse: 0.0105 - r_square: 0.9902 - val_loss: 2.7125e-05 - val_rmse: 0.0036 - val_r_square: 0.9991\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9650e-04 - rmse: 0.0106 - r_square: 0.9899 - val_loss: 1.9317e-05 - val_rmse: 0.0031 - val_r_square: 0.9993\n",
      "Epoch 44/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8757e-04 - rmse: 0.0106 - r_square: 0.9902 - val_loss: 1.8740e-05 - val_rmse: 0.0030 - val_r_square: 0.9994\n",
      "Epoch 45/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9029e-04 - rmse: 0.0105 - r_square: 0.9902 - val_loss: 2.7075e-05 - val_rmse: 0.0037 - val_r_square: 0.9991\n",
      "Epoch 46/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8706e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 4.8878e-05 - val_rmse: 0.0051 - val_r_square: 0.9984\n",
      "Epoch 47/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9769e-04 - rmse: 0.0106 - r_square: 0.9899 - val_loss: 5.0055e-05 - val_rmse: 0.0050 - val_r_square: 0.9983\n",
      "Epoch 48/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9828e-04 - rmse: 0.0106 - r_square: 0.9899 - val_loss: 1.4371e-05 - val_rmse: 0.0025 - val_r_square: 0.9995\n",
      "Epoch 49/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9833e-04 - rmse: 0.0107 - r_square: 0.9899 - val_loss: 2.6391e-05 - val_rmse: 0.0035 - val_r_square: 0.9991\n",
      "Epoch 50/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0654e-04 - rmse: 0.0106 - r_square: 0.9896 - val_loss: 2.5987e-05 - val_rmse: 0.0036 - val_r_square: 0.9991\n",
      "Epoch 51/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7672e-04 - rmse: 0.0104 - r_square: 0.9907 - val_loss: 8.0267e-05 - val_rmse: 0.0057 - val_r_square: 0.9973\n",
      "Epoch 52/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8454e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 8.3293e-05 - val_rmse: 0.0066 - val_r_square: 0.9972\n",
      "Epoch 53/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8788e-04 - rmse: 0.0106 - r_square: 0.9902 - val_loss: 2.3879e-05 - val_rmse: 0.0032 - val_r_square: 0.9992\n",
      "Epoch 54/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8990e-04 - rmse: 0.0105 - r_square: 0.9902 - val_loss: 5.2580e-05 - val_rmse: 0.0047 - val_r_square: 0.9982\n",
      "Epoch 55/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8951e-04 - rmse: 0.0105 - r_square: 0.9901 - val_loss: 3.4727e-05 - val_rmse: 0.0044 - val_r_square: 0.9988\n",
      "Epoch 56/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8722e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 4.7398e-05 - val_rmse: 0.0049 - val_r_square: 0.9984\n",
      "Epoch 57/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8296e-04 - rmse: 0.0104 - r_square: 0.9903 - val_loss: 2.8953e-05 - val_rmse: 0.0038 - val_r_square: 0.9990\n",
      "Epoch 58/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8369e-04 - rmse: 0.0104 - r_square: 0.9904 - val_loss: 4.3172e-05 - val_rmse: 0.0041 - val_r_square: 0.9985\n",
      "Epoch 59/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8732e-04 - rmse: 0.0106 - r_square: 0.9902 - val_loss: 2.4062e-05 - val_rmse: 0.0038 - val_r_square: 0.9992\n",
      "Epoch 60/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9142e-04 - rmse: 0.0106 - r_square: 0.9901 - val_loss: 7.6194e-05 - val_rmse: 0.0058 - val_r_square: 0.9975\n",
      "Epoch 61/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7998e-04 - rmse: 0.0105 - r_square: 0.9905 - val_loss: 1.8300e-05 - val_rmse: 0.0029 - val_r_square: 0.9994\n",
      "Epoch 62/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8497e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 4.4798e-05 - val_rmse: 0.0048 - val_r_square: 0.9985\n",
      "Epoch 63/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9098e-04 - rmse: 0.0106 - r_square: 0.9901 - val_loss: 7.6308e-05 - val_rmse: 0.0057 - val_r_square: 0.9974\n",
      "Epoch 64/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9011e-04 - rmse: 0.0106 - r_square: 0.9902 - val_loss: 2.0437e-05 - val_rmse: 0.0030 - val_r_square: 0.9993\n",
      "Epoch 65/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9132e-04 - rmse: 0.0105 - r_square: 0.9902 - val_loss: 1.6830e-05 - val_rmse: 0.0028 - val_r_square: 0.9994\n",
      "Epoch 66/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 3.0146e-04 - rmse: 0.0107 - r_square: 0.9898 - val_loss: 1.2389e-04 - val_rmse: 0.0070 - val_r_square: 0.9959\n",
      "Epoch 67/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9013e-04 - rmse: 0.0106 - r_square: 0.9901 - val_loss: 3.2691e-05 - val_rmse: 0.0042 - val_r_square: 0.9989\n",
      "Epoch 68/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7908e-04 - rmse: 0.0104 - r_square: 0.9905 - val_loss: 1.4383e-04 - val_rmse: 0.0061 - val_r_square: 0.9953\n",
      "Epoch 69/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8716e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 2.2374e-05 - val_rmse: 0.0033 - val_r_square: 0.9992\n",
      "Epoch 70/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8524e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 2.6042e-05 - val_rmse: 0.0036 - val_r_square: 0.9991\n",
      "Epoch 71/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8651e-04 - rmse: 0.0106 - r_square: 0.9903 - val_loss: 1.9749e-05 - val_rmse: 0.0031 - val_r_square: 0.9993\n",
      "Epoch 72/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8314e-04 - rmse: 0.0105 - r_square: 0.9904 - val_loss: 5.0458e-05 - val_rmse: 0.0047 - val_r_square: 0.9983\n",
      "Epoch 73/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7891e-04 - rmse: 0.0103 - r_square: 0.9905 - val_loss: 6.0226e-05 - val_rmse: 0.0051 - val_r_square: 0.9980\n",
      "Epoch 74/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8519e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 2.8935e-05 - val_rmse: 0.0039 - val_r_square: 0.9990\n",
      "Epoch 75/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8635e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 4.1524e-05 - val_rmse: 0.0044 - val_r_square: 0.9986\n",
      "Epoch 76/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7495e-04 - rmse: 0.0104 - r_square: 0.9907 - val_loss: 1.5161e-05 - val_rmse: 0.0026 - val_r_square: 0.9995\n",
      "Epoch 77/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8660e-04 - rmse: 0.0103 - r_square: 0.9903 - val_loss: 3.0822e-05 - val_rmse: 0.0038 - val_r_square: 0.9990\n",
      "Epoch 78/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7954e-04 - rmse: 0.0104 - r_square: 0.9905 - val_loss: 3.6010e-05 - val_rmse: 0.0042 - val_r_square: 0.9988\n",
      "Epoch 79/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9511e-04 - rmse: 0.0106 - r_square: 0.9900 - val_loss: 2.4821e-05 - val_rmse: 0.0034 - val_r_square: 0.9992\n",
      "Epoch 80/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8271e-04 - rmse: 0.0104 - r_square: 0.9904 - val_loss: 2.5355e-05 - val_rmse: 0.0036 - val_r_square: 0.9991\n",
      "Epoch 81/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7486e-04 - rmse: 0.0104 - r_square: 0.9907 - val_loss: 2.2227e-05 - val_rmse: 0.0033 - val_r_square: 0.9993\n",
      "Epoch 82/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.9167e-04 - rmse: 0.0105 - r_square: 0.9901 - val_loss: 2.2105e-05 - val_rmse: 0.0033 - val_r_square: 0.9993\n",
      "Epoch 83/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7970e-04 - rmse: 0.0104 - r_square: 0.9905 - val_loss: 4.5950e-05 - val_rmse: 0.0042 - val_r_square: 0.9985\n",
      "Epoch 84/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8531e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 1.9042e-05 - val_rmse: 0.0031 - val_r_square: 0.9994\n",
      "Epoch 85/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8490e-04 - rmse: 0.0105 - r_square: 0.9903 - val_loss: 3.0774e-05 - val_rmse: 0.0039 - val_r_square: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8957e-04 - rmse: 0.0105 - r_square: 0.9902 - val_loss: 1.6515e-05 - val_rmse: 0.0028 - val_r_square: 0.9994\n",
      "Epoch 87/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8190e-04 - rmse: 0.0105 - r_square: 0.9904 - val_loss: 2.2233e-05 - val_rmse: 0.0030 - val_r_square: 0.9993\n",
      "Epoch 88/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8614e-04 - rmse: 0.0104 - r_square: 0.9903 - val_loss: 3.5048e-05 - val_rmse: 0.0044 - val_r_square: 0.9988\n",
      "Epoch 89/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8992e-04 - rmse: 0.0105 - r_square: 0.9902 - val_loss: 7.0878e-05 - val_rmse: 0.0058 - val_r_square: 0.9976\n",
      "Epoch 90/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8102e-04 - rmse: 0.0105 - r_square: 0.9905 - val_loss: 3.5079e-05 - val_rmse: 0.0040 - val_r_square: 0.9988\n",
      "Epoch 91/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7637e-04 - rmse: 0.0103 - r_square: 0.9906 - val_loss: 2.8738e-05 - val_rmse: 0.0040 - val_r_square: 0.9990\n",
      "Epoch 92/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7628e-04 - rmse: 0.0103 - r_square: 0.9906 - val_loss: 2.9812e-05 - val_rmse: 0.0040 - val_r_square: 0.9990\n",
      "Epoch 93/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8317e-04 - rmse: 0.0104 - r_square: 0.9903 - val_loss: 3.4289e-05 - val_rmse: 0.0038 - val_r_square: 0.9988\n",
      "Epoch 94/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8219e-04 - rmse: 0.0103 - r_square: 0.9904 - val_loss: 5.5320e-05 - val_rmse: 0.0046 - val_r_square: 0.9982\n",
      "Epoch 95/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7703e-04 - rmse: 0.0104 - r_square: 0.9906 - val_loss: 2.6990e-05 - val_rmse: 0.0033 - val_r_square: 0.9991\n",
      "Epoch 96/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8298e-04 - rmse: 0.0105 - r_square: 0.9904 - val_loss: 1.6513e-05 - val_rmse: 0.0029 - val_r_square: 0.9994\n",
      "Epoch 97/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.8065e-04 - rmse: 0.0103 - r_square: 0.9905 - val_loss: 3.2209e-05 - val_rmse: 0.0044 - val_r_square: 0.9989\n",
      "Epoch 98/200\n",
      "828205/828205 [==============================] - 5s 6us/step - loss: 2.7719e-04 - rmse: 0.0103 - r_square: 0.9905 - val_loss: 3.1340e-05 - val_rmse: 0.0037 - val_r_square: 0.9989\n",
      "Epoch 00098: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model3 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', input_shape=(7,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model3.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result3 = model3.fit(X_train, \n",
    "                   y_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.099005 ]\n",
      " [  8.367201 ]\n",
      " [  0.8974564]\n",
      " [  8.664426 ]\n",
      " [ 96.953476 ]\n",
      " [237.70483  ]\n",
      " [ 61.601765 ]\n",
      " [202.17596  ]\n",
      " [ 19.617977 ]\n",
      " [ 13.987272 ]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      2.523942\n",
      "Mean squared error (MSE):       14.312753\n",
      "Root mean squared error (RMSE): 3.783220\n",
      "R square (R^2):                 0.998958\n"
     ]
    }
   ],
   "source": [
    "predictions3 = model3.predict(X_test)\n",
    "pre_act_3 = sc.inverse_transform(predictions3)\n",
    "print(pre_act_3[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_act,pre_act_3))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_act,pre_act_3))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_act,pre_act_3)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_act,pre_act_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference: \n",
    "&emsp;&emsp;What does 'Accuracy' mean in Regression? https://github.com/keras-team/keras/issues/7947 <br>\n",
    "&emsp;&emsp;https://keras.io/metrics/<br>\n",
    "&emsp;&emsp;Scale, Standardize, or Normalize with Scikit-Learn https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02 <br>\n",
    "&emsp;&emsp;The Day my Computer Won the Nobel Prize (Neural Network Option Pricing)  https://medium.com/datadriveninvestor/the-day-my-computer-won-the-nobel-prize-neural-network-option-pricing-d29b4379f1d2 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
