{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl (1.4MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-19.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: pyyaml in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\program files\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/58/34bfa8fa17f86333361172b3b502e805195180f19a7496ad0f6149138d55/tensorflow-1.13.1-cp36-cp36m-win_amd64.whl (63.1MB)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/59/ec6c6075dd628f2efd33dbe11b259e63e1de7cbc26e45b38de767df528d4/protobuf-3.8.0-cp36-cp36m-win_amd64.whl (1.1MB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/6a/e83233ed636bdf8668f0e79897fd70bce04869482dd88f3cfc4c42404fb2/grpcio-1.21.1-cp36-cp36m-win_amd64.whl (1.6MB)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\mayingzh\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.3)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: h5py in c:\\program files\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\program files\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: termcolor, gast, absl-py\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\mayingzh\\AppData\\Local\\pip\\Cache\\wheels\\ee\\98\\38\\46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "Successfully built termcolor gast absl-py\n",
      "Installing collected packages: protobuf, termcolor, gast, absl-py, grpcio, astor, markdown, tensorboard, mock, tensorflow-estimator, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 grpcio-1.21.1 markdown-3.1.1 mock-3.0.5 protobuf-3.8.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading https://files.pythonhosted.org/packages/20/ed/e036d31a9b2c750f270cbb1cfc1c0f94ac78ae504eea7eec3267be4e294a/numpy-1.16.4-cp36-cp36m-win_amd64.whl (11.9MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.16.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\mayingzh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "!pip install --user keras\n",
    "!pip install --user tensorflow\n",
    "!pip install --user -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CPU only\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and do data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>exdate</th>\n",
       "      <th>maturity</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>underlying_price</th>\n",
       "      <th>cp_flag_C</th>\n",
       "      <th>cp_flag_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.181376</td>\n",
       "      <td>58.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.450289</td>\n",
       "      <td>58.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.676564</td>\n",
       "      <td>58.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.369425</td>\n",
       "      <td>58.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AXP</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.888123</td>\n",
       "      <td>58.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date      exdate  maturity  strike_price  best_offer  \\\n",
       "0    AXP  2013-01-02  2013-01-04         2          60.0        0.03   \n",
       "1    AXP  2013-01-02  2013-01-04         2          62.5        0.05   \n",
       "2    AXP  2013-01-02  2013-01-04         2          65.0        0.05   \n",
       "3    AXP  2013-01-02  2013-01-04         2          67.5        0.50   \n",
       "4    AXP  2013-01-02  2013-01-04         2          70.0        0.01   \n",
       "\n",
       "   impl_volatility  underlying_price  cp_flag_C  cp_flag_P  \n",
       "0         0.181376             58.75          1          0  \n",
       "1         0.450289             58.75          1          0  \n",
       "2         0.676564             58.75          1          0  \n",
       "3         1.369425             58.75          1          0  \n",
       "4         0.888123             58.75          1          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Options.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['best_offer'].values\n",
    "X = df[['maturity', 'strike_price', 'impl_volatility', 'underlying_price', 'cp_flag_C', 'cp_flag_P']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data to build a regression neural network model\n",
    "sc= preprocessing.MinMaxScaler()\n",
    "X= sc.fit_transform(X)\n",
    "y= y.reshape(-1,1)\n",
    "y=sc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573351, 6)\n",
      "(1573351, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train, XX_validation, yy_train, yy_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built Keras sequential model with 3 hidden layer, and after the first hidden layer.\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(6,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable early stopping based on the loss of validation data\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is a simple regression problem, we should custom metrics function\n",
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1))\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean_squared_error to compile regression model loss\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1258680 samples, validate on 314671 samples\n",
      "Epoch 1/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 1.2521e-04 - rmse: 0.0041 - r_square: 0.9881 - val_loss: 2.6333e-05 - val_rmse: 0.0039 - val_r_square: 0.9974\n",
      "Epoch 2/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 1.3736e-05 - rmse: 0.0025 - r_square: 0.9986 - val_loss: 9.3649e-06 - val_rmse: 0.0021 - val_r_square: 0.9991\n",
      "Epoch 3/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 1.0946e-05 - rmse: 0.0022 - r_square: 0.9989 - val_loss: 1.0919e-05 - val_rmse: 0.0022 - val_r_square: 0.9989\n",
      "Epoch 4/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 9.1033e-06 - rmse: 0.0019 - r_square: 0.9991 - val_loss: 5.6784e-06 - val_rmse: 0.0014 - val_r_square: 0.9994\n",
      "Epoch 5/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 8.0413e-06 - rmse: 0.0018 - r_square: 0.9992 - val_loss: 5.9252e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 6/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 7.5417e-06 - rmse: 0.0017 - r_square: 0.9993 - val_loss: 5.6026e-06 - val_rmse: 0.0015 - val_r_square: 0.9995\n",
      "Epoch 7/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 7.1565e-06 - rmse: 0.0017 - r_square: 0.9993 - val_loss: 7.4322e-06 - val_rmse: 0.0017 - val_r_square: 0.9993\n",
      "Epoch 8/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 6.8538e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 6.3870e-06 - val_rmse: 0.0016 - val_r_square: 0.9994\n",
      "Epoch 9/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 6.5609e-06 - rmse: 0.0016 - r_square: 0.9994 - val_loss: 8.4156e-06 - val_rmse: 0.0017 - val_r_square: 0.9992\n",
      "Epoch 10/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 6.3769e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 5.2138e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 11/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 6.1054e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 7.0084e-06 - val_rmse: 0.0015 - val_r_square: 0.9993\n",
      "Epoch 12/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 6.0304e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 4.4528e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 13/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 5.9794e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 4.8211e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 14/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 5.7980e-06 - rmse: 0.0014 - r_square: 0.9994 - val_loss: 4.8975e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 15/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.7687e-06 - rmse: 0.0014 - r_square: 0.9994 - val_loss: 9.9562e-06 - val_rmse: 0.0019 - val_r_square: 0.9990\n",
      "Epoch 16/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 5.6151e-06 - rmse: 0.0014 - r_square: 0.9994 - val_loss: 7.7668e-06 - val_rmse: 0.0018 - val_r_square: 0.9992\n",
      "Epoch 17/200\n",
      "1258680/1258680 [==============================] - 21s 16us/step - loss: 5.5760e-06 - rmse: 0.0014 - r_square: 0.9994 - val_loss: 6.7596e-06 - val_rmse: 0.0016 - val_r_square: 0.9993\n",
      "Epoch 18/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 5.5367e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 5.3382e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 19/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 5.4335e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 5.1905e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 20/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 5.3875e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 4.3865e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 21/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.3636e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 5.8822e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 22/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.2923e-06 - rmse: 0.0014 - r_square: 0.9995 - val_loss: 5.3002e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 23/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.2626e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.7226e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 24/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 5.2657e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 6.2241e-06 - val_rmse: 0.0014 - val_r_square: 0.9994\n",
      "Epoch 25/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 5.1827e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 7.2431e-06 - val_rmse: 0.0015 - val_r_square: 0.9993\n",
      "Epoch 26/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.1636e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.1391e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 27/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.0765e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.3720e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 28/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.1023e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.5273e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 29/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.0589e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.6101e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 30/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 5.0085e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.0759e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 31/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 5.0149e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.1255e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 32/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.9781e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.0960e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 33/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.9252e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.9016e-06 - val_rmse: 0.0014 - val_r_square: 0.9994\n",
      "Epoch 34/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.8832e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.2423e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 35/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.9098e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 1.0063e-05 - val_rmse: 0.0019 - val_r_square: 0.9990\n",
      "Epoch 36/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.9080e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.4794e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 37/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.8891e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.2326e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 38/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.8874e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.1834e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 39/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.8959e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.2756e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 40/200\n",
      "1258680/1258680 [==============================] - 16s 13us/step - loss: 4.8067e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.5450e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 41/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.8130e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 5.1332e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.7911e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.1476e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 43/200\n",
      "1258680/1258680 [==============================] - 16s 13us/step - loss: 4.7948e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.2708e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 44/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.7686e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.3124e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 45/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.7502e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.0832e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 46/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.7131e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.1871e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 47/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.7181e-06 - rmse: 0.0013 - r_square: 0.9995 - val_loss: 4.0424e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 48/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.7035e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.7164e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 49/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.7076e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 3.9980e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 50/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6697e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.0883e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 51/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6771e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.6112e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 52/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6708e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.3569e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 53/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6529e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 5.3903e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 54/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6501e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.3861e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 55/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6551e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.2487e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 56/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5985e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 5.8019e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 57/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6590e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 3.9485e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 58/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5778e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 3.9176e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 59/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6062e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.5492e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 60/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5446e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3717e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 61/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.6052e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.9767e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 62/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5833e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 3.9598e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 63/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5556e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0860e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 64/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5376e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.2255e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 65/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5883e-06 - rmse: 0.0012 - r_square: 0.9995 - val_loss: 4.9395e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 66/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5057e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3706e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 67/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5332e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9604e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 68/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5431e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1366e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 69/200\n",
      "1258680/1258680 [==============================] - 16s 13us/step - loss: 4.5147e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1082e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 70/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5109e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.9238e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 71/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5188e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.5727e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 72/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.4793e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3305e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 73/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.5183e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.5966e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 74/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5019e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0850e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 75/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.5026e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.6452e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 76/200\n",
      "1258680/1258680 [==============================] - 24s 19us/step - loss: 4.4809e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0990e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 77/200\n",
      "1258680/1258680 [==============================] - 21s 17us/step - loss: 4.4763e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.0631e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 78/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.4284e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0302e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 79/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.4413e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.0115e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 80/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 4.4761e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 6.2865e-06 - val_rmse: 0.0017 - val_r_square: 0.9994\n",
      "Epoch 81/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 4.4043e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9827e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 82/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.4455e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.8132e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 83/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.4377e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1840e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "1258680/1258680 [==============================] - 16s 13us/step - loss: 4.4316e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.8910e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 85/200\n",
      "1258680/1258680 [==============================] - 23s 18us/step - loss: 4.3917e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.4650e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 86/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.3903e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8902e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 87/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.3671e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.2352e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 88/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.3983e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.4021e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 89/200\n",
      "1258680/1258680 [==============================] - 22s 17us/step - loss: 4.4138e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.0662e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 90/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.3535e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.4574e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 91/200\n",
      "1258680/1258680 [==============================] - 26s 21us/step - loss: 4.4050e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.4176e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 92/200\n",
      "1258680/1258680 [==============================] - 23s 18us/step - loss: 4.4091e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3090e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 93/200\n",
      "1258680/1258680 [==============================] - 24s 19us/step - loss: 4.3870e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8304e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 94/200\n",
      "1258680/1258680 [==============================] - 21s 17us/step - loss: 4.3720e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.3752e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 95/200\n",
      "1258680/1258680 [==============================] - 21s 17us/step - loss: 4.3741e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3211e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 96/200\n",
      "1258680/1258680 [==============================] - 21s 16us/step - loss: 4.3730e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9625e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 97/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.3464e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.4765e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 98/200\n",
      "1258680/1258680 [==============================] - 22s 18us/step - loss: 4.3433e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9390e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 99/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.3368e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.4137e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 100/200\n",
      "1258680/1258680 [==============================] - 21s 16us/step - loss: 4.3474e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1982e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 101/200\n",
      "1258680/1258680 [==============================] - 22s 17us/step - loss: 4.3453e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.2780e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 102/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.3247e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8319e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 103/200\n",
      "1258680/1258680 [==============================] - 21s 16us/step - loss: 4.3306e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 6.9083e-06 - val_rmse: 0.0017 - val_r_square: 0.9993\n",
      "Epoch 104/200\n",
      "1258680/1258680 [==============================] - 18s 15us/step - loss: 4.2991e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.3874e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 105/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.3116e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0088e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 106/200\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 4.3294e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.4099e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 107/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 4.2577e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9933e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 108/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 4.2789e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3287e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 109/200\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 4.3057e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.7620e-06 - val_rmse: 0.0013 - val_r_square: 0.9994\n",
      "Epoch 110/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2973e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0795e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 111/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.3228e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.2811e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 112/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2681e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7790e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 113/200\n",
      "1258680/1258680 [==============================] - 17s 13us/step - loss: 4.3044e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9375e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 114/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2564e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.6713e-06 - val_rmse: 0.0014 - val_r_square: 0.9994\n",
      "Epoch 115/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2574e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9544e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 116/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.2954e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1471e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 117/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2684e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.7219e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 118/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2675e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.7203e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 119/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2597e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9382e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 120/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2802e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.4792e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 121/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2196e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9409e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 122/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.2497e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8488e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 123/200\n",
      "1258680/1258680 [==============================] - 18s 14us/step - loss: 4.2694e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0210e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 124/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2370e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0734e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 125/200\n",
      "1258680/1258680 [==============================] - 17s 14us/step - loss: 4.2296e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7617e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.2292e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.9778e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 127/200\n",
      "1258680/1258680 [==============================] - 16s 13us/step - loss: 4.2265e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.1165e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 128/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.2066e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8690e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 129/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.2653e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0233e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 130/200\n",
      "1258680/1258680 [==============================] - 16s 12us/step - loss: 4.2215e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3293e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 131/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.2088e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1049e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 132/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1917e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1495e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 133/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.2171e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.6583e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 134/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1843e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.7269e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 135/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1892e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.6365e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 136/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.2002e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7275e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 137/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1942e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1278e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 138/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.2013e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7124e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 139/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1898e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9432e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 140/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.2011e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.2268e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 141/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1930e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 6.2924e-06 - val_rmse: 0.0015 - val_r_square: 0.9994\n",
      "Epoch 142/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1775e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.6553e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 143/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1977e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0121e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 144/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1671e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1142e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 145/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1878e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.0966e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 146/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1653e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.5224e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 147/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.2151e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8151e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 148/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1452e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6968e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 149/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1885e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.2855e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 150/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1734e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.6380e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 151/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1340e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.3085e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 152/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1791e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.7390e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 153/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1729e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.3314e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 154/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1923e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9217e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 155/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1384e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2268e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 156/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1486e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1025e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 157/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1491e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9600e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 158/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1463e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.6135e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 159/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1217e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9828e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 160/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1004e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.2234e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 161/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1433e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.5295e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 162/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1325e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 5.5011e-06 - val_rmse: 0.0014 - val_r_square: 0.9995\n",
      "Epoch 163/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1196e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7960e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 164/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1391e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9554e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 165/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1563e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.9308e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 166/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1380e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.6704e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1682e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 4.1121e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 168/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1163e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.3409e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 169/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1531e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8064e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 170/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1190e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0852e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 171/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1115e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2169e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 172/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1181e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0900e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 173/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1074e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7056e-06 - val_rmse: 0.0010 - val_r_square: 0.9996\n",
      "Epoch 174/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1122e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.7270e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 175/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1197e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.7435e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 176/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1328e-06 - rmse: 0.0012 - r_square: 0.9996 - val_loss: 3.8264e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 177/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0982e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4804e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 178/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0789e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.6668e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 179/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1015e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.2412e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 180/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1051e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9552e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 181/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1017e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8962e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 182/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0939e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9591e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 183/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0781e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4694e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 184/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0791e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8282e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 185/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0904e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9213e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 186/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0978e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.0141e-06 - val_rmse: 0.0013 - val_r_square: 0.9995\n",
      "Epoch 187/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0815e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.1098e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 188/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0572e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8727e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 189/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0728e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.0348e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 190/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.1208e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8443e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 191/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0674e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.6067e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 192/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0855e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8378e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 193/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0550e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 5.6932e-06 - val_rmse: 0.0013 - val_r_square: 0.9994\n",
      "Epoch 194/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0405e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.7406e-06 - val_rmse: 0.0012 - val_r_square: 0.9995\n",
      "Epoch 195/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0745e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9286e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 196/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0972e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4959e-06 - val_rmse: 0.0012 - val_r_square: 0.9996\n",
      "Epoch 197/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0835e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.4699e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 198/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0562e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.8798e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 199/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0634e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 3.9226e-06 - val_rmse: 0.0011 - val_r_square: 0.9996\n",
      "Epoch 200/200\n",
      "1258680/1258680 [==============================] - 15s 12us/step - loss: 4.0741e-06 - rmse: 0.0011 - r_square: 0.9996 - val_loss: 4.5175e-06 - val_rmse: 0.0013 - val_r_square: 0.9996\n",
      "Epoch 00200: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "result = model.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05586029]\n",
      " [0.00241558]\n",
      " [0.00177731]\n",
      " [0.07973139]\n",
      " [0.03048718]\n",
      " [0.00082504]\n",
      " [0.00016485]\n",
      " [0.11386313]\n",
      " [0.00207109]\n",
      " [0.00079346]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05267722],\n",
       "       [0.00354072],\n",
       "       [0.00187875],\n",
       "       [0.07471638],\n",
       "       [0.03136065],\n",
       "       [0.0003613 ],\n",
       "       [0.00028904],\n",
       "       [0.11337524],\n",
       "       [0.00122841],\n",
       "       [0.00050582]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning curves including R^2 and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for rmse\n",
    "plt.plot(result.history['rmse'])\n",
    "plt.plot(result.history['val_rmse'])\n",
    "plt.title('rmse')\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve for R^2\n",
    "plt.plot(result.history['r_square'])\n",
    "plt.plot(result.history['val_r_square'])\n",
    "plt.title('model R^2')\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.001252\n",
      "Mean squared error (MSE):       0.000004\n",
      "Root mean squared error (RMSE): 0.002118\n",
      "R square (R^2):                 0.999578\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm, math\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_test,predictions))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_test,predictions))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_test,predictions)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1258680 samples, validate on 314671 samples\n",
      "Epoch 1/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 2.8917e-04 - rmse: 0.0080 - r_square: 0.9724 - val_loss: 2.5321e-04 - val_rmse: 0.0088 - val_r_square: 0.9761\n",
      "Epoch 2/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 2.8919e-05 - rmse: 0.0033 - r_square: 0.9972 - val_loss: 2.1958e-04 - val_rmse: 0.0078 - val_r_square: 0.9793\n",
      "Epoch 3/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 1.8725e-05 - rmse: 0.0027 - r_square: 0.9982 - val_loss: 1.9962e-04 - val_rmse: 0.0072 - val_r_square: 0.9813\n",
      "Epoch 4/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 1.4866e-05 - rmse: 0.0024 - r_square: 0.9985 - val_loss: 2.3551e-04 - val_rmse: 0.0084 - val_r_square: 0.9778\n",
      "Epoch 5/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 1.3045e-05 - rmse: 0.0022 - r_square: 0.9987 - val_loss: 1.6788e-04 - val_rmse: 0.0063 - val_r_square: 0.9843\n",
      "Epoch 6/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 1.1717e-05 - rmse: 0.0021 - r_square: 0.9988 - val_loss: 1.6766e-04 - val_rmse: 0.0062 - val_r_square: 0.9843\n",
      "Epoch 7/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 1.0993e-05 - rmse: 0.0020 - r_square: 0.9989 - val_loss: 1.7289e-04 - val_rmse: 0.0062 - val_r_square: 0.9838\n",
      "Epoch 8/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 1.0174e-05 - rmse: 0.0019 - r_square: 0.9990 - val_loss: 1.9205e-04 - val_rmse: 0.0070 - val_r_square: 0.9820\n",
      "Epoch 9/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 1.0211e-05 - rmse: 0.0019 - r_square: 0.9990 - val_loss: 1.7658e-04 - val_rmse: 0.0065 - val_r_square: 0.9834\n",
      "Epoch 10/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 9.7083e-06 - rmse: 0.0019 - r_square: 0.9990 - val_loss: 1.7193e-04 - val_rmse: 0.0064 - val_r_square: 0.9839\n",
      "Epoch 11/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 9.2064e-06 - rmse: 0.0018 - r_square: 0.9991 - val_loss: 1.8125e-04 - val_rmse: 0.0066 - val_r_square: 0.9830\n",
      "Epoch 12/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 8.9488e-06 - rmse: 0.0018 - r_square: 0.9991 - val_loss: 1.6816e-04 - val_rmse: 0.0063 - val_r_square: 0.9843\n",
      "Epoch 13/150\n",
      "1258680/1258680 [==============================] - 25s 20us/step - loss: 8.7716e-06 - rmse: 0.0018 - r_square: 0.9991 - val_loss: 1.5108e-04 - val_rmse: 0.0059 - val_r_square: 0.9859\n",
      "Epoch 14/150\n",
      "1258680/1258680 [==============================] - 22s 17us/step - loss: 8.6037e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.7327e-04 - val_rmse: 0.0064 - val_r_square: 0.9838\n",
      "Epoch 15/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 8.3254e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.7985e-04 - val_rmse: 0.0064 - val_r_square: 0.9832\n",
      "Epoch 16/150\n",
      "1258680/1258680 [==============================] - 21s 16us/step - loss: 8.1329e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.9756e-04 - val_rmse: 0.0070 - val_r_square: 0.9815\n",
      "Epoch 17/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 8.1311e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.7686e-04 - val_rmse: 0.0065 - val_r_square: 0.9835\n",
      "Epoch 18/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 7.8342e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.7993e-04 - val_rmse: 0.0065 - val_r_square: 0.9832\n",
      "Epoch 19/150\n",
      "1258680/1258680 [==============================] - 21s 17us/step - loss: 7.7467e-06 - rmse: 0.0017 - r_square: 0.9992 - val_loss: 1.6600e-04 - val_rmse: 0.0062 - val_r_square: 0.9845\n",
      "Epoch 20/150\n",
      "1258680/1258680 [==============================] - 26s 21us/step - loss: 7.5806e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.8818e-04 - val_rmse: 0.0065 - val_r_square: 0.9824\n",
      "Epoch 21/150\n",
      "1258680/1258680 [==============================] - 24s 19us/step - loss: 7.4722e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.6608e-04 - val_rmse: 0.0063 - val_r_square: 0.9844\n",
      "Epoch 22/150\n",
      "1258680/1258680 [==============================] - 22s 17us/step - loss: 7.5391e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.8567e-04 - val_rmse: 0.0067 - val_r_square: 0.9826\n",
      "Epoch 23/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 7.3532e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.6378e-04 - val_rmse: 0.0061 - val_r_square: 0.9847\n",
      "Epoch 24/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 7.3114e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.8830e-04 - val_rmse: 0.0067 - val_r_square: 0.9824\n",
      "Epoch 25/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 7.3140e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.8192e-04 - val_rmse: 0.0066 - val_r_square: 0.9829\n",
      "Epoch 26/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 7.1729e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 2.0154e-04 - val_rmse: 0.0069 - val_r_square: 0.9811\n",
      "Epoch 27/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 7.0237e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.6690e-04 - val_rmse: 0.0062 - val_r_square: 0.9844\n",
      "Epoch 28/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 7.0528e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.6183e-04 - val_rmse: 0.0062 - val_r_square: 0.9849\n",
      "Epoch 29/150\n",
      "1258680/1258680 [==============================] - 22s 17us/step - loss: 6.8764e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.6182e-04 - val_rmse: 0.0062 - val_r_square: 0.9848\n",
      "Epoch 30/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.8951e-06 - rmse: 0.0016 - r_square: 0.9993 - val_loss: 1.7616e-04 - val_rmse: 0.0064 - val_r_square: 0.9835\n",
      "Epoch 31/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.8428e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.6251e-04 - val_rmse: 0.0062 - val_r_square: 0.9848\n",
      "Epoch 32/150\n",
      "1258680/1258680 [==============================] - 22s 18us/step - loss: 6.7461e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.3714e-04 - val_rmse: 0.0055 - val_r_square: 0.9872\n",
      "Epoch 33/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.6717e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.5915e-04 - val_rmse: 0.0060 - val_r_square: 0.9851\n",
      "Epoch 34/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.5950e-06 - rmse: 0.0015 - r_square: 0.9993 - val_loss: 1.3955e-04 - val_rmse: 0.0055 - val_r_square: 0.9870\n",
      "Epoch 35/150\n",
      "1258680/1258680 [==============================] - 22s 17us/step - loss: 6.6048e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5219e-04 - val_rmse: 0.0059 - val_r_square: 0.9858\n",
      "Epoch 36/150\n",
      "1258680/1258680 [==============================] - 23s 18us/step - loss: 6.5026e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5146e-04 - val_rmse: 0.0060 - val_r_square: 0.9859\n",
      "Epoch 37/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 6.5922e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5286e-04 - val_rmse: 0.0059 - val_r_square: 0.9857\n",
      "Epoch 38/150\n",
      "1258680/1258680 [==============================] - 23s 18us/step - loss: 6.4247e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5251e-04 - val_rmse: 0.0058 - val_r_square: 0.9858\n",
      "Epoch 39/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.3693e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4159e-04 - val_rmse: 0.0059 - val_r_square: 0.9868\n",
      "Epoch 40/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.3708e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5809e-04 - val_rmse: 0.0060 - val_r_square: 0.9852\n",
      "Epoch 41/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.3755e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4815e-04 - val_rmse: 0.0061 - val_r_square: 0.9862\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.4506e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4504e-04 - val_rmse: 0.0058 - val_r_square: 0.9865\n",
      "Epoch 43/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.2947e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.6168e-04 - val_rmse: 0.0061 - val_r_square: 0.9849\n",
      "Epoch 44/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 6.2979e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5177e-04 - val_rmse: 0.0059 - val_r_square: 0.9859\n",
      "Epoch 45/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 6.2846e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5278e-04 - val_rmse: 0.0062 - val_r_square: 0.9858\n",
      "Epoch 46/150\n",
      "1258680/1258680 [==============================] - 21s 16us/step - loss: 6.2389e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5832e-04 - val_rmse: 0.0062 - val_r_square: 0.9852\n",
      "Epoch 47/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 6.1594e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4601e-04 - val_rmse: 0.0058 - val_r_square: 0.9864\n",
      "Epoch 48/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 6.1611e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5984e-04 - val_rmse: 0.0061 - val_r_square: 0.9851\n",
      "Epoch 49/150\n",
      "1258680/1258680 [==============================] - 21s 17us/step - loss: 6.2265e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4590e-04 - val_rmse: 0.0059 - val_r_square: 0.9864\n",
      "Epoch 50/150\n",
      "1258680/1258680 [==============================] - 21s 16us/step - loss: 6.1429e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.5684e-04 - val_rmse: 0.0061 - val_r_square: 0.9854\n",
      "Epoch 51/150\n",
      "1258680/1258680 [==============================] - 19s 15us/step - loss: 6.1576e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4108e-04 - val_rmse: 0.0056 - val_r_square: 0.9869\n",
      "Epoch 52/150\n",
      "1258680/1258680 [==============================] - 20s 16us/step - loss: 6.1252e-06 - rmse: 0.0015 - r_square: 0.9994 - val_loss: 1.4785e-04 - val_rmse: 0.0058 - val_r_square: 0.9862\n",
      "Epoch 00052: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(6,)),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model2.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result2 = model2.fit(XX_train, \n",
    "                   yy_train,\n",
    "                   epochs = 150,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(XX_validation, yy_validation),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04803328]\n",
      " [0.00311903]\n",
      " [0.00254652]\n",
      " [0.06959646]\n",
      " [0.02624514]\n",
      " [0.00024288]\n",
      " [0.00085834]\n",
      " [0.10023231]\n",
      " [0.00202981]\n",
      " [0.00094579]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.005810\n",
      "Mean squared error (MSE):       0.000146\n",
      "Root mean squared error (RMSE): 0.012069\n",
      "R square (R^2):                 0.986288\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model2.predict(X_test)\n",
    "print(predictions2[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_test,predictions2))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_test,predictions2))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(skm.mean_squared_error(y_test,predictions2)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_test,predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try batch normalization technique to regularize neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 487123 samples, validate on 239927 samples\n",
      "Epoch 1/200\n",
      "487123/487123 [==============================] - 4s 8us/step - loss: 0.0010 - rmse: 0.0176 - r_square: 0.9569 - val_loss: 1.4472e-04 - val_rmse: 0.0078 - val_r_square: 0.9940\n",
      "Epoch 2/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 3.5415e-04 - rmse: 0.0125 - r_square: 0.9854 - val_loss: 6.6277e-05 - val_rmse: 0.0060 - val_r_square: 0.9973\n",
      "Epoch 3/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 3.1503e-04 - rmse: 0.0114 - r_square: 0.9871 - val_loss: 1.5766e-04 - val_rmse: 0.0077 - val_r_square: 0.9935\n",
      "Epoch 4/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 3.0017e-04 - rmse: 0.0109 - r_square: 0.9877 - val_loss: 1.3407e-04 - val_rmse: 0.0090 - val_r_square: 0.9944\n",
      "Epoch 5/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.9197e-04 - rmse: 0.0109 - r_square: 0.9880 - val_loss: 1.4660e-04 - val_rmse: 0.0089 - val_r_square: 0.9940\n",
      "Epoch 6/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.8454e-04 - rmse: 0.0105 - r_square: 0.9883 - val_loss: 1.4590e-04 - val_rmse: 0.0068 - val_r_square: 0.9941\n",
      "Epoch 7/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5636e-04 - rmse: 0.0100 - r_square: 0.9894 - val_loss: 3.2742e-05 - val_rmse: 0.0042 - val_r_square: 0.9986\n",
      "Epoch 8/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5502e-04 - rmse: 0.0099 - r_square: 0.9895 - val_loss: 1.3824e-04 - val_rmse: 0.0077 - val_r_square: 0.9943\n",
      "Epoch 9/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5413e-04 - rmse: 0.0099 - r_square: 0.9896 - val_loss: 3.6484e-05 - val_rmse: 0.0042 - val_r_square: 0.9985\n",
      "Epoch 10/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5418e-04 - rmse: 0.0098 - r_square: 0.9895 - val_loss: 6.0479e-05 - val_rmse: 0.0055 - val_r_square: 0.9975\n",
      "Epoch 11/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5245e-04 - rmse: 0.0099 - r_square: 0.9896 - val_loss: 3.8806e-05 - val_rmse: 0.0044 - val_r_square: 0.9984\n",
      "Epoch 12/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.6297e-04 - rmse: 0.0100 - r_square: 0.9892 - val_loss: 2.4315e-05 - val_rmse: 0.0032 - val_r_square: 0.9990\n",
      "Epoch 13/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4506e-04 - rmse: 0.0097 - r_square: 0.9898 - val_loss: 3.0089e-05 - val_rmse: 0.0032 - val_r_square: 0.9988\n",
      "Epoch 14/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.5724e-04 - rmse: 0.0098 - r_square: 0.9894 - val_loss: 1.9008e-05 - val_rmse: 0.0028 - val_r_square: 0.9992\n",
      "Epoch 15/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4267e-04 - rmse: 0.0095 - r_square: 0.9900 - val_loss: 8.3593e-05 - val_rmse: 0.0061 - val_r_square: 0.9966\n",
      "Epoch 16/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4752e-04 - rmse: 0.0097 - r_square: 0.9898 - val_loss: 1.3307e-04 - val_rmse: 0.0072 - val_r_square: 0.9946\n",
      "Epoch 17/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3897e-04 - rmse: 0.0094 - r_square: 0.9903 - val_loss: 7.3407e-05 - val_rmse: 0.0053 - val_r_square: 0.9970\n",
      "Epoch 18/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3634e-04 - rmse: 0.0094 - r_square: 0.9902 - val_loss: 1.7224e-05 - val_rmse: 0.0029 - val_r_square: 0.9993\n",
      "Epoch 19/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4679e-04 - rmse: 0.0096 - r_square: 0.9898 - val_loss: 5.2111e-05 - val_rmse: 0.0053 - val_r_square: 0.9979\n",
      "Epoch 20/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4215e-04 - rmse: 0.0096 - r_square: 0.9900 - val_loss: 3.7329e-05 - val_rmse: 0.0040 - val_r_square: 0.9985\n",
      "Epoch 21/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2942e-04 - rmse: 0.0093 - r_square: 0.9906 - val_loss: 2.2811e-05 - val_rmse: 0.0029 - val_r_square: 0.9991\n",
      "Epoch 22/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4971e-04 - rmse: 0.0097 - r_square: 0.9898 - val_loss: 2.4531e-05 - val_rmse: 0.0032 - val_r_square: 0.9990\n",
      "Epoch 23/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3881e-04 - rmse: 0.0094 - r_square: 0.9902 - val_loss: 5.2940e-05 - val_rmse: 0.0046 - val_r_square: 0.9978\n",
      "Epoch 24/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3484e-04 - rmse: 0.0094 - r_square: 0.9903 - val_loss: 2.5193e-05 - val_rmse: 0.0035 - val_r_square: 0.9990\n",
      "Epoch 25/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3831e-04 - rmse: 0.0095 - r_square: 0.9902 - val_loss: 3.4562e-05 - val_rmse: 0.0043 - val_r_square: 0.9986\n",
      "Epoch 26/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3410e-04 - rmse: 0.0093 - r_square: 0.9904 - val_loss: 3.5790e-05 - val_rmse: 0.0039 - val_r_square: 0.9985\n",
      "Epoch 27/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3963e-04 - rmse: 0.0095 - r_square: 0.9901 - val_loss: 5.8185e-05 - val_rmse: 0.0054 - val_r_square: 0.9976\n",
      "Epoch 28/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3109e-04 - rmse: 0.0092 - r_square: 0.9905 - val_loss: 3.8614e-05 - val_rmse: 0.0036 - val_r_square: 0.9984\n",
      "Epoch 29/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3334e-04 - rmse: 0.0093 - r_square: 0.9905 - val_loss: 1.9158e-05 - val_rmse: 0.0029 - val_r_square: 0.9992\n",
      "Epoch 30/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2940e-04 - rmse: 0.0093 - r_square: 0.9905 - val_loss: 2.0703e-05 - val_rmse: 0.0027 - val_r_square: 0.9991\n",
      "Epoch 31/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2816e-04 - rmse: 0.0093 - r_square: 0.9906 - val_loss: 3.6843e-05 - val_rmse: 0.0041 - val_r_square: 0.9985\n",
      "Epoch 32/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2853e-04 - rmse: 0.0093 - r_square: 0.9906 - val_loss: 3.7567e-05 - val_rmse: 0.0038 - val_r_square: 0.9985\n",
      "Epoch 33/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2363e-04 - rmse: 0.0093 - r_square: 0.9908 - val_loss: 2.8971e-05 - val_rmse: 0.0034 - val_r_square: 0.9988\n",
      "Epoch 34/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2115e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 1.7335e-05 - val_rmse: 0.0027 - val_r_square: 0.9993\n",
      "Epoch 35/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3398e-04 - rmse: 0.0094 - r_square: 0.9904 - val_loss: 2.3413e-05 - val_rmse: 0.0033 - val_r_square: 0.9990\n",
      "Epoch 36/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3700e-04 - rmse: 0.0095 - r_square: 0.9902 - val_loss: 2.6944e-05 - val_rmse: 0.0033 - val_r_square: 0.9989\n",
      "Epoch 37/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3066e-04 - rmse: 0.0093 - r_square: 0.9905 - val_loss: 1.8262e-05 - val_rmse: 0.0025 - val_r_square: 0.9992\n",
      "Epoch 38/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3079e-04 - rmse: 0.0093 - r_square: 0.9905 - val_loss: 7.0820e-05 - val_rmse: 0.0057 - val_r_square: 0.9971\n",
      "Epoch 39/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2840e-04 - rmse: 0.0093 - r_square: 0.9906 - val_loss: 5.1693e-05 - val_rmse: 0.0046 - val_r_square: 0.9979\n",
      "Epoch 40/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.4427e-04 - rmse: 0.0095 - r_square: 0.9899 - val_loss: 3.1388e-05 - val_rmse: 0.0035 - val_r_square: 0.9987\n",
      "Epoch 41/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2237e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 2.7407e-05 - val_rmse: 0.0037 - val_r_square: 0.9989\n",
      "Epoch 42/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2086e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 6.4634e-05 - val_rmse: 0.0055 - val_r_square: 0.9974\n",
      "Epoch 43/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2498e-04 - rmse: 0.0092 - r_square: 0.9908 - val_loss: 1.8365e-05 - val_rmse: 0.0026 - val_r_square: 0.9992\n",
      "Epoch 44/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2660e-04 - rmse: 0.0091 - r_square: 0.9907 - val_loss: 5.7419e-05 - val_rmse: 0.0059 - val_r_square: 0.9976\n",
      "Epoch 45/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2331e-04 - rmse: 0.0092 - r_square: 0.9907 - val_loss: 1.5006e-05 - val_rmse: 0.0025 - val_r_square: 0.9994\n",
      "Epoch 46/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2514e-04 - rmse: 0.0091 - r_square: 0.9907 - val_loss: 2.1396e-05 - val_rmse: 0.0033 - val_r_square: 0.9991\n",
      "Epoch 47/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1763e-04 - rmse: 0.0090 - r_square: 0.9910 - val_loss: 3.9048e-05 - val_rmse: 0.0045 - val_r_square: 0.9984\n",
      "Epoch 48/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2386e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 2.5654e-05 - val_rmse: 0.0032 - val_r_square: 0.9989\n",
      "Epoch 49/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3553e-04 - rmse: 0.0094 - r_square: 0.9904 - val_loss: 3.1644e-05 - val_rmse: 0.0045 - val_r_square: 0.9987\n",
      "Epoch 50/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2581e-04 - rmse: 0.0092 - r_square: 0.9907 - val_loss: 3.1348e-05 - val_rmse: 0.0037 - val_r_square: 0.9987\n",
      "Epoch 51/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2108e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.9372e-05 - val_rmse: 0.0035 - val_r_square: 0.9988\n",
      "Epoch 52/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2228e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 4.8100e-05 - val_rmse: 0.0047 - val_r_square: 0.9980\n",
      "Epoch 53/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2258e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 1.5655e-05 - val_rmse: 0.0024 - val_r_square: 0.9994\n",
      "Epoch 54/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2098e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.3211e-05 - val_rmse: 0.0032 - val_r_square: 0.9990\n",
      "Epoch 55/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2657e-04 - rmse: 0.0092 - r_square: 0.9907 - val_loss: 1.9761e-05 - val_rmse: 0.0026 - val_r_square: 0.9992\n",
      "Epoch 56/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2287e-04 - rmse: 0.0092 - r_square: 0.9909 - val_loss: 2.0357e-05 - val_rmse: 0.0029 - val_r_square: 0.9992\n",
      "Epoch 57/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2106e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.4313e-05 - val_rmse: 0.0033 - val_r_square: 0.9990\n",
      "Epoch 58/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.3131e-04 - rmse: 0.0093 - r_square: 0.9904 - val_loss: 3.0427e-05 - val_rmse: 0.0039 - val_r_square: 0.9987\n",
      "Epoch 59/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1997e-04 - rmse: 0.0091 - r_square: 0.9910 - val_loss: 2.3945e-05 - val_rmse: 0.0031 - val_r_square: 0.9990\n",
      "Epoch 60/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2447e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 3.6661e-05 - val_rmse: 0.0034 - val_r_square: 0.9985\n",
      "Epoch 61/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1865e-04 - rmse: 0.0090 - r_square: 0.9910 - val_loss: 2.4775e-05 - val_rmse: 0.0032 - val_r_square: 0.9990\n",
      "Epoch 62/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2732e-04 - rmse: 0.0092 - r_square: 0.9906 - val_loss: 1.6062e-05 - val_rmse: 0.0024 - val_r_square: 0.9993\n",
      "Epoch 63/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1205e-04 - rmse: 0.0090 - r_square: 0.9912 - val_loss: 7.4692e-05 - val_rmse: 0.0054 - val_r_square: 0.9969\n",
      "Epoch 64/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1079e-04 - rmse: 0.0089 - r_square: 0.9913 - val_loss: 6.7484e-05 - val_rmse: 0.0051 - val_r_square: 0.9972\n",
      "Epoch 65/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1771e-04 - rmse: 0.0090 - r_square: 0.9910 - val_loss: 2.3371e-05 - val_rmse: 0.0035 - val_r_square: 0.9990\n",
      "Epoch 66/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2135e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.2457e-05 - val_rmse: 0.0031 - val_r_square: 0.9991\n",
      "Epoch 67/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2335e-04 - rmse: 0.0092 - r_square: 0.9909 - val_loss: 2.0304e-05 - val_rmse: 0.0028 - val_r_square: 0.9992\n",
      "Epoch 68/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1315e-04 - rmse: 0.0089 - r_square: 0.9912 - val_loss: 2.7621e-05 - val_rmse: 0.0035 - val_r_square: 0.9989\n",
      "Epoch 69/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1295e-04 - rmse: 0.0090 - r_square: 0.9913 - val_loss: 1.9383e-05 - val_rmse: 0.0031 - val_r_square: 0.9992\n",
      "Epoch 70/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1914e-04 - rmse: 0.0091 - r_square: 0.9910 - val_loss: 2.7297e-05 - val_rmse: 0.0038 - val_r_square: 0.9989\n",
      "Epoch 71/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2291e-04 - rmse: 0.0092 - r_square: 0.9908 - val_loss: 6.4090e-05 - val_rmse: 0.0049 - val_r_square: 0.9973\n",
      "Epoch 72/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2204e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.0816e-05 - val_rmse: 0.0029 - val_r_square: 0.9991\n",
      "Epoch 73/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1317e-04 - rmse: 0.0090 - r_square: 0.9912 - val_loss: 6.2106e-05 - val_rmse: 0.0062 - val_r_square: 0.9974\n",
      "Epoch 74/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2238e-04 - rmse: 0.0092 - r_square: 0.9908 - val_loss: 3.0137e-05 - val_rmse: 0.0036 - val_r_square: 0.9988\n",
      "Epoch 75/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2305e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 1.9085e-05 - val_rmse: 0.0025 - val_r_square: 0.9992\n",
      "Epoch 76/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1560e-04 - rmse: 0.0090 - r_square: 0.9911 - val_loss: 3.2413e-05 - val_rmse: 0.0040 - val_r_square: 0.9987\n",
      "Epoch 77/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2431e-04 - rmse: 0.0091 - r_square: 0.9908 - val_loss: 2.1438e-05 - val_rmse: 0.0032 - val_r_square: 0.9991\n",
      "Epoch 78/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0469e-04 - rmse: 0.0088 - r_square: 0.9915 - val_loss: 4.7530e-05 - val_rmse: 0.0041 - val_r_square: 0.9980\n",
      "Epoch 79/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1649e-04 - rmse: 0.0091 - r_square: 0.9911 - val_loss: 2.4759e-05 - val_rmse: 0.0033 - val_r_square: 0.9990\n",
      "Epoch 80/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2199e-04 - rmse: 0.0092 - r_square: 0.9909 - val_loss: 2.1750e-05 - val_rmse: 0.0029 - val_r_square: 0.9991\n",
      "Epoch 81/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1651e-04 - rmse: 0.0090 - r_square: 0.9911 - val_loss: 1.8060e-05 - val_rmse: 0.0030 - val_r_square: 0.9993\n",
      "Epoch 82/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1302e-04 - rmse: 0.0089 - r_square: 0.9912 - val_loss: 2.2619e-05 - val_rmse: 0.0028 - val_r_square: 0.9991\n",
      "Epoch 83/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2407e-04 - rmse: 0.0092 - r_square: 0.9907 - val_loss: 2.9842e-05 - val_rmse: 0.0034 - val_r_square: 0.9988\n",
      "Epoch 84/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1314e-04 - rmse: 0.0089 - r_square: 0.9912 - val_loss: 3.1316e-05 - val_rmse: 0.0038 - val_r_square: 0.9987\n",
      "Epoch 85/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1724e-04 - rmse: 0.0090 - r_square: 0.9911 - val_loss: 2.4251e-05 - val_rmse: 0.0039 - val_r_square: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1264e-04 - rmse: 0.0090 - r_square: 0.9912 - val_loss: 2.0521e-05 - val_rmse: 0.0029 - val_r_square: 0.9992\n",
      "Epoch 87/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2124e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 1.7220e-05 - val_rmse: 0.0027 - val_r_square: 0.9993\n",
      "Epoch 88/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0725e-04 - rmse: 0.0088 - r_square: 0.9915 - val_loss: 3.5184e-05 - val_rmse: 0.0041 - val_r_square: 0.9986\n",
      "Epoch 89/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1255e-04 - rmse: 0.0090 - r_square: 0.9913 - val_loss: 2.6888e-05 - val_rmse: 0.0031 - val_r_square: 0.9989\n",
      "Epoch 90/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0636e-04 - rmse: 0.0088 - r_square: 0.9915 - val_loss: 1.9418e-05 - val_rmse: 0.0028 - val_r_square: 0.9992\n",
      "Epoch 91/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0932e-04 - rmse: 0.0089 - r_square: 0.9913 - val_loss: 3.1192e-05 - val_rmse: 0.0041 - val_r_square: 0.9987\n",
      "Epoch 92/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.0490e-04 - rmse: 0.0089 - r_square: 0.9916 - val_loss: 3.2297e-05 - val_rmse: 0.0047 - val_r_square: 0.9987\n",
      "Epoch 93/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1912e-04 - rmse: 0.0091 - r_square: 0.9909 - val_loss: 2.8050e-05 - val_rmse: 0.0036 - val_r_square: 0.9988\n",
      "Epoch 94/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.2103e-04 - rmse: 0.0091 - r_square: 0.9910 - val_loss: 1.5035e-05 - val_rmse: 0.0023 - val_r_square: 0.9994\n",
      "Epoch 95/200\n",
      "487123/487123 [==============================] - 3s 7us/step - loss: 2.1224e-04 - rmse: 0.0089 - r_square: 0.9912 - val_loss: 3.0091e-05 - val_rmse: 0.0036 - val_r_square: 0.9988\n",
      "Epoch 00095: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model3 = Sequential([\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', input_shape=(6,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "model3.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[rmse, r_square],\n",
    ")\n",
    "# fit the model\n",
    "result3 = model3.fit(X_train, \n",
    "                   y_train,\n",
    "                   epochs = 200,\n",
    "                   batch_size=256,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks = [es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04051611]\n",
      " [ 0.34659985]\n",
      " [ 0.12310097]\n",
      " [ 0.05491048]\n",
      " [ 0.02672598]\n",
      " [ 0.01006674]\n",
      " [ 0.5663377 ]\n",
      " [-0.00239683]\n",
      " [-0.00114246]\n",
      " [ 0.18679872]]\n",
      "\n",
      "\n",
      "Mean absolute error (MAE):      0.003646\n",
      "Mean squared error (MSE):       0.000030\n",
      "Root mean squared error (RMSE): 0.005486\n",
      "R square (R^2):                 0.998779\n"
     ]
    }
   ],
   "source": [
    "predictions3 = model3.predict(X_test)\n",
    "print(predictions3[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Mean absolute error (MAE):      %f\" % skm.mean_absolute_error(y_test,predictions3))\n",
    "print(\"Mean squared error (MSE):       %f\" % skm.mean_squared_error(y_test,predictions3))\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(sklearn.metrics.mean_squared_error(y_test,predictions3)))\n",
    "print(\"R square (R^2):                 %f\" % skm.r2_score(y_test,predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference: \n",
    "&emsp;&emsp;What does 'Accuracy' mean in Regression? https://github.com/keras-team/keras/issues/7947 <br>\n",
    "&emsp;&emsp;https://keras.io/metrics/<br>\n",
    "&emsp;&emsp;Scale, Standardize, or Normalize with Scikit-Learn https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02 <br>\n",
    "&emsp;&emsp;The Day my Computer Won the Nobel Prize (Neural Network Option Pricing)  https://medium.com/datadriveninvestor/the-day-my-computer-won-the-nobel-prize-neural-network-option-pricing-d29b4379f1d2 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
